{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "\n",
    "#allFeat = np.load('/tf/notebooks/clusteringTree/stl_feat/feats_2048.npy')\n",
    "#gtAll = np.load('/tf/notebooks/clusteringTree/stl_feat/labels_2048.npy')-1|\n",
    "\n",
    "# allFeat = np.load('/tf/notebooks/STL-10/danielFeat.npy')\n",
    "# gtAll = np.load('/tf/notebooks/STL-10/danielGt.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from clusteringX2 import normIt\n",
    "from clusteringX2 import clusterModel\n",
    "from clusteringX2 import train_step3\n",
    "from clusteringX2 import train_step4\n",
    "\n",
    "\n",
    "def clustering(feat, numClass=60, thres=0.1, iter_=1000):\n",
    "    \n",
    "    denom = 0.1\n",
    "    #feat, m = normIt(feat)\n",
    "    m = np.zeros(feat.shape[1])\n",
    "    \n",
    "    # initilization\n",
    "    kmeans = KMeans(n_clusters=numClass, random_state=0).fit(feat)\n",
    "    labelK = kmeans.predict(feat)\n",
    "    means =np.zeros([numClass, feat.shape[1]])\n",
    "\n",
    "    for i in range(numClass):\n",
    "        mask = labelK == i\n",
    "        means[i,:] = np.mean(feat[mask,:], axis =0)\n",
    "\n",
    "    sigInit = np.zeros([numClass])\n",
    "    for i in range(numClass):\n",
    "        mask = np.logical_not(labelK == i)\n",
    "        sigInit[i] = np.mean(np.matmul(feat[mask,:], np.transpose(means[i,:])))\n",
    "    model = clusterModel(means.transpose(), sigInit)\n",
    "    train_step4(model, feat.astype(\"float32\"), iter=iter_, denom=denom)\n",
    "    \n",
    "    \n",
    "    \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    s = np.max(c, axis=1)\n",
    "    t = np.mean(s)\n",
    "    mask = s > t*0.5\n",
    "    \n",
    "    \n",
    "    train_step4(model, feat[mask,:].astype(\"float32\"), iter=iter_, denom=denom)\n",
    "    \n",
    "    \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    s = np.max(c, axis=1)\n",
    "    t = np.mean(s)\n",
    "    mask = s > t*0.5\n",
    "    train_step4(model, feat[mask,:].astype(\"float32\"), iter=iter_, denom=denom)\n",
    "\n",
    " \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    labels = np.argmax(c, axis =1)\n",
    "    mask_ = np.zeros(numClass, dtype=bool)\n",
    "        \n",
    "    for i in range(numClass):\n",
    "        if np.sum(labels==i)>0:\n",
    "            mask_[i] = 1\n",
    "    w = model.w.numpy()\n",
    "    sig = model.sig.numpy()\n",
    "    w = w[:,mask_]\n",
    "    sig = sig[mask_]\n",
    "            \n",
    "\n",
    "    return w, sig, m, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, mask=None, w=None, sig=None, m=None):\n",
    "        self.mask = mask\n",
    "        self.w = w\n",
    "        self.sig = sig\n",
    "        self.m = m\n",
    "        self.listOfChildren = []\n",
    "            \n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.nodeList = []\n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self):\n",
    "        self.numLayers = 0\n",
    "        self.listOfLayers = []\n",
    "        self.numNodes = 0\n",
    "        self.listOfNodes = []\n",
    "        \n",
    "    def addNode(self, c):\n",
    "        self.listOfNodes.append(c)\n",
    "        self.numNodes = self.numNodes + 1\n",
    "        \n",
    "    def addLayer(self, c):\n",
    "        self.listOfLayers.append(c)\n",
    "        self.numLayers = self.numLayers + 1\n",
    "\n",
    "    \n",
    "def startTree(allFeat, numClass=60):\n",
    "    tree = Tree()    \n",
    "    w, sig, m, inMask = clustering(allFeat, numClass)\n",
    "    mask = np.ones(allFeat.shape[0], dtype=bool)\n",
    "    #mask[np.logical_not(inMask)] = 0\n",
    "    n = Node(mask, w, sig, m)\n",
    "\n",
    "    tree.addNode(n)\n",
    "    newLayer = Layer()\n",
    "    newLayer.nodeList.append(tree.numNodes-1)\n",
    "    tree.addLayer(newLayer)\n",
    "    \n",
    "    return tree\n",
    "#allFeat = allFeat/np.linalg.norm(allFeat, axis=1, keepdims=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "    \n",
    "def dataProjection(feat, node):\n",
    "    x, _ = normIt(feat, node.m) \n",
    "    s = np.linalg.norm(node.w, axis =0, keepdims=True)\n",
    "    return (np.matmul(x, node.w) - node.sig), s\n",
    "\n",
    "\n",
    "def extendTree(tree, allFeat, numClass=2, clusteringThreshold=100):\n",
    "    newLayer = Layer()\n",
    "    lastLayer = tree.listOfLayers[-1]\n",
    "    for nodeIndex in lastLayer.nodeList:\n",
    "        node = tree.listOfNodes[nodeIndex]\n",
    "        curFeat = allFeat[node.mask,:]\n",
    "        score, _ = dataProjection(curFeat, node)\n",
    "        \n",
    "        clusterInd = np.argmax(score, axis =1)\n",
    "        curInd = np.where(node.mask)[0]\n",
    "\n",
    "        #########################################\n",
    "        #_, m_sub = normIt(curFeat)\n",
    "        #########################################\n",
    "        \n",
    "        for i in range(score.shape[1]):\n",
    "            subMask = clusterInd == i\n",
    "            if sum(subMask) > clusteringThreshold:\n",
    "                \n",
    "                newMask =  np.zeros(allFeat.shape[0], dtype=bool)\n",
    "                newMask[curInd[subMask]] = 1\n",
    "                \n",
    "                \n",
    "                #########################################\n",
    "                #nF, m_sub = normIt(allFeat[newMask,:])\n",
    "                #########################################\n",
    "\n",
    "                nF, m_sub = normIt(allFeat[newMask,:])\n",
    "                #nF = allFeat[newMask,:]\n",
    "                w, sig, _, inMask = clustering(nF, numClass)\n",
    "\n",
    "                print(w.shape, sum(newMask))\n",
    "                if w.shape[1]>=2:\n",
    "                    n = Node(newMask, w, sig, m_sub)\n",
    "                    tree.addNode(n)\n",
    "                    newLayer.nodeList.append(tree.numNodes-1)\n",
    "                    node.listOfChildren.append(tree.numNodes-1)\n",
    "                else:\n",
    "                    node.listOfChildren.append(-1)\n",
    "            else:\n",
    "                node.listOfChildren.append(-1)\n",
    "    tree.addLayer(newLayer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2oneHot(labels):\n",
    "    b = np.zeros((labels.size, labels.max()+1), dtype=bool)\n",
    "    b[np.arange(labels.size),labels] = 1\n",
    "    return b\n",
    "\n",
    "\n",
    "\n",
    "def projectXX(feat, tree, maxClus=60, unit_vector=False, scale2data=False, verboise=True):\n",
    "    projectionSpace = np.zeros([feat.shape[0], tree.numNodes*maxClus])\n",
    "    maskAll = np.zeros([feat.shape[0], tree.numNodes*maxClus])\n",
    "\n",
    "    cur = 0    \n",
    "    for i, l in enumerate(tree.listOfLayers):\n",
    "        for nIndex in l.nodeList:\n",
    "            n = tree.listOfNodes[nIndex]\n",
    "            f, s = dataProjection(feat, n)\n",
    "            numDim = f.shape[1]\n",
    "            lab = np.argmax(f, axis =1)\n",
    "            maskAll[:,cur:cur+numDim] = label2oneHot(lab)\n",
    "            projectionSpace[:,cur:cur+numDim] = f\n",
    "            cur = cur + numDim\n",
    "    projectionSpace = projectionSpace[:,:cur]\n",
    "    maskAll = maskAll[:,:cur]\n",
    "    \n",
    "    return projectionSpace, maskAll\n",
    "\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2path(mask, tree):\n",
    "    pathNode = -1*np.ones([mask.shape[0], len(tree.listOfLayers)+1], dtype=int)\n",
    "    pathNode[:,0] = 0\n",
    "    \n",
    "    pathDim = -1*np.ones([mask.shape[0], len(tree.listOfLayers)+1], dtype=int)\n",
    "\n",
    "    \n",
    "    cur = 0\n",
    "    for i, l in enumerate(tree.listOfLayers):\n",
    "        print('layer:',i)\n",
    "        \n",
    "        for nIndex in l.nodeList:           \n",
    "            \n",
    "            n = tree.listOfNodes[nIndex]\n",
    "            dim = n.w.shape[1]\n",
    "            \n",
    "            \n",
    "            allCur = pathNode[:,i] == nIndex # in node nIndex\n",
    "            sub_mask = mask[:,cur:cur+dim] # with dimenions\n",
    "            ind = np.argmax(sub_mask)\n",
    "\n",
    "            for k in range(dim):\n",
    "                m = np.logical_and(allCur, sub_mask[:,k])\n",
    "                pathDim[m, i] = cur + k \n",
    "\n",
    "            \n",
    "            \n",
    "            if not n.listOfChildren:\n",
    "                cur = cur + dim\n",
    "                continue\n",
    "\n",
    "                        \n",
    "            \n",
    "            for k in range(dim):\n",
    "                m = np.logical_and(allCur, sub_mask[:,k])\n",
    "                pathNode[m, i+1] = n.listOfChildren[k]\n",
    "                \n",
    "                \n",
    "            cur = cur + dim\n",
    "            \n",
    "            \n",
    "    return pathNode, pathDim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classScore(pathDim, ff, dim):\n",
    "    numPts = pathDim.shape[0]\n",
    "    score = np.zeros(pathDim.shape[0])\n",
    "    \n",
    "    for i in range(numPts):\n",
    "        for j in range(dim+1):\n",
    "            if pathDim[i,j]>=0:\n",
    "                score[i] = score[i] + ff[i, pathDim[i,j]]\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# allFeat = np.load('/tf/notebooks/STL-10/danielFeat.npy')\n",
    "# gtAll = np.load('/tf/notebooks/STL-10/danielGt.npy')\n",
    "    \n",
    "\n",
    "allFeat = np.load('/tf/notebooks/Food59/train/resNet50.npy')\n",
    "gtAll = np.load('/tf/notebooks/Food59/train/gt.npy')\n",
    "\n",
    "mask = gtAll<10\n",
    "allFeat = allFeat[mask]\n",
    "gtAll = gtAll[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat, _ = normIt(allFeat)\n",
    "gt = gtAll.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 13) 2621\n",
      "(2048, 39) 1355\n",
      "(2048, 47) 1283\n",
      "(2048, 54) 716\n",
      "(2048, 51) 651\n",
      "(2048, 51) 1296\n",
      "(2048, 47) 1304\n",
      "(2048, 25) 1979\n",
      "(2048, 25) 1795\n",
      "(2048, 57) 321\n",
      "(2048, 52) 751\n",
      "(2048, 58) 780\n",
      "(2048, 56) 230\n",
      "(2048, 53) 198\n",
      "(2048, 52) 110\n",
      "(2048, 51) 113\n",
      "(2048, 53) 154\n",
      "(2048, 53) 165\n",
      "(2048, 54) 162\n",
      "(2048, 55) 245\n",
      "(2048, 56) 227\n",
      "(2048, 53) 140\n",
      "(2048, 50) 117\n",
      "(2048, 54) 146\n",
      "(2048, 52) 216\n",
      "(2048, 53) 113\n",
      "(2048, 54) 209\n",
      "(2048, 59) 304\n",
      "(2048, 53) 154\n",
      "(2048, 53) 193\n",
      "(2048, 54) 154\n",
      "(2048, 51) 133\n",
      "(2048, 60) 373\n",
      "(2048, 56) 104\n",
      "(2048, 49) 101\n",
      "(2048, 50) 117\n",
      "(2048, 59) 462\n",
      "(2048, 54) 102\n",
      "(2048, 55) 117\n",
      "(2048, 57) 380\n",
      "(2048, 47) 109\n",
      "(2048, 59) 365\n",
      "(2048, 57) 211\n",
      "(2048, 53) 115\n",
      "(2048, 51) 155\n",
      "(2048, 54) 164\n",
      "(2048, 56) 173\n",
      "(2048, 54) 156\n",
      "(2048, 51) 118\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n"
     ]
    }
   ],
   "source": [
    "f = feat\n",
    "\n",
    "tree2 = startTree(f, numClass=60)\n",
    "extendTree(tree2, f, numClass=60)\n",
    "extendTree(tree2, f, numClass=60)\n",
    "extendTree(tree2, f, numClass=60)\n",
    "ff2, mask2 = projectXX(feat, tree2)\n",
    "pathNode2, pathDim2 = mask2path(mask2, tree2)\n",
    "s2 = classScore(pathDim2, ff2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <__main__.Node object at 0x7f62e802f518>\n",
      "1 <__main__.Node object at 0x7f62bab788d0>\n",
      "2 <__main__.Node object at 0x7f62b8409fd0>\n",
      "3 <__main__.Node object at 0x7f62b83ac160>\n",
      "4 <__main__.Node object at 0x7f62b8426eb8>\n",
      "5 <__main__.Node object at 0x7f62b8339908>\n",
      "6 <__main__.Node object at 0x7f62baad0f60>\n",
      "7 <__main__.Node object at 0x7f62b82aa6a0>\n",
      "8 <__main__.Node object at 0x7f62b8383a90>\n",
      "9 <__main__.Node object at 0x7f62b82c0e80>\n",
      "10 <__main__.Node object at 0x7f62200e36a0>\n",
      "11 <__main__.Node object at 0x7f62200a1160>\n",
      "12 <__main__.Node object at 0x7f61f06e7ac8>\n",
      "13 <__main__.Node object at 0x7f622003e630>\n",
      "14 <__main__.Node object at 0x7f61f065f4a8>\n",
      "15 <__main__.Node object at 0x7f61f067acc0>\n",
      "16 <__main__.Node object at 0x7f61f0694630>\n",
      "17 <__main__.Node object at 0x7f61f0605e10>\n",
      "18 <__main__.Node object at 0x7f61f0557908>\n",
      "19 <__main__.Node object at 0x7f61f057f240>\n",
      "20 <__main__.Node object at 0x7f61f06506d8>\n",
      "21 <__main__.Node object at 0x7f61f04eb9b0>\n",
      "22 <__main__.Node object at 0x7f61f045bba8>\n",
      "23 <__main__.Node object at 0x7f61f0478c88>\n",
      "24 <__main__.Node object at 0x7f61f0493c88>\n",
      "25 <__main__.Node object at 0x7f61f0407e80>\n",
      "26 <__main__.Node object at 0x7f61f04140b8>\n",
      "27 <__main__.Node object at 0x7f61f0493f60>\n",
      "28 <__main__.Node object at 0x7f61f0380cc0>\n",
      "29 <__main__.Node object at 0x7f61f0577ac8>\n",
      "30 <__main__.Node object at 0x7f61f02a9c88>\n",
      "31 <__main__.Node object at 0x7f61f02ae828>\n",
      "32 <__main__.Node object at 0x7f61f0280898>\n",
      "33 <__main__.Node object at 0x7f61f0387438>\n",
      "34 <__main__.Node object at 0x7f61f04a2a90>\n",
      "35 <__main__.Node object at 0x7f61f01cda20>\n",
      "36 <__main__.Node object at 0x7f61f0195c88>\n",
      "37 <__main__.Node object at 0x7f61f018c4e0>\n",
      "38 <__main__.Node object at 0x7f61f0195b38>\n",
      "39 <__main__.Node object at 0x7f61f0186e80>\n",
      "40 <__main__.Node object at 0x7f61f00d6ac8>\n",
      "41 <__main__.Node object at 0x7f61f013def0>\n",
      "42 <__main__.Node object at 0x7f61f002e278>\n",
      "43 <__main__.Node object at 0x7f61f0069160>\n",
      "44 <__main__.Node object at 0x7f61bc3b6b38>\n",
      "45 <__main__.Node object at 0x7f61bc3efef0>\n",
      "46 <__main__.Node object at 0x7f61bc3b6e80>\n",
      "47 <__main__.Node object at 0x7f61bc389a90>\n",
      "48 <__main__.Node object at 0x7f61bc368f98>\n",
      "49 <__main__.Node object at 0x7f61bc291358>\n"
     ]
    }
   ],
   "source": [
    "def projectTree2(feat, tree, maxClus=60, unit_vector=True, scale2data=True, verboise=True):\n",
    "    \n",
    "    projectionSpace = np.zeros([feat.shape[0], tree.numNodes*maxClus])\n",
    "    \n",
    "    cur = 0\n",
    "    \n",
    "    for i, n in enumerate(tree.listOfNodes):\n",
    "        \n",
    "        f, _ = dataProjection(feat, n)\n",
    "        numDim = f.shape[1]\n",
    "        if unit_vector:\n",
    "            f_ = np.concatenate([f, 10*np.ones([f.shape[0],1])], axis =1)\n",
    "            f_ = f_/np.linalg.norm(f_, axis =1, keepdims=True)\n",
    "            f = f_[:,:numDim]\n",
    "        if scale2data:\n",
    "            f = f*np.sum(n.mask)/n.mask.size \n",
    "        projectionSpace[:, cur:cur+numDim] = f\n",
    "        cur = cur+numDim\n",
    "        \n",
    "        if verboise == True:\n",
    "            print(i, n)\n",
    "    projectionSpace = projectionSpace[:,:cur]\n",
    "    return projectionSpace\n",
    "        \n",
    "featTest = projectTree2(feat, tree2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNumPerClass(pathDim):\n",
    "    numClass = np.max(pathDim)+1\n",
    "    numPerClass = np.zeros(numClass)\n",
    "    for i in range(numClass):\n",
    "        numPerClass[i] = np.sum(pathDim==i)\n",
    "    return numPerClass\n",
    "\n",
    "numPerDim = getNumPerClass(pathDim2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13000, 2519)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "# setup\n",
    "gt_use = gt.copy()\n",
    "#gt_use = gtCoarse.copy()\n",
    "#########\n",
    "\n",
    "\n",
    "samplePerClass = 1\n",
    "numClass = int(max(gt_use)+1)\n",
    "ind = []\n",
    "for i in range(numClass):\n",
    "    index = list(np.where(gt_use==i)[0])\n",
    "    if len(index) == 0:\n",
    "        continue\n",
    "    index = random.sample(index, samplePerClass);\n",
    "    ind = ind + (index)\n",
    "#ind = random.sample(range(pp_s.shape[0]), numClass*samplePerClass);\n",
    "\n",
    "print(featTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours\n",
      "Precision: 0.703076923076923\n",
      "map: 0.9164123022217459\n"
     ]
    }
   ],
   "source": [
    "print('Ours')\n",
    "\n",
    "dimMask = numPerDim >0\n",
    "ff = featTest[:,dimMask]\n",
    "\n",
    "\n",
    "lModel = LabelSpreading(gamma=100)\n",
    "lModel.fit(ff[ind], gt_use[ind])\n",
    "label = lModel.predict(ff)\n",
    "score = np.max(lModel.predict_proba(ff), axis=1)\n",
    "\n",
    "\n",
    "print('Precision:', np.sum(label==gt)/label.size)\n",
    "print('map:', average_precision_score(label==gt, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "n_components=2519 must be between 0 and min(n_samples, n_features)=2048 with svd_solver='full'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5c7e56569bd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatTest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mf_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_norm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#f_pca = f_pca/np.linalg.norm(f_pca, axis =1, keepdims=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mlModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_pca\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_use\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0mC\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mordered\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse\u001b[0m \u001b[0;34m'np.ascontiguousarray'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \"\"\"\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;31m# Call different fits for either full or truncated SVD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'full'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'arpack'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'randomized'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_truncated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_svd_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit_full\u001b[0;34m(self, X, n_components)\u001b[0m\n\u001b[1;32m    433\u001b[0m                              \u001b[0;34m\"min(n_samples, n_features)=%r with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m                              \u001b[0;34m\"svd_solver='full'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m                              % (n_components, min(n_samples, n_features)))\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mn_components\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: n_components=2519 must be between 0 and min(n_samples, n_features)=2048 with svd_solver='full'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print('PCA')\n",
    "\n",
    "lModel = LabelSpreading(gamma=0.01) #20\n",
    "\n",
    "f_norm, _ = normIt(feat)\n",
    "\n",
    "pca = PCA(n_components=featTest.shape[1])\n",
    "f_pca = pca.fit_transform(f_norm)\n",
    "#f_pca = f_pca/np.linalg.norm(f_pca, axis =1, keepdims=True)\n",
    "lModel.fit(f_pca[ind], gt_use[ind])\n",
    "label = lModel.predict(f_pca)\n",
    "score = np.max(lModel.predict_proba(f_pca), axis=1)\n",
    "\n",
    "print('Precision:', np.sum(label==gt_use)/label.size)\n",
    "print('map:', average_precision_score(label==gt_use, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def test_feat(feat, labels, nBest= 1000):\n",
    "    num_feat = feat.shape[0]\n",
    "    d = pairwise_distances(feat)\n",
    "    ind = np.argsort(d, axis =1)\n",
    "    \n",
    "    err = np.zeros(num_feat)\n",
    "    \n",
    "    for i in range(num_feat):\n",
    "        l = labels[ind[i,:nBest+1]]      \n",
    "        err[i] = nBest - (sum((l-l[0]) == 0))+1\n",
    "                          \n",
    "    return err\n",
    "\n",
    "\n",
    "\n",
    "nBest = 500\n",
    "\n",
    "err = test_feat(ff[1::2], gt[1::2], nBest=nBest)\n",
    "print('ours')\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', ff.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err = test_feat(f, gt, nBest=nBest)\n",
    "\n",
    "print('original')\n",
    "\n",
    "\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', featTest.shape[1])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
