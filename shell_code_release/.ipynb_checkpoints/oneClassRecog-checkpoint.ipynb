{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "allFeat = np.load('/tf/notebooks/STL-10/danielFeat.npy')\n",
    "gtAll = np.load('/tf/notebooks/STL-10/danielGt.npy')\n",
    "\n",
    "# allFeat = np.load('/tf/notebooks/clusteringTree/stl_feat/feats_2048.npy')\n",
    "# gtAll = np.load('/tf/notebooks/clusteringTree/stl_feat/labels_2048.npy')-1\n",
    "\n",
    "\n",
    "\n",
    "#m = np.load('/tf/notebooks/Flickr11K/resNet50Mean.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from clusteringX2 import normIt\n",
    "\n",
    "#allFeat = allFeat/np.linalg.norm(allFeat, axis =1, keepdims=True)\n",
    "allFeat, _ = normIt(allFeat)\n",
    "\n",
    "\n",
    "numClass = max(gtAll)+1\n",
    "allMeans = np.zeros([numClass, allFeat.shape[1]])\n",
    "for i in range(numClass):\n",
    "    allMeans[i,:] = np.mean(allFeat[gtAll==i], axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestSplit_oneClass(allFeat, allGt, target, numSamples=300):\n",
    "    mask = np.where(allGt ==target)[0]\n",
    "    trainInd = random.sample(list(mask), numSamples)    \n",
    "    trainFeat = np.copy(allFeat[trainInd])\n",
    "    testFeat = allFeat.copy()\n",
    "    testFeat = np.delete(testFeat, trainInd, axis =0)\n",
    "    testGt = allGt.copy()\n",
    "    testGt = np.delete(testGt, trainInd, axis =0)\n",
    "    return trainFeat, testFeat, testGt\n",
    "\n",
    "def trainTestSplit_multiClass(allFeat, allGt, numSamples=300):\n",
    "    numClass = int(np.max(allGt)+1)\n",
    "    trainFeat = []\n",
    "    testFeat = allFeat.copy()\n",
    "    testGt = allGt.copy()\n",
    "    for i in range(numClass):\n",
    "        trainF, testFeat, testGt = trainTestSplit_oneClass(testFeat, testGt, i, numSamples=numSamples)\n",
    "        trainFeat.append(trainF)\n",
    "        \n",
    "    \n",
    "    return trainFeat, testFeat, testGt\n",
    "        \n",
    "\n",
    "trainFeat, testFeat, testGt = trainTestSplit_multiClass(allFeat, gtAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_neighbors_of_i(m_all, i):\n",
    "    neighbors = np.zeros(m_all.shape[0])\n",
    "    for j in range(m_all.shape[0]):\n",
    "        neighbors[j] = np.linalg.norm(m_all[i,:]-m_all[j,:])\n",
    "    return neighbors, np.argsort(neighbors)\n",
    "   \n",
    "    \n",
    "\n",
    "def stacked_classifer(train_feat, target, m_all):\n",
    "    _, neighs = sorted_neighbors_of_i(m_all, target)\n",
    "    classifers = []\n",
    "    current_shell = []\n",
    "    for i in neighs:\n",
    "        current_shell.append(i)\n",
    "        if len(current_shell)> 1:\n",
    "            m1 = np.mean(m_all[current_shell,:], axis =0, keepdims=True)\n",
    "            tf = train_feat-m1\n",
    "            tf = tf/np.linalg.norm(tf, axis =1, keepdims=True)\n",
    "            clf1 = OneClassSVM(gamma='auto').fit(tf)\n",
    "            classifers.append({'mean': m1, 'classifer': clf1})\n",
    "    return classifers\n",
    "\n",
    "def basic_classifer(train_feat):\n",
    "    classifers = []\n",
    "    m1 = 0\n",
    "    clf1 = OneClassSVM(gamma='auto').fit(train_feat)\n",
    "    classifers.append({'mean': m1, 'classifer': clf1})\n",
    "    return classifers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allClassifiers = []\n",
    "for i in range(numClass):\n",
    "    target = i\n",
    "    m_ex = np.concatenate([np.zeros([1, allMeans.shape[1]]), allMeans])\n",
    "    classifers = stacked_classifer(trainFeat[target], target+1, m_ex)\n",
    "    allClassifiers.append(classifers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_samples(classifers, test_feat):\n",
    "    score = np.zeros([test_feat.shape[0], len(classifers)])\n",
    "    for i in range(len(classifers)):\n",
    "        m = classifers[i]['mean']\n",
    "        tsf = test_feat-m\n",
    "        tsf = tsf/np.linalg.norm(tsf, keepdims=True, axis =1)\n",
    "        s = classifers[i]['classifer'].score_samples(tsf)   \n",
    "        score[:,i] = s\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros([testFeat.shape[0], numClass])\n",
    "\n",
    "for i in range(numClass):\n",
    "    s = score_samples(allClassifiers[i], testFeat)\n",
    "    s = np.mean(s, axis =1)\n",
    "    scores[:,i] = s\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.946\n"
     ]
    }
   ],
   "source": [
    "print('stacked')\n",
    "labelEst = np.argmax(scores, axis=1)\n",
    "print(1-np.mean(labelEst-testGt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "allClassifiersTrad = []\n",
    "for i in range(numClass):\n",
    "    target = i\n",
    "    classifers = basic_classifer(trainFeat[target])\n",
    "    allClassifiersTrad.append(classifers)\n",
    "    \n",
    "scoresTrad = np.zeros([testFeat.shape[0], numClass])\n",
    "\n",
    "for i in range(numClass):\n",
    "    s = score_samples(allClassifiersTrad[i], testFeat)\n",
    "    s = np.mean(s, axis =1)\n",
    "    scoresTrad[:,i] = s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basic\n",
      "0.9238\n"
     ]
    }
   ],
   "source": [
    "print('basic')\n",
    "labelEst = np.argmax(scoresTrad, axis=1)\n",
    "print(1-np.mean(labelEst-testGt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'donk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cfd52543731e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdonk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'donk' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "k = donk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=1e-05,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def listToFeat(feat):\n",
    "    newFeat = np.concatenate(feat, axis =0)\n",
    "    newGt = np.zeros(newFeat.shape[0], dtype = int)\n",
    "    cur = 0\n",
    "    for i in range(len(feat)):\n",
    "        newGt[cur:cur+feat[i].shape[0]] = i\n",
    "        cur = cur + feat[i].shape[0]\n",
    "    return newFeat, newGt\n",
    "\n",
    "trainFeat_, trainGt_ = listToFeat(trainFeat)\n",
    "clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "clf.fit(trainFeat_, trainGt_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm\n",
      "0.9755\n"
     ]
    }
   ],
   "source": [
    "print('svm')\n",
    "labelEst = clf.predict(testFeat)\n",
    "print(1-np.mean(labelEst-testGt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
