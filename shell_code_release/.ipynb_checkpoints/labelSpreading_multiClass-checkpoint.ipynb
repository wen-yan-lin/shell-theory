{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "\n",
    "#allFeat = np.load('/tf/notebooks/clusteringTree/stl_feat/feats_2048.npy')\n",
    "#gtAll = np.load('/tf/notebooks/clusteringTree/stl_feat/labels_2048.npy')-1|\n",
    "\n",
    "# allFeat = np.load('/tf/notebooks/STL-10/danielFeat.npy')\n",
    "# gtAll = np.load('/tf/notebooks/STL-10/danielGt.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from clusteringX2 import normIt\n",
    "from clusteringX2 import clusterModel\n",
    "from clusteringX2 import train_step3\n",
    "from clusteringX2 import train_step4\n",
    "\n",
    "\n",
    "def clustering(feat, numClass=60, thres=0.1, iter_=1000):\n",
    "    \n",
    "    denom = 0.1\n",
    "    #feat, m = normIt(feat)\n",
    "    m = np.zeros(feat.shape[1])\n",
    "    \n",
    "    # initilization\n",
    "    kmeans = KMeans(n_clusters=numClass, random_state=0).fit(feat)\n",
    "    labelK = kmeans.predict(feat)\n",
    "    means =np.zeros([numClass, feat.shape[1]])\n",
    "\n",
    "    for i in range(numClass):\n",
    "        mask = labelK == i\n",
    "        means[i,:] = np.mean(feat[mask,:], axis =0)\n",
    "\n",
    "    sigInit = np.zeros([numClass])\n",
    "    for i in range(numClass):\n",
    "        mask = np.logical_not(labelK == i)\n",
    "        sigInit[i] = np.mean(np.matmul(feat[mask,:], np.transpose(means[i,:])))\n",
    "    model = clusterModel(means.transpose(), sigInit)\n",
    "    train_step4(model, feat.astype(\"float32\"), iter=iter_, denom=denom)\n",
    "    \n",
    "    \n",
    "    \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    s = np.max(c, axis=1)\n",
    "    t = np.mean(s)\n",
    "    mask = s > t*0.5\n",
    "    \n",
    "    \n",
    "    train_step4(model, feat[mask,:].astype(\"float32\"), iter=iter_, denom=denom)\n",
    "    \n",
    "    \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    s = np.max(c, axis=1)\n",
    "    t = np.mean(s)\n",
    "    mask = s > t*0.5\n",
    "    train_step4(model, feat[mask,:].astype(\"float32\"), iter=iter_, denom=denom)\n",
    "\n",
    " \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    labels = np.argmax(c, axis =1)\n",
    "    mask_ = np.zeros(numClass, dtype=bool)\n",
    "        \n",
    "    for i in range(numClass):\n",
    "        if np.sum(labels==i)>0:\n",
    "            mask_[i] = 1\n",
    "    w = model.w.numpy()\n",
    "    sig = model.sig.numpy()\n",
    "    w = w[:,mask_]\n",
    "    sig = sig[mask_]\n",
    "            \n",
    "\n",
    "    return w, sig, m, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, mask=None, w=None, sig=None, m=None):\n",
    "        self.mask = mask\n",
    "        self.w = w\n",
    "        self.sig = sig\n",
    "        self.m = m\n",
    "        self.listOfChildren = []\n",
    "            \n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.nodeList = []\n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self):\n",
    "        self.numLayers = 0\n",
    "        self.listOfLayers = []\n",
    "        self.numNodes = 0\n",
    "        self.listOfNodes = []\n",
    "        \n",
    "    def addNode(self, c):\n",
    "        self.listOfNodes.append(c)\n",
    "        self.numNodes = self.numNodes + 1\n",
    "        \n",
    "    def addLayer(self, c):\n",
    "        self.listOfLayers.append(c)\n",
    "        self.numLayers = self.numLayers + 1\n",
    "\n",
    "    \n",
    "def startTree(allFeat, numClass=60):\n",
    "    tree = Tree()    \n",
    "    w, sig, m, inMask = clustering(allFeat, numClass)\n",
    "    mask = np.ones(allFeat.shape[0], dtype=bool)\n",
    "    #mask[np.logical_not(inMask)] = 0\n",
    "    n = Node(mask, w, sig, m)\n",
    "\n",
    "    tree.addNode(n)\n",
    "    newLayer = Layer()\n",
    "    newLayer.nodeList.append(tree.numNodes-1)\n",
    "    tree.addLayer(newLayer)\n",
    "    \n",
    "    return tree\n",
    "#allFeat = allFeat/np.linalg.norm(allFeat, axis=1, keepdims=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "    \n",
    "def dataProjection(feat, node):\n",
    "    x, _ = normIt(feat, node.m) \n",
    "    s = np.linalg.norm(node.w, axis =0, keepdims=True)\n",
    "    return (np.matmul(x, node.w) - node.sig), s\n",
    "\n",
    "\n",
    "def extendTree(tree, allFeat, numClass=2, clusteringThreshold=100):\n",
    "    newLayer = Layer()\n",
    "    lastLayer = tree.listOfLayers[-1]\n",
    "    for nodeIndex in lastLayer.nodeList:\n",
    "        node = tree.listOfNodes[nodeIndex]\n",
    "        curFeat = allFeat[node.mask,:]\n",
    "        score, _ = dataProjection(curFeat, node)\n",
    "        \n",
    "        clusterInd = np.argmax(score, axis =1)\n",
    "        curInd = np.where(node.mask)[0]\n",
    "\n",
    "        #########################################\n",
    "        #_, m_sub = normIt(curFeat)\n",
    "        #########################################\n",
    "        \n",
    "        for i in range(score.shape[1]):\n",
    "            subMask = clusterInd == i\n",
    "            if sum(subMask) > clusteringThreshold:\n",
    "                \n",
    "                newMask =  np.zeros(allFeat.shape[0], dtype=bool)\n",
    "                newMask[curInd[subMask]] = 1\n",
    "                \n",
    "                \n",
    "                #########################################\n",
    "                #nF, m_sub = normIt(allFeat[newMask,:])\n",
    "                #########################################\n",
    "\n",
    "                nF, m_sub = normIt(allFeat[newMask,:], m_sub)\n",
    "                #nF = allFeat[newMask,:]\n",
    "                w, sig, _, inMask = clustering(nF, numClass)\n",
    "\n",
    "                print(w.shape, sum(newMask))\n",
    "                if w.shape[1]>=2:\n",
    "                    n = Node(newMask, w, sig, m_sub)\n",
    "                    tree.addNode(n)\n",
    "                    newLayer.nodeList.append(tree.numNodes-1)\n",
    "                    node.listOfChildren.append(tree.numNodes-1)\n",
    "                else:\n",
    "                    node.listOfChildren.append(-1)\n",
    "            else:\n",
    "                node.listOfChildren.append(-1)\n",
    "    tree.addLayer(newLayer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2oneHot(labels):\n",
    "    b = np.zeros((labels.size, labels.max()+1), dtype=bool)\n",
    "    b[np.arange(labels.size),labels] = 1\n",
    "    return b\n",
    "\n",
    "\n",
    "\n",
    "def projectXX(feat, tree, maxClus=60, unit_vector=False, scale2data=False, verboise=True):\n",
    "    projectionSpace = np.zeros([feat.shape[0], tree.numNodes*maxClus])\n",
    "    maskAll = np.zeros([feat.shape[0], tree.numNodes*maxClus])\n",
    "\n",
    "    cur = 0    \n",
    "    for i, l in enumerate(tree.listOfLayers):\n",
    "        for nIndex in l.nodeList:\n",
    "            n = tree.listOfNodes[nIndex]\n",
    "            f, s = dataProjection(feat, n)\n",
    "            numDim = f.shape[1]\n",
    "            lab = np.argmax(f, axis =1)\n",
    "            maskAll[:,cur:cur+numDim] = label2oneHot(lab)\n",
    "            projectionSpace[:,cur:cur+numDim] = f\n",
    "            cur = cur + numDim\n",
    "    projectionSpace = projectionSpace[:,:cur]\n",
    "    maskAll = maskAll[:,:cur]\n",
    "    \n",
    "    return projectionSpace, maskAll\n",
    "\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2path(mask, tree):\n",
    "    pathNode = -1*np.ones([mask.shape[0], len(tree.listOfLayers)+1], dtype=int)\n",
    "    pathNode[:,0] = 0\n",
    "    \n",
    "    pathDim = -1*np.ones([mask.shape[0], len(tree.listOfLayers)+1], dtype=int)\n",
    "\n",
    "    \n",
    "    cur = 0\n",
    "    for i, l in enumerate(tree.listOfLayers):\n",
    "        print('layer:',i)\n",
    "        \n",
    "        for nIndex in l.nodeList:           \n",
    "            \n",
    "            n = tree.listOfNodes[nIndex]\n",
    "            dim = n.w.shape[1]\n",
    "            \n",
    "            \n",
    "            allCur = pathNode[:,i] == nIndex # in node nIndex\n",
    "            sub_mask = mask[:,cur:cur+dim] # with dimenions\n",
    "            ind = np.argmax(sub_mask)\n",
    "\n",
    "            for k in range(dim):\n",
    "                m = np.logical_and(allCur, sub_mask[:,k])\n",
    "                pathDim[m, i] = cur + k \n",
    "\n",
    "            \n",
    "            \n",
    "            if not n.listOfChildren:\n",
    "                cur = cur + dim\n",
    "                continue\n",
    "\n",
    "                        \n",
    "            \n",
    "            for k in range(dim):\n",
    "                m = np.logical_and(allCur, sub_mask[:,k])\n",
    "                pathNode[m, i+1] = n.listOfChildren[k]\n",
    "                \n",
    "                \n",
    "            cur = cur + dim\n",
    "            \n",
    "            \n",
    "    return pathNode, pathDim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classScore(pathDim, ff, dim):\n",
    "    numPts = pathDim.shape[0]\n",
    "    score = np.zeros(pathDim.shape[0])\n",
    "    \n",
    "    for i in range(numPts):\n",
    "        for j in range(dim+1):\n",
    "            if pathDim[i,j]>=0:\n",
    "                score[i] = score[i] + ff[i, pathDim[i,j]]\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "allFeat = np.load('/tf/notebooks/STL-10/danielFeat.npy')\n",
    "gtAll = np.load('/tf/notebooks/STL-10/danielGt.npy')\n",
    "    \n",
    "allFeat, _ = normIt(allFeat)\n",
    "mask = np.logical_or(gtAll==0, gtAll==1)\n",
    "\n",
    "\n",
    "outlier = random.sample(range(5*1300,10*1300),600)\n",
    "\n",
    "\n",
    "feat = allFeat[mask,:]\n",
    "feat = np.concatenate([feat, allFeat[outlier]], axis=0)\n",
    "gt = gtAll[mask]\n",
    "gt = np.concatenate([gt, gtAll[outlier]], axis=0)\n",
    "\n",
    "feat = allFeat\n",
    "gt = gtAll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = feat\n",
    "gt = gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 6) 2621\n",
      "(2048, 3) 1355\n",
      "(2048, 5) 1283\n",
      "(2048, 2) 716\n",
      "(2048, 1) 651\n",
      "(2048, 3) 1296\n",
      "(2048, 6) 1304\n",
      "(2048, 7) 1979\n",
      "(2048, 11) 1795\n",
      "(2048, 12) 2611\n",
      "(2048, 48) 1353\n",
      "(2048, 39) 1279\n",
      "(2048, 51) 714\n",
      "(2048, 40) 1293\n",
      "(2048, 52) 1298\n",
      "(2048, 1) 418\n",
      "(2048, 38) 1550\n",
      "(2048, 50) 834\n",
      "(2048, 22) 407\n",
      "(2048, 32) 168\n",
      "(2048, 44) 264\n",
      "(2048, 43) 724\n",
      "(2048, 44) 116\n",
      "(2048, 39) 621\n",
      "(2048, 53) 327\n",
      "(2048, 40) 657\n",
      "(2048, 53) 162\n",
      "(2048, 54) 175\n",
      "(2048, 47) 104\n",
      "(2048, 52) 168\n",
      "(2048, 39) 196\n",
      "(2048, 53) 233\n",
      "(2048, 55) 241\n",
      "(2048, 57) 188\n",
      "(2048, 52) 201\n",
      "(2048, 54) 119\n",
      "(2048, 46) 195\n",
      "(2048, 58) 302\n",
      "(2048, 51) 173\n",
      "(2048, 46) 115\n",
      "(2048, 45) 172\n",
      "(2048, 57) 296\n",
      "(2048, 49) 800\n",
      "(2048, 57) 112\n",
      "(2048, 53) 330\n",
      "(2048, 58) 358\n",
      "(2048, 53) 118\n",
      "(2048, 49) 124\n",
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n",
      "layer: 3\n"
     ]
    }
   ],
   "source": [
    "f = feat\n",
    "\n",
    "tree2 = startTree(f, numClass=60)\n",
    "extendTree(tree2, f, numClass=60)\n",
    "extendTree(tree2, f, numClass=60)\n",
    "extendTree(tree2, f, numClass=60)\n",
    "ff2, mask2 = projectXX(feat, tree2)\n",
    "pathNode2, pathDim2 = mask2path(mask2, tree2)\n",
    "s2 = classScore(pathDim2, ff2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <__main__.Node object at 0x7fd4364a8c50>\n",
      "1 <__main__.Node object at 0x7fd42fd87978>\n",
      "2 <__main__.Node object at 0x7fd4204e6e80>\n",
      "3 <__main__.Node object at 0x7fd42041cac8>\n",
      "4 <__main__.Node object at 0x7fd42040db38>\n",
      "5 <__main__.Node object at 0x7fd420263d30>\n",
      "6 <__main__.Node object at 0x7fd42030cc88>\n",
      "7 <__main__.Node object at 0x7fd42014cdd8>\n",
      "8 <__main__.Node object at 0x7fd420069ba8>\n",
      "9 <__main__.Node object at 0x7fd410183a58>\n",
      "10 <__main__.Node object at 0x7fd41012a390>\n",
      "11 <__main__.Node object at 0x7fd41015a320>\n",
      "12 <__main__.Node object at 0x7fd3e81dc710>\n",
      "13 <__main__.Node object at 0x7fd410046f98>\n",
      "14 <__main__.Node object at 0x7fd3e8176a20>\n",
      "15 <__main__.Node object at 0x7fd3e8176d68>\n",
      "16 <__main__.Node object at 0x7fd390788f60>\n",
      "17 <__main__.Node object at 0x7fd390705ba8>\n",
      "18 <__main__.Node object at 0x7fd39066c908>\n",
      "19 <__main__.Node object at 0x7fd39058dfd0>\n",
      "20 <__main__.Node object at 0x7fd390615160>\n",
      "21 <__main__.Node object at 0x7fd39075fda0>\n",
      "22 <__main__.Node object at 0x7fd3906f0710>\n",
      "23 <__main__.Node object at 0x7fd39037ad68>\n",
      "24 <__main__.Node object at 0x7fd39033ca90>\n",
      "25 <__main__.Node object at 0x7fd390284908>\n",
      "26 <__main__.Node object at 0x7fd3902a7b00>\n",
      "27 <__main__.Node object at 0x7fd390374dd8>\n",
      "28 <__main__.Node object at 0x7fd390221390>\n",
      "29 <__main__.Node object at 0x7fd3903a2b70>\n",
      "30 <__main__.Node object at 0x7fd390147eb8>\n",
      "31 <__main__.Node object at 0x7fd3900bba90>\n",
      "32 <__main__.Node object at 0x7fd3900c8e10>\n",
      "33 <__main__.Node object at 0x7fd390132860>\n",
      "34 <__main__.Node object at 0x7fd3900b5320>\n",
      "35 <__main__.Node object at 0x7fd39019d588>\n",
      "36 <__main__.Node object at 0x7fd37077cc50>\n",
      "37 <__main__.Node object at 0x7fd370779dd8>\n",
      "38 <__main__.Node object at 0x7fd37074df28>\n",
      "39 <__main__.Node object at 0x7fd3706c67f0>\n",
      "40 <__main__.Node object at 0x7fd370691fd0>\n",
      "41 <__main__.Node object at 0x7fd3706b8400>\n",
      "42 <__main__.Node object at 0x7fd3705e2f28>\n",
      "43 <__main__.Node object at 0x7fd3705c8e48>\n",
      "44 <__main__.Node object at 0x7fd3705a5f60>\n",
      "45 <__main__.Node object at 0x7fd3705c8940>\n",
      "46 <__main__.Node object at 0x7fd370525f60>\n"
     ]
    }
   ],
   "source": [
    "def projectTree2(feat, tree, maxClus=60, unit_vector=True, scale2data=True, verboise=True):\n",
    "    \n",
    "    projectionSpace = np.zeros([feat.shape[0], tree.numNodes*maxClus])\n",
    "    \n",
    "    cur = 0\n",
    "    \n",
    "    for i, n in enumerate(tree.listOfNodes):\n",
    "        \n",
    "        f, _ = dataProjection(feat, n)\n",
    "        numDim = f.shape[1]\n",
    "        if unit_vector:\n",
    "            f_ = np.concatenate([f, 10*np.ones([f.shape[0],1])], axis =1)\n",
    "            f_ = f_/np.linalg.norm(f_, axis =1, keepdims=True)\n",
    "            f = f_[:,:numDim]\n",
    "        if scale2data:\n",
    "            f = f*np.sum(n.mask)/n.mask.size \n",
    "        projectionSpace[:, cur:cur+numDim] = f\n",
    "        cur = cur+numDim\n",
    "        \n",
    "        if verboise == True:\n",
    "            print(i, n)\n",
    "    projectionSpace = projectionSpace[:,:cur]\n",
    "    return projectionSpace\n",
    "        \n",
    "featTest = projectTree2(feat, tree2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.621e+03 1.355e+03 1.283e+03 ... 3.000e+00 1.000e+00 1.000e+00]\n"
     ]
    }
   ],
   "source": [
    "def getNumPerClass(pathDim):\n",
    "    numClass = np.max(pathDim)+1\n",
    "    numPerClass = np.zeros(numClass)\n",
    "    for i in range(numClass):\n",
    "        numPerClass[i] = np.sum(pathDim==i)\n",
    "    return numPerClass\n",
    "\n",
    "numPerDim = getNumPerClass(pathDim2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13000, 1837)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "# setup\n",
    "gt_use = gt.copy()\n",
    "#gt_use = gtCoarse.copy()\n",
    "#########\n",
    "\n",
    "\n",
    "samplePerClass = 1000\n",
    "numClass = int(max(gt_use)+1)\n",
    "ind = []\n",
    "for i in range(numClass):\n",
    "    index = list(np.where(gt_use==i)[0])\n",
    "    if len(index) == 0:\n",
    "        continue\n",
    "    index = random.sample(index, samplePerClass);\n",
    "    ind = ind + (index)\n",
    "#ind = random.sample(range(pp_s.shape[0]), numClass*samplePerClass);\n",
    "\n",
    "print(featTest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours\n",
      "Precision: 0.9866153846153846\n",
      "map: 0.9989625653239259\n"
     ]
    }
   ],
   "source": [
    "print('Ours')\n",
    "\n",
    "dimMask = numPerDim >0\n",
    "ff = featTest[:,dimMask]\n",
    "\n",
    "\n",
    "lModel = LabelSpreading(gamma=100)\n",
    "lModel.fit(ff[ind], gt_use[ind])\n",
    "label = lModel.predict(ff)\n",
    "score = np.max(lModel.predict_proba(ff), axis=1)\n",
    "\n",
    "\n",
    "print('Precision:', np.sum(label==gt)/label.size)\n",
    "print('map:', average_precision_score(label==gt, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "Precision: 0.9263846153846154\n",
      "map: 0.9752950274031749\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print('PCA')\n",
    "\n",
    "lModel = LabelSpreading(gamma=0.01) #20\n",
    "\n",
    "f_norm, _ = normIt(feat)\n",
    "\n",
    "pca = PCA(n_components=featTest.shape[1])\n",
    "f_pca = pca.fit_transform(f_norm)\n",
    "#f_pca = f_pca/np.linalg.norm(f_pca, axis =1, keepdims=True)\n",
    "lModel.fit(f_pca[ind], gt_use[ind])\n",
    "label = lModel.predict(f_pca)\n",
    "score = np.max(lModel.predict_proba(f_pca), axis=1)\n",
    "\n",
    "print('Precision:', np.sum(label==gt_use)/label.size)\n",
    "print('map:', average_precision_score(label==gt_use, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ours\n",
      "average error of  78.881462 from 500 nearest neighbors\n",
      "num dimenions: 1837\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def test_feat(feat, labels, nBest= 1000):\n",
    "    num_feat = feat.shape[0]\n",
    "    d = pairwise_distances(feat)\n",
    "    ind = np.argsort(d, axis =1)\n",
    "    \n",
    "    err = np.zeros(num_feat)\n",
    "    \n",
    "    for i in range(num_feat):\n",
    "        l = labels[ind[i,:nBest+1]]      \n",
    "        err[i] = nBest - (sum((l-l[0]) == 0))+1\n",
    "                          \n",
    "    return err\n",
    "\n",
    "\n",
    "\n",
    "nBest = 500\n",
    "\n",
    "err = test_feat(ff, gt, nBest=nBest)\n",
    "print('ours')\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', ff.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original\n",
      "average error of  96.136615 from 500 nearest neighbors\n",
      "num dimenions: 1837\n"
     ]
    }
   ],
   "source": [
    "err = test_feat(f, gt, nBest=nBest)\n",
    "\n",
    "print('original')\n",
    "\n",
    "\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', featTest.shape[1])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
