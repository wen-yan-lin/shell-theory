{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "\n",
    "#allFeat = np.load('/tf/notebooks/clusteringTree/stl_feat/feats_2048.npy')\n",
    "#gtAll = np.load('/tf/notebooks/clusteringTree/stl_feat/labels_2048.npy')-1|\n",
    "\n",
    "# allFeat = np.load('/tf/notebooks/STL-10/danielFeat.npy')\n",
    "# gtAll = np.load('/tf/notebooks/STL-10/danielGt.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from clusteringX2 import normIt\n",
    "from clusteringX2 import clusterModel\n",
    "from clusteringX2 import train_step3\n",
    "from clusteringX2 import train_step4\n",
    "\n",
    "\n",
    "def clustering(feat, numClass=60, thres=0.1, iter_=1000):\n",
    "    \n",
    "    denom = 0.1\n",
    "    #feat, m = normIt(feat)\n",
    "    m = np.zeros(feat.shape[1])\n",
    "    \n",
    "    # initilization\n",
    "    kmeans = KMeans(n_clusters=numClass, random_state=0).fit(feat)\n",
    "    labelK = kmeans.predict(feat)\n",
    "    means =np.zeros([numClass, feat.shape[1]])\n",
    "\n",
    "    for i in range(numClass):\n",
    "        mask = labelK == i\n",
    "        means[i,:] = np.mean(feat[mask,:], axis =0)\n",
    "\n",
    "    sigInit = np.zeros([numClass])\n",
    "    for i in range(numClass):\n",
    "        mask = np.logical_not(labelK == i)\n",
    "        sigInit[i] = np.mean(np.matmul(feat[mask,:], np.transpose(means[i,:])))\n",
    "    model = clusterModel(means.transpose(), sigInit)\n",
    "    train_step4(model, feat.astype(\"float32\"), iter=iter_, denom=denom)\n",
    "    \n",
    "    \n",
    "    \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    s = np.max(c, axis=1)\n",
    "    t = np.mean(s)\n",
    "    mask = s > t*0.5\n",
    "    \n",
    "    \n",
    "    train_step4(model, feat[mask,:].astype(\"float32\"), iter=iter_, denom=denom)\n",
    "    \n",
    "    \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    s = np.max(c, axis=1)\n",
    "    t = np.mean(s)\n",
    "    mask = s > t*0.5\n",
    "    train_step4(model, feat[mask,:].astype(\"float32\"), iter=iter_, denom=denom)\n",
    "\n",
    " \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    labels = np.argmax(c, axis =1)\n",
    "    mask_ = np.zeros(numClass, dtype=bool)\n",
    "        \n",
    "    for i in range(numClass):\n",
    "        if np.sum(labels==i)>0:\n",
    "            mask_[i] = 1\n",
    "    w = model.w.numpy()\n",
    "    sig = model.sig.numpy()\n",
    "    w = w[:,mask_]\n",
    "    sig = sig[mask_]\n",
    "            \n",
    "\n",
    "    return w, sig, m, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, mask=None, w=None, sig=None, m=None):\n",
    "        self.mask = mask\n",
    "        self.w = w\n",
    "        self.sig = sig\n",
    "        self.m = m\n",
    "        self.listOfChildren = []\n",
    "            \n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.nodeList = []\n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self):\n",
    "        self.numLayers = 0\n",
    "        self.listOfLayers = []\n",
    "        self.numNodes = 0\n",
    "        self.listOfNodes = []\n",
    "        \n",
    "    def addNode(self, c):\n",
    "        self.listOfNodes.append(c)\n",
    "        self.numNodes = self.numNodes + 1\n",
    "        \n",
    "    def addLayer(self, c):\n",
    "        self.listOfLayers.append(c)\n",
    "        self.numLayers = self.numLayers + 1\n",
    "\n",
    "    \n",
    "def startTree(allFeat, numClass=60):\n",
    "    tree = Tree()    \n",
    "    w, sig, m, inMask = clustering(allFeat, numClass)\n",
    "    mask = np.ones(allFeat.shape[0], dtype=bool)\n",
    "    #mask[np.logical_not(inMask)] = 0\n",
    "    n = Node(mask, w, sig, m)\n",
    "\n",
    "    tree.addNode(n)\n",
    "    newLayer = Layer()\n",
    "    newLayer.nodeList.append(tree.numNodes-1)\n",
    "    tree.addLayer(newLayer)\n",
    "    \n",
    "    return tree\n",
    "#allFeat = allFeat/np.linalg.norm(allFeat, axis=1, keepdims=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "    \n",
    "def dataProjection(feat, node):\n",
    "    x, _ = normIt(feat, node.m) \n",
    "    s = np.linalg.norm(node.w, axis =0, keepdims=True)\n",
    "    return (np.matmul(x, node.w) - node.sig), s\n",
    "\n",
    "\n",
    "def extendTree(tree, allFeat, numClass=2, clusteringThreshold=100):\n",
    "    newLayer = Layer()\n",
    "    lastLayer = tree.listOfLayers[-1]\n",
    "    for nodeIndex in lastLayer.nodeList:\n",
    "        node = tree.listOfNodes[nodeIndex]\n",
    "        curFeat = allFeat[node.mask,:]\n",
    "        score, _ = dataProjection(curFeat, node)\n",
    "        \n",
    "        clusterInd = np.argmax(score, axis =1)\n",
    "        curInd = np.where(node.mask)[0]\n",
    "\n",
    "        #########################################\n",
    "        #_, m_sub = normIt(curFeat)\n",
    "        #########################################\n",
    "        \n",
    "        for i in range(score.shape[1]):\n",
    "            subMask = clusterInd == i\n",
    "            if sum(subMask) > clusteringThreshold:\n",
    "                \n",
    "                newMask =  np.zeros(allFeat.shape[0], dtype=bool)\n",
    "                newMask[curInd[subMask]] = 1\n",
    "                \n",
    "                \n",
    "                #########################################\n",
    "                nF, m_sub = normIt(allFeat[newMask,:])\n",
    "                #########################################\n",
    "\n",
    "                #nF, m_sub = normIt(allFeat[newMask,:], m_sub)\n",
    "                #nF = allFeat[newMask,:]\n",
    "                w, sig, _, inMask = clustering(nF, numClass)\n",
    "\n",
    "                print(w.shape, sum(newMask))\n",
    "                if w.shape[1]>=2:\n",
    "                    n = Node(newMask, w, sig, m_sub)\n",
    "                    tree.addNode(n)\n",
    "                    newLayer.nodeList.append(tree.numNodes-1)\n",
    "                    node.listOfChildren.append(tree.numNodes-1)\n",
    "                else:\n",
    "                    node.listOfChildren.append(-1)\n",
    "            else:\n",
    "                node.listOfChildren.append(-1)\n",
    "    tree.addLayer(newLayer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2oneHot(labels):\n",
    "    b = np.zeros((labels.size, labels.max()+1), dtype=bool)\n",
    "    b[np.arange(labels.size),labels] = 1\n",
    "    return b\n",
    "\n",
    "\n",
    "\n",
    "def projectXX(feat, tree, maxClus=60, unit_vector=False, scale2data=False, verboise=True):\n",
    "    projectionSpace = np.zeros([feat.shape[0], tree.numNodes*maxClus])\n",
    "    maskAll = np.zeros([feat.shape[0], tree.numNodes*maxClus])\n",
    "\n",
    "    cur = 0    \n",
    "    for i, l in enumerate(tree.listOfLayers):\n",
    "        for nIndex in l.nodeList:\n",
    "            n = tree.listOfNodes[nIndex]\n",
    "            f, s = dataProjection(feat, n)\n",
    "            numDim = f.shape[1]\n",
    "            lab = np.argmax(f, axis =1)\n",
    "            maskAll[:,cur:cur+numDim] = label2oneHot(lab)\n",
    "            projectionSpace[:,cur:cur+numDim] = f\n",
    "            cur = cur + numDim\n",
    "    projectionSpace = projectionSpace[:,:cur]\n",
    "    maskAll = maskAll[:,:cur]\n",
    "    \n",
    "    return projectionSpace, maskAll\n",
    "\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2path(mask, tree):\n",
    "    pathNode = -1*np.ones([mask.shape[0], len(tree.listOfLayers)+1], dtype=int)\n",
    "    pathNode[:,0] = 0\n",
    "    \n",
    "    pathDim = -1*np.ones([mask.shape[0], len(tree.listOfLayers)+1], dtype=int)\n",
    "\n",
    "    \n",
    "    cur = 0\n",
    "    for i, l in enumerate(tree.listOfLayers):\n",
    "        print('layer:',i)\n",
    "        \n",
    "        for nIndex in l.nodeList:           \n",
    "            \n",
    "            n = tree.listOfNodes[nIndex]\n",
    "            dim = n.w.shape[1]\n",
    "            \n",
    "            \n",
    "            allCur = pathNode[:,i] == nIndex # in node nIndex\n",
    "            sub_mask = mask[:,cur:cur+dim] # with dimenions\n",
    "            ind = np.argmax(sub_mask)\n",
    "\n",
    "            for k in range(dim):\n",
    "                m = np.logical_and(allCur, sub_mask[:,k])\n",
    "                pathDim[m, i] = cur + k \n",
    "\n",
    "            \n",
    "            \n",
    "            if not n.listOfChildren:\n",
    "                cur = cur + dim\n",
    "                continue\n",
    "\n",
    "                        \n",
    "            \n",
    "            for k in range(dim):\n",
    "                m = np.logical_and(allCur, sub_mask[:,k])\n",
    "                pathNode[m, i+1] = n.listOfChildren[k]\n",
    "                \n",
    "                \n",
    "            cur = cur + dim\n",
    "            \n",
    "            \n",
    "    return pathNode, pathDim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classScore(pathDim, ff, dim):\n",
    "    numPts = pathDim.shape[0]\n",
    "    score = np.zeros(pathDim.shape[0])\n",
    "    \n",
    "    for i in range(numPts):\n",
    "        for j in range(dim+1):\n",
    "            if pathDim[i,j]>=0:\n",
    "                score[i] = score[i] + ff[i, pathDim[i,j]]\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting umap.learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/92/36bac74962b424870026cb0b42cec3d5b6f4afa37d81818475d8762f9255/umap-learn-0.3.10.tar.gz (40kB)\n",
      "\u001b[K     |████████████████████████████████| 40kB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.6/dist-packages (from umap.learn) (1.17.2)\n",
      "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from umap.learn) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from umap.learn) (1.4.1)\n",
      "Collecting numba>=0.37 (from umap.learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/49/61522f34b1333aa4e9aa02005dc0774d25bd234400dff718b16615d6a744/numba-0.48.0-cp36-cp36m-manylinux1_x86_64.whl (2.5MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5MB 2.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->umap.learn) (0.14.1)\n",
      "Collecting llvmlite<0.32.0,>=0.31.0dev0 (from numba>=0.37->umap.learn)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/bb/60d4033d56c9da36490af19caa6c794b72b8aef6f792fdfa8cb95d11e419/llvmlite-0.31.0-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n",
      "\u001b[K     |████████████████████████████████| 20.2MB 82.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.37->umap.learn) (41.2.0)\n",
      "Building wheels for collected packages: umap.learn\n",
      "  Building wheel for umap.learn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for umap.learn: filename=umap_learn-0.3.10-cp36-none-any.whl size=44352 sha256=a2b2edf5ce9828045a5941254aef674aabe4511bd5ef4fa0cb0b43dc5c9bca2c\n",
      "  Stored in directory: /root/.cache/pip/wheels/d0/f8/d5/8e3af3ee957feb9b403a060ebe72f7561887fef9dea658326e\n",
      "Successfully built umap.learn\n",
      "Installing collected packages: llvmlite, numba, umap.learn\n",
      "Successfully installed llvmlite-0.31.0 numba-0.48.0 umap.learn\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Uninstalling enum34-1.1.6:\n",
      "  Successfully uninstalled enum34-1.1.6\n",
      "Collecting hdbscan\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/2f/2423d844072f007a74214c1adc46260e45f034bb1679ccadfbb8a601f647/hdbscan-0.8.26.tar.gz (4.7MB)\n",
      "\u001b[K     |████████████████████████████████| 4.7MB 916kB/s eta 0:00:01\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting cython>=0.27 (from hdbscan)\n",
      "  Using cached https://files.pythonhosted.org/packages/9e/cc/60984d76cde8cb76d7a897fc0dfb316c6c2f8c753cdf468a9d5773376b84/Cython-0.29.16-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.14.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.17.2)\n",
      "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.4.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from hdbscan) (1.11.0)\n",
      "Building wheels for collected packages: hdbscan\n",
      "  Building wheel for hdbscan (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hdbscan: filename=hdbscan-0.8.26-cp36-cp36m-linux_x86_64.whl size=2361267 sha256=918a5ef2342bc4ac1896b36520bc857677b76015dd437009b501d94f2f8afaf4\n",
      "  Stored in directory: /root/.cache/pip/wheels/82/38/41/372f034d8abd271ef7787a681e0a47fc05d472683a7eb088ed\n",
      "Successfully built hdbscan\n",
      "Installing collected packages: cython, hdbscan\n",
      "Successfully installed cython-0.29.16 hdbscan-0.8.26\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pip3 install umap.learn\n",
    "\n",
    "!pip uninstall -y enum34\n",
    "\n",
    "! pip3 install hdbscan\n",
    "\n",
    "import umap\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9742659763313609"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "allFeat = np.load('/tf/notebooks/STL-10/danielFeat.npy')\n",
    "gtAll = np.load('/tf/notebooks/STL-10/danielGt.npy')\n",
    "\n",
    "# allFeat = np.load('/tf/notebooks/clusteringTree/stl_feat/feats_2048.npy')\n",
    "# gtAll = np.load('/tf/notebooks/clusteringTree/stl_feat/labels_2048.npy')-1\n",
    "\n",
    "\n",
    "\n",
    "#m = np.load('/tf/notebooks/Flickr11K/resNet50Mean.npy')\n",
    "#allFeat, _ = normIt(allFeat)\n",
    "\n",
    "#allFeat = allFeat - m.reshape([1,m.size])\n",
    "#allFeat = allFeat/np.linalg.norm(allFeat, axis =1, keepdims=True)\n",
    "\n",
    "\n",
    "\n",
    "mask = np.logical_or(gtAll==3, gtAll==4)\n",
    "#mask = np.logical_or(gtAll==0, gtAll==1)\n",
    "mask = np.logical_or(mask, gtAll==5)\n",
    "\n",
    "\n",
    "#outlier = random.sample(range(5*1300,10*1300),100)\n",
    "\n",
    "\n",
    "feat = allFeat[mask,:]\n",
    "#feat = np.concatenate([feat, allFeat[outlier]], axis=0)\n",
    "gt = gtAll[mask]\n",
    "#gt = np.concatenate([gt, gtAll[outlier]], axis=0)\n",
    "\n",
    "f = feat[0:1500:2]\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "# f, m = normIt(f)\n",
    "# feat, _ = normIt(feat, m)\n",
    "\n",
    "\n",
    "# feat, m = normIt(feat)\n",
    "# f, _ = normIt(f, m)\n",
    "\n",
    "\n",
    "\n",
    "# _, m = normIt(allFeat)\n",
    "# f, _ = normIt(f, m)\n",
    "# feat, _ = normIt(feat, m)\n",
    "\n",
    "\n",
    "i = 0\n",
    "true = np.zeros(feat.shape[0], dtype=bool)\n",
    "true[i*2600:(i+1)*2600] = 1\n",
    "\n",
    "\n",
    "clf = OneClassSVM().fit(f)\n",
    "oc_score = clf.score_samples(feat)\n",
    "\n",
    "roc_auc_score(true, oc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'donk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-cfd52543731e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdonk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'donk' is not defined"
     ]
    }
   ],
   "source": [
    "k = donk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = np.argsort(-oc_score)\n",
    "sum(top[:2600]<=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "clf = OneClassSVM().fit(f)\n",
    "f_score = clf.score_samples(f)\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.02).fit(f_score.reshape([f_score.size,1]))            \n",
    "\n",
    "feat_score = clf.score_samples(feat)\n",
    "oc_score = kde.score_samples(feat_score.reshape([feat_score.size,1]))\n",
    "roc_auc_score(true, oc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tree2 = startTree(f, numClass=60)\n",
    "extendTree(tree2, f, numClass=60)\n",
    "extendTree(tree2, f, numClass=60)\n",
    "extendTree(tree2, f, numClass=60)\n",
    "ff2, mask2 = projectXX(f, tree2)\n",
    "#pathNode2, pathDim2 = mask2path(mask2, tree2)\n",
    "#s2 = classScore(pathDim2, ff2, 4)\n",
    "ff2 = ff2/np.linalg.norm(ff2, axis=1, keepdims=True)\n",
    "print(ff2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "\n",
    "def multiOcSvm(labels, feat):\n",
    "    l = np.unique(labels)\n",
    "    numClass = np.sum(l>=0)\n",
    "    allClf = []\n",
    "    allKde = []\n",
    "    allWeight = []\n",
    "    for i in range(l.size):\n",
    "        mask = labels==l[i]\n",
    "        clf = OneClassSVM(gamma='auto').fit(feat[mask])\n",
    "        s = clf.score_samples(feat[mask])\n",
    "        kde = KernelDensity(kernel='gaussian', bandwidth=0.02).fit(s.reshape([s.size,1]))            \n",
    "        allClf.append(clf)\n",
    "        allKde.append(kde)\n",
    "        allWeight.append(sum(mask))\n",
    "    return allClf, allKde, allWeight\n",
    "\n",
    "tree2 = startTree(f, numClass=60)\n",
    "ff2, mask2 = projectXX(f, tree2)\n",
    "#ff2N = ff2/np.linalg.norm(ff2, axis=1, keepdims=True)\n",
    "\n",
    "allSVM, allKde, allWeight = multiOcSvm(np.argmax(ff2, axis=1), f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(mask2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9597215976331361"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiSvmScore(allSVM, allKde, allWeight, feat):\n",
    "    score = np.zeros([feat.shape[0], len(allSVM)])\n",
    "    for i, s in enumerate(allSVM):\n",
    "        if allWeight[i]>20:\n",
    "            ss = s.score_samples(feat)\n",
    "            score[:,i] = ss/allWeight[i]\n",
    "            #score[:,i] = allKde[i].score_samples(ss.reshape([ss.size,1]))\n",
    "        #plt.figure(i)\n",
    "        #plt.hist(score[:,i])\n",
    "    return score\n",
    "\n",
    "ff_All, mask2 = projectXX(feat, tree2)\n",
    "#ff_AllN = ff_All/np.linalg.norm(ff_All, axis=1, keepdims=True)\n",
    "\n",
    "score = multiSvmScore(allSVM, allKde, allWeight, feat)\n",
    "roc_auc_score(true, np.max(score, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-165056.22723553       0.               0.         ...       0.\n",
      "  -427145.82717465       0.        ]\n",
      " [-165057.13205804       0.               0.         ...       0.\n",
      "  -427145.58862376       0.        ]\n",
      " [-165056.79977793       0.               0.         ...       0.\n",
      "  -427147.52968211       0.        ]\n",
      " ...\n",
      " [-165057.40151814       0.               0.         ...       0.\n",
      "  -427146.72469741       0.        ]\n",
      " [-165057.33310335       0.               0.         ...       0.\n",
      "  -427148.39342488       0.        ]\n",
      " [-165057.79709808       0.               0.         ...       0.\n",
      "  -427146.88968035       0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8003606508875739"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(true, np.max(ff_All, axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(score, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_All, mask2 = projectXX(feat, tree2)\n",
    "ff_AllN = ff_All/np.linalg.norm(ff_All, axis=1, keepdims=True)\n",
    "\n",
    "s2 = np.max(ff_All, axis=1)\n",
    "roc_auc_score(true, s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "\n",
    "\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.02).fit(ff2N)            \n",
    "s2 = kde.score_samples(ff_AllN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(s2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "i = 0\n",
    "true = np.zeros(feat.shape[0], dtype=bool)\n",
    "true[i*1300:(i+1)*1300] = 1\n",
    "roc_auc_score(true, s2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "clf = OneClassSVM().fit(ff2)\n",
    "oc_score = clf.score_samples(ff_All)\n",
    "\n",
    "roc_auc_score(true, oc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = donk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
