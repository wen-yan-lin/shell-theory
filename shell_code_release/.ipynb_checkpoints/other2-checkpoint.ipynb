{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "allFeat = np.load('/tf/notebooks/stl_feat/feats_2048.npy')\n",
    "gtAll = np.load('/tf/notebooks/stl_feat/labels_2048.npy')-1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clusteringX2 import normIt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def clusteringKmeans(feat, numClass=2):\n",
    "    feat, m = normIt(feat)\n",
    "    \n",
    "    # initilization\n",
    "    kmeans = KMeans(n_clusters=numClass, random_state=0).fit(feat)\n",
    "    labelK = kmeans.predict(feat)\n",
    "    means =np.zeros([numClass, feat.shape[1]])\n",
    "\n",
    "    for i in range(numClass):\n",
    "        mask = labelK == i\n",
    "        means[i,:] = np.mean(feat[mask,:], axis =0)\n",
    "\n",
    "    return kmeans, m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodeK:\n",
    "    def __init__(self, mask=None, kmeans = None, m=None, numClus=None):\n",
    "        self.mask = mask\n",
    "        self.classifier = kmeans\n",
    "        self.m = m\n",
    "        self.numClus = numClus\n",
    "        \n",
    "\n",
    "    \n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.nodeList = []\n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self):\n",
    "        self.numLayers = 0\n",
    "        self.listOfLayers = []\n",
    "        self.numNodes = 0\n",
    "        self.listOfNodes = []\n",
    "        \n",
    "    def addNode(self, c):\n",
    "        self.listOfNodes.append(c)\n",
    "        self.numNodes = self.numNodes + 1\n",
    "        \n",
    "    def addLayer(self, c):\n",
    "        self.listOfLayers.append(c)\n",
    "        self.numLayers = self.numLayers + 1\n",
    "\n",
    "    \n",
    "def startTree(allFeat, numClass=10):\n",
    "    tree = Tree()    \n",
    "    kmeans, m = clusteringKmeans(allFeat, numClass)\n",
    "    mask = np.ones(allFeat.shape[0], dtype=bool)\n",
    "    n = NodeK(mask, kmeans, m, numClass)\n",
    "\n",
    "    tree.addNode(n)\n",
    "    newLayer = Layer()\n",
    "    newLayer.nodeList.append(tree.numNodes-1)\n",
    "    tree.addLayer(newLayer)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "    \n",
    "def node2LabelK(feat, node):\n",
    "    x, _ = normIt(feat, node.m)\n",
    "    return node.classifier.predict(x)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def extendTree(tree, allFeat, numClass=10, clusteringThreshold=100):\n",
    "    newLayer = Layer()\n",
    "    lastLayer = tree.listOfLayers[-1]\n",
    "    for nodeIndex in lastLayer.nodeList:\n",
    "        node = tree.listOfNodes[nodeIndex]\n",
    "        curFeat = allFeat[node.mask,:]\n",
    "        clusterInd = node2LabelK(curFeat, node)\n",
    "        curInd = np.where(node.mask)[0]\n",
    "\n",
    "        for i in range(numClass):\n",
    "            subMask = clusterInd == i\n",
    "            if sum(subMask) > clusteringThreshold:\n",
    "                \n",
    "                newMask =  np.zeros(allFeat.shape[0], dtype=bool)\n",
    "                newMask[curInd[subMask]] = 1\n",
    "                \n",
    "\n",
    "                kmeans, m = clusteringKmeans(allFeat[newMask,:], numClass)\n",
    "                n = NodeK(newMask, kmeans, m, numClass)\n",
    "                \n",
    "                tree.addNode(n)\n",
    "                newLayer.nodeList.append(tree.numNodes-1)\n",
    "        tree.addLayer(newLayer)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "feat = allFeat[gtAll<4,:]#[np.logical_or(gtAll==0,  gtAll==1),:]\n",
    "    \n",
    "tree = startTree(feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "extendTree(tree, feat)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "feat1_, _ = normIt(feat)\n",
    "d_ori = pairwise_distances(feat1_, feat1_)\n",
    "nnOri = np.argsort(d_ori, axis =1)\n",
    "\n",
    "projectX = np.zeros([feat.shape[0], tree.numNodes])\n",
    "for i, n in enumerate(tree.listOfNodes):\n",
    "    m = n.mask\n",
    "    projectX[m,i] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01839507125009748\n",
      "358.69576923076926\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clusNeigbours = np.zeros([feat.shape[0],feat.shape[0]], dtype=bool )\n",
    "\n",
    "for i in range(feat.shape[0]):\n",
    "    sameClus = np.sum(np.absolute(projectX - projectX[i,:]), axis =1)\n",
    "    mask = sameClus == 0\n",
    "    clusNeigbours[i,:] = mask\n",
    "    clusNeigbours[i,i] = 0\n",
    "\n",
    "    \n",
    "sorted_dist = np.sort(d_ori, axis =1)\n",
    "\n",
    "err_store = np.zeros(clusNeigbours.shape[0])\n",
    "\n",
    "err = 0\n",
    "num_neigbours = 0\n",
    "for i in range(nnOri.shape[0]):\n",
    "    #val = np.min(d_ori[clusNeigbours[i,:], :])    \n",
    "    val1 = np.min(d_ori[clusNeigbours[i,:], i])  \n",
    "    val2 = sorted_dist[i, 1]\n",
    "    err = err + (val1-val2)/val2\n",
    "    err_store[i] = (val1-val2)/val2\n",
    "    num_neigbours = num_neigbours + sum(clusNeigbours[i,:])\n",
    "    #print((val1-val2)/val2, val1-val2, sum(clusNeigbours[i,:]))\n",
    "print(err/nnOri.shape[0])\n",
    "print(num_neigbours/nnOri.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[0.1134485  0.11392804 0.1140201  0.11463634 0.11464337 0.11500245\n",
      " 0.11532362 0.1161875  0.11621554 0.11716925 0.1172725  0.11734523\n",
      " 0.117943   0.11816794 0.12001792 0.12158482 0.12197601 0.12205692\n",
      " 0.12232045 0.12260818 0.12279965 0.12341097 0.12358131 0.12380792\n",
      " 0.12518215 0.12532035 0.12657154 0.12661635 0.12728546 0.1289207\n",
      " 0.12931718 0.12950775 0.13057428 0.13127667 0.13175269 0.13217687\n",
      " 0.13223057 0.13247108 0.13318749 0.1335642  0.13433533 0.13593933\n",
      " 0.13636381 0.1388089  0.13910582 0.140051   0.14061699 0.14228071\n",
      " 0.14272073 0.14443116 0.1445864  0.1446738  0.14601649 0.14627635\n",
      " 0.14786993 0.14927065 0.14966266 0.15142649 0.15164909 0.15190402\n",
      " 0.15233411 0.15270719 0.15297382 0.15334911 0.15472458 0.15551219\n",
      " 0.15663497 0.15665734 0.15758798 0.16016011 0.16050797 0.16146605\n",
      " 0.16181917 0.16216364 0.16246819 0.16256037 0.16285555 0.16399347\n",
      " 0.16407495 0.16452247 0.1665861  0.16737806 0.16824313 0.16863601\n",
      " 0.16883426 0.16898956 0.16923423 0.16936286 0.16991703 0.17008614\n",
      " 0.17038952 0.17155026 0.17206048 0.17229629 0.17336968 0.17340287\n",
      " 0.17379401 0.17466823 0.17750276 0.18122618 0.18138373 0.18166537\n",
      " 0.18180054 0.18260265 0.18328719 0.18413663 0.18500685 0.18560183\n",
      " 0.18618005 0.18631791 0.18688311 0.18750263 0.18811506 0.18895451\n",
      " 0.19092074 0.19494009 0.19505281 0.1962706  0.19798034 0.19802932\n",
      " 0.19892075 0.20053862 0.20281577 0.20303812 0.20421694 0.20430252\n",
      " 0.21020022 0.21894489 0.22116077 0.22492161 0.22574216 0.22620627\n",
      " 0.22682661 0.22690174 0.22964973 0.23163014 0.23506497 0.235318\n",
      " 0.2443789  0.2463622  0.2465265  0.2539994  0.25710802 0.25724328\n",
      " 0.2641422  0.26462017 0.26604677 0.26617744 0.2740208  0.27508524\n",
      " 0.27525475 0.27839772 0.28957188 0.29123124 0.2916274  0.29495089\n",
      " 0.29724489 0.29878361 0.30675854 0.30778772 0.31458728 0.31724848\n",
      " 0.32541246 0.33884447 0.34436585 0.34653123 0.35031827 0.35442676\n",
      " 0.35801187 0.37279072 0.38144649 0.38959041 0.42569728 0.43249357\n",
      " 0.43588129 0.43876626 0.4410152  0.44383989 0.45049626 0.46088273\n",
      " 0.47322647 0.47700903 0.50596468 0.51825058 0.56449234 0.63150473\n",
      " 0.6433826  0.65636191 0.66396367 0.86964104 0.95574591 1.05232156\n",
      " 1.0536665  1.36288321 1.40896599 1.58228347 1.81622152 2.00920738\n",
      " 2.09134436 3.6265337 ]\n"
     ]
    }
   ],
   "source": [
    "print(np.median(err_store))\n",
    "e = np.sort(err_store)\n",
    "print(e[5000:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
