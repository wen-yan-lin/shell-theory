{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "\n",
    "#allFeat = np.load('/tf/notebooks/clusteringTree/stl_feat/feats_2048.npy')\n",
    "#gtAll = np.load('/tf/notebooks/clusteringTree/stl_feat/labels_2048.npy')-1|\n",
    "\n",
    "# allFeat = np.load('/tf/notebooks/STL-10/danielFeat.npy')\n",
    "# gtAll = np.load('/tf/notebooks/STL-10/danielGt.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from clusteringX2 import normIt\n",
    "from clusteringX2 import clusterModel\n",
    "from clusteringX2 import train_step3\n",
    "from clusteringX2 import train_step4\n",
    "\n",
    "\n",
    "def clustering(feat, numClass=60, thres=0.1, iter_=1000):\n",
    "    \n",
    "    denom = 0.1\n",
    "    #feat, m = normIt(feat)\n",
    "    m = np.zeros(feat.shape[1])\n",
    "    \n",
    "    # initilization\n",
    "    kmeans = KMeans(n_clusters=numClass, random_state=0).fit(feat)\n",
    "    labelK = kmeans.predict(feat)\n",
    "    means =np.zeros([numClass, feat.shape[1]])\n",
    "\n",
    "    for i in range(numClass):\n",
    "        mask = labelK == i\n",
    "        means[i,:] = np.mean(feat[mask,:], axis =0)\n",
    "\n",
    "    sigInit = np.zeros([numClass])\n",
    "    for i in range(numClass):\n",
    "        mask = np.logical_not(labelK == i)\n",
    "        sigInit[i] = np.mean(np.matmul(feat[mask,:], np.transpose(means[i,:])))\n",
    "    model = clusterModel(means.transpose(), sigInit)\n",
    "    train_step4(model, feat.astype(\"float32\"), iter=iter_, denom=denom)\n",
    "    \n",
    "    \n",
    "    \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    s = np.max(c, axis=1)\n",
    "    t = np.mean(s)\n",
    "    mask = s > t*0.5\n",
    "    \n",
    "    \n",
    "    train_step4(model, feat[mask,:].astype(\"float32\"), iter=iter_, denom=denom)\n",
    "    \n",
    "    \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    s = np.max(c, axis=1)\n",
    "    t = np.mean(s)\n",
    "    mask = s > t*0.5\n",
    "    train_step4(model, feat[mask,:].astype(\"float32\"), iter=iter_, denom=denom)\n",
    "\n",
    " \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    labels = np.argmax(c, axis =1)\n",
    "    mask_ = np.zeros(numClass, dtype=bool)\n",
    "        \n",
    "    for i in range(numClass):\n",
    "        if np.sum(labels==i)>0:\n",
    "            mask_[i] = 1\n",
    "    w = model.w.numpy()\n",
    "    sig = model.sig.numpy()\n",
    "    w = w[:,mask_]\n",
    "    sig = sig[mask_]\n",
    "            \n",
    "\n",
    "    return w, sig, m, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, mask=None, w=None, sig=None, m=None):\n",
    "        self.mask = mask\n",
    "        self.w = w\n",
    "        self.sig = sig\n",
    "        self.m = m\n",
    "        self.listOfChildren = []\n",
    "            \n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.nodeList = []\n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self):\n",
    "        self.numLayers = 0\n",
    "        self.listOfLayers = []\n",
    "        self.numNodes = 0\n",
    "        self.listOfNodes = []\n",
    "        \n",
    "    def addNode(self, c):\n",
    "        self.listOfNodes.append(c)\n",
    "        self.numNodes = self.numNodes + 1\n",
    "        \n",
    "    def addLayer(self, c):\n",
    "        self.listOfLayers.append(c)\n",
    "        self.numLayers = self.numLayers + 1\n",
    "\n",
    "    \n",
    "def startTree(allFeat, numClass=60):\n",
    "    tree = Tree()    \n",
    "    w, sig, m, inMask = clustering(allFeat, numClass)\n",
    "    mask = np.ones(allFeat.shape[0], dtype=bool)\n",
    "    #mask[np.logical_not(inMask)] = 0\n",
    "    n = Node(mask, w, sig, m)\n",
    "\n",
    "    tree.addNode(n)\n",
    "    newLayer = Layer()\n",
    "    newLayer.nodeList.append(tree.numNodes-1)\n",
    "    tree.addLayer(newLayer)\n",
    "    \n",
    "    return tree\n",
    "#allFeat = allFeat/np.linalg.norm(allFeat, axis=1, keepdims=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "    \n",
    "def dataProjection(feat, node):\n",
    "    x, _ = normIt(feat, node.m) \n",
    "    s = np.linalg.norm(node.w, axis =0, keepdims=True)\n",
    "    return (np.matmul(x, node.w) - node.sig), s\n",
    "\n",
    "\n",
    "def extendTree(tree, allFeat, numClass=2, clusteringThreshold=100):\n",
    "    newLayer = Layer()\n",
    "    lastLayer = tree.listOfLayers[-1]\n",
    "    for nodeIndex in lastLayer.nodeList:\n",
    "        node = tree.listOfNodes[nodeIndex]\n",
    "        curFeat = allFeat[node.mask,:]\n",
    "        score, _ = dataProjection(curFeat, node)\n",
    "        \n",
    "        clusterInd = np.argmax(score, axis =1)\n",
    "        curInd = np.where(node.mask)[0]\n",
    "\n",
    "        #########################################\n",
    "        #_, m_sub = normIt(curFeat)\n",
    "        #########################################\n",
    "        \n",
    "        for i in range(score.shape[1]):\n",
    "            subMask = clusterInd == i\n",
    "            if sum(subMask) > clusteringThreshold:\n",
    "                \n",
    "                newMask =  np.zeros(allFeat.shape[0], dtype=bool)\n",
    "                newMask[curInd[subMask]] = 1\n",
    "                \n",
    "                \n",
    "                #########################################\n",
    "                nF, m_sub = normIt(allFeat[newMask,:])\n",
    "                #########################################\n",
    "\n",
    "                #nF, m_sub = normIt(allFeat[newMask,:], m_sub)\n",
    "                #nF = allFeat[newMask,:]\n",
    "                w, sig, _, inMask = clustering(nF, numClass)\n",
    "\n",
    "                print(w.shape, sum(newMask))\n",
    "                if w.shape[1]>=2:\n",
    "                    n = Node(newMask, w, sig, m_sub)\n",
    "                    tree.addNode(n)\n",
    "                    newLayer.nodeList.append(tree.numNodes-1)\n",
    "                    node.listOfChildren.append(tree.numNodes-1)\n",
    "                else:\n",
    "                    node.listOfChildren.append(-1)\n",
    "            else:\n",
    "                node.listOfChildren.append(-1)\n",
    "    tree.addLayer(newLayer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label2oneHot(labels):\n",
    "    b = np.zeros((labels.size, labels.max()+1), dtype=bool)\n",
    "    b[np.arange(labels.size),labels] = 1\n",
    "    return b\n",
    "\n",
    "\n",
    "\n",
    "def projectXX(feat, tree, maxClus=60, unit_vector=False, scale2data=False, verboise=True):\n",
    "    projectionSpace = np.zeros([feat.shape[0], tree.numNodes*maxClus])\n",
    "    maskAll = np.zeros([feat.shape[0], tree.numNodes*maxClus])\n",
    "\n",
    "    cur = 0    \n",
    "    for i, l in enumerate(tree.listOfLayers):\n",
    "        for nIndex in l.nodeList:\n",
    "            n = tree.listOfNodes[nIndex]\n",
    "            f, s = dataProjection(feat, n)\n",
    "            numDim = f.shape[1]\n",
    "            lab = np.argmax(f, axis =1)\n",
    "            maskAll[:,cur:cur+numDim] = label2oneHot(lab)\n",
    "            projectionSpace[:,cur:cur+numDim] = f\n",
    "            cur = cur + numDim\n",
    "    projectionSpace = projectionSpace[:,:cur]\n",
    "    maskAll = maskAll[:,:cur]\n",
    "    \n",
    "    return projectionSpace, maskAll\n",
    "\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2path(mask, tree):\n",
    "    pathNode = -1*np.ones([mask.shape[0], len(tree.listOfLayers)+1], dtype=int)\n",
    "    pathNode[:,0] = 0\n",
    "    \n",
    "    pathDim = -1*np.ones([mask.shape[0], len(tree.listOfLayers)+1], dtype=int)\n",
    "\n",
    "    \n",
    "    cur = 0\n",
    "    for i, l in enumerate(tree.listOfLayers):\n",
    "        print('layer:',i)\n",
    "        \n",
    "        for nIndex in l.nodeList:           \n",
    "            \n",
    "            n = tree.listOfNodes[nIndex]\n",
    "            dim = n.w.shape[1]\n",
    "            \n",
    "            \n",
    "            allCur = pathNode[:,i] == nIndex # in node nIndex\n",
    "            sub_mask = mask[:,cur:cur+dim] # with dimenions\n",
    "            ind = np.argmax(sub_mask)\n",
    "\n",
    "            for k in range(dim):\n",
    "                m = np.logical_and(allCur, sub_mask[:,k])\n",
    "                pathDim[m, i] = cur + k \n",
    "\n",
    "            \n",
    "            \n",
    "            if not n.listOfChildren:\n",
    "                cur = cur + dim\n",
    "                continue\n",
    "\n",
    "                        \n",
    "            \n",
    "            for k in range(dim):\n",
    "                m = np.logical_and(allCur, sub_mask[:,k])\n",
    "                pathNode[m, i+1] = n.listOfChildren[k]\n",
    "                \n",
    "                \n",
    "            cur = cur + dim\n",
    "            \n",
    "            \n",
    "    return pathNode, pathDim\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classScore(pathDim, ff, dim):\n",
    "    numPts = pathDim.shape[0]\n",
    "    score = np.zeros(pathDim.shape[0])\n",
    "    \n",
    "    for i in range(numPts):\n",
    "        for j in range(dim+1):\n",
    "            if pathDim[i,j]>=0:\n",
    "                score[i] = score[i] + ff[i, pathDim[i,j]]\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /root/.cache/pip/wheels/d0/f8/d5/8e3af3ee957feb9b403a060ebe72f7561887fef9dea658326e/umap_learn-0.3.10-cp36-none-any.whl\n",
      "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from umap.learn) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from umap.learn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.6/dist-packages (from umap.learn) (1.18.1)\n",
      "Requirement already satisfied: numba>=0.37 in /usr/local/lib/python3.6/dist-packages (from umap.learn) (0.48.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->umap.learn) (0.14.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.37->umap.learn) (44.0.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.37->umap.learn) (0.31.0)\n",
      "Installing collected packages: umap.learn\n",
      "Successfully installed umap.learn\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[33mWARNING: Skipping enum34 as it is not installed.\u001b[0m\n",
      "Requirement already satisfied: hdbscan in /usr/local/lib/python3.6/dist-packages (0.8.26)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.13.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.17 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.22.1)\n",
      "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.29.16)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from hdbscan) (0.14.1)\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pip3 install umap.learn\n",
    "\n",
    "!pip uninstall -y enum34\n",
    "\n",
    "! pip3 install hdbscan\n",
    "\n",
    "import umap\n",
    "import hdbscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "internetFeat = np.load('/tf/notebooks/internetData/monkey/resNet50.npy') # cat, dog, monkey\n",
    "stlFeat = np.load('/tf/notebooks/STL-10/danielFeat.npy')\n",
    "gtAll = np.load('/tf/notebooks/STL-10/danielGt.npy')\n",
    "\n",
    "internetFeat = stlFeat[gtAll==3]\n",
    "internetFeat = internetFeat[::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeat = internetFeat.copy()\n",
    "testFeat = stlFeat.copy()\n",
    "true = np.zeros(testFeat.shape[0], dtype=bool)\n",
    "true[gtAll==3] = 1 #3, 5, 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# tree2 = startTree(f, numClass=60)\n",
    "# extendTree(tree2, f, numClass=60)\n",
    "# extendTree(tree2, f, numClass=60)\n",
    "# extendTree(tree2, f, numClass=60)\n",
    "# ff2, mask2 = projectXX(f, tree2)\n",
    "# #pathNode2, pathDim2 = mask2path(mask2, tree2)\n",
    "# #s2 = classScore(pathDim2, ff2, 4)\n",
    "# ff2 = ff2/np.linalg.norm(ff2, axis=1, keepdims=True)\n",
    "# print(ff2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testFeat, m = normIt(testFeat)\n",
    "trainFeat, _ = normIt(trainFeat, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _, m = normIt(internetFeat)\n",
    "# trainFeat, _ = normIt(trainFeat, m)\n",
    "# testFeat, _ = normIt(testFeat, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 0\n",
      "layer: 1\n",
      "layer: 2\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "\n",
    "\n",
    "alpha = 1\n",
    "_, mI = normIt(internetFeat)\n",
    "mClus = alpha*mI + (1-alpha)*m\n",
    "trainClus, _ = normIt(internetFeat, mClus)\n",
    "\n",
    "tree2 = startTree(trainClus, numClass=60)\n",
    "extendTree(tree2, trainClus, numClass=60)\n",
    "extendTree(tree2, trainClus, numClass=60)\n",
    "# extendTree(tree2, trainClus, numClass=2)\n",
    "# extendTree(tree2, trainClus, numClass=2)\n",
    "# extendTree(tree2, trainClus, numClass=2)\n",
    "\n",
    "ff2, mask2 = projectXX(trainClus, tree2)\n",
    "#ff2N = ff2/np.linalg.norm(ff2, axis=1, keepdims=True)\n",
    "pathNode2, pathDim2 = mask2path(mask2, tree2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiOcSvm2(labels, feat):\n",
    "    l = np.unique(labels)\n",
    "    numClass = np.sum(l>=0)\n",
    "    allModels = []\n",
    "    for i in range(l.size):\n",
    "        mask = labels==l[i]\n",
    "        num = sum(mask)\n",
    "        clf = OneClassSVM(gamma='auto').fit(feat[mask])\n",
    "        s = clf.score_samples(feat[mask])\n",
    "        s_ = s/num\n",
    "        \n",
    "        allModels.append({'classifier':clf, 'mean':np.max(s_), 'std':np.std(s_), 'numInstance':num})\n",
    "    return allModels\n",
    "\n",
    "#allModels = multiOcSvm2(np.argmax(ff2, axis=1), trainFeat)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiOcSvm3(labels, feat):\n",
    "    l = np.unique(labels)\n",
    "    numClass = np.sum(l>=0)\n",
    "    allModels = []\n",
    "    for i in range(l.size):\n",
    "        mask = labels==l[i]\n",
    "        num = sum(mask)\n",
    "        m_ = np.mean(feat[mask], axis=0, keepdims=True)\n",
    "        d = feat[mask] - m_\n",
    "        d = np.linalg.norm(d, axis=1)\n",
    "        #print(d)\n",
    "#         plt.figure(i)\n",
    "#         plt.hist(d)\n",
    "        allModels.append({'clusMean': m_, 'numInstance': num, 'var': np.min(d) })\n",
    "    return allModels\n",
    "allModels = multiOcSvm3(np.argmax(ff2, axis=1), trainFeat)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58\n",
      "0.9605784352399737 58\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def multiSvmScore3(allModels, feat):\n",
    "    score = -10000*np.ones([feat.shape[0], len(allModels)])\n",
    "    minNum = 0\n",
    "    tot = 0\n",
    "    stdAve = 0\n",
    "    for i, s in enumerate(allModels):\n",
    "        if  s['numInstance']>minNum:\n",
    "            stdAve = stdAve + s['var']\n",
    "            tot = tot +1\n",
    "            #print(s['numInstance'])\n",
    "    print(tot)\n",
    "    stdAve = stdAve/tot\n",
    "            \n",
    "    for i, s in enumerate(allModels):\n",
    "        if s['numInstance']>minNum:\n",
    "            ss = np.linalg.norm(feat - s['clusMean'], axis=1)\n",
    "            ss = ss - s['var']\n",
    "            ss[ss<0] = 0\n",
    "            ss = np.exp(-(ss*ss)/0.01)\n",
    "            #ss = np.exp(-ss/0.1)\n",
    "            score[:,i] = ss*s['numInstance']\n",
    "    return score\n",
    "\n",
    "\n",
    "score = multiSvmScore3(allModels, testFeat)\n",
    "print(roc_auc_score(true, np.max(score, axis=1)), len(allModels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "58\n",
      "1\n",
      "1\n",
      "0.989474819197896 58\n"
     ]
    }
   ],
   "source": [
    "allModels0 = multiOcSvm3(np.zeros(ff2.shape[0], dtype=int), trainFeat)    \n",
    "score0 = multiSvmScore3(allModels0, testFeat)\n",
    "\n",
    "allModels1 = multiOcSvm3(pathDim2[:,0], trainFeat)    \n",
    "score1 = multiSvmScore3(allModels1, testFeat)\n",
    "\n",
    "allModels2 = multiOcSvm3(pathDim2[:,1], trainFeat)    \n",
    "score2 = multiSvmScore3(allModels2, testFeat)\n",
    "\n",
    "allModels3 = multiOcSvm3(pathDim2[:,2], trainFeat)    \n",
    "score3 = multiSvmScore3(allModels3, testFeat)\n",
    "\n",
    "\n",
    "print(roc_auc_score(true, np.max(score0, axis=1) + np.max(score1, axis=1) +  np.max(score2, axis=1) +  np.max(score3, axis=1)), len(allModels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9904430309007234"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(true, np.max(score0, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "58\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "allModels0 = multiOcSvm3(np.zeros(ff2.shape[0], dtype=int), trainFeat)    \n",
    "score0 = multiSvmScore3(allModels0, testFeat)\n",
    "\n",
    "scores.append(score0)\n",
    "\n",
    "\n",
    "for i in range(pathDim2.shape[1]-1):\n",
    "    allModels_ = multiOcSvm3(pathDim2[:,i], trainFeat)    \n",
    "    scores.append(multiSvmScore3(allModels_, testFeat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.989474819197896"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalScore = np.zeros(testFeat.shape[0])\n",
    "for i in range(len(scores)):\n",
    "    finalScore = finalScore + np.max(scores[i], axis =1)\n",
    "roc_auc_score(true, finalScore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc: 0.989474819197896\n",
      "mean: 0.972\n",
      "Top 100 accuracy: 0.99\n",
      "Top 1300 accuracy: 0.86\n"
     ]
    }
   ],
   "source": [
    "numInliers = np.sum(true)\n",
    "ind = np.argsort(-finalScore)\n",
    "estMask = np.zeros(true.size, dtype=bool)\n",
    "estMask[ind[:numInliers]] = True\n",
    "\n",
    "print('roc:', roc_auc_score(true, finalScore))\n",
    "print('mean:', np.mean(estMask==true))\n",
    "thres = 100\n",
    "print('Top', thres, 'accuracy:',  np.mean(true[ind[:thres]]))\n",
    "thres = numInliers\n",
    "print('Top', thres, 'accuracy:',  np.mean(true[ind[:thres]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc: 0.9881293228139383\n",
      "mean: 0.97\n",
      "Top 100 accuracy: 0.99\n",
      "Top 1300 accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "      \n",
    "    \n",
    "clf = OneClassSVM(gamma='auto').fit(trainFeat)\n",
    "ocsvm = clf.score_samples(testFeat)\n",
    "print('roc:', roc_auc_score(true, ocsvm))\n",
    "\n",
    "\n",
    "ind = np.argsort(-ocsvm)\n",
    "estMask = np.zeros(true.size, dtype=bool)\n",
    "estMask[ind[:numInliers]] = True\n",
    "\n",
    "print('mean:', np.mean(estMask==true))\n",
    "thres = 100\n",
    "print('Top', thres, 'accuracy:',  np.mean(true[ind[:thres]]))\n",
    "thres = numInliers\n",
    "print('Top', thres, 'accuracy:',  np.mean(true[ind[:thres]]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
