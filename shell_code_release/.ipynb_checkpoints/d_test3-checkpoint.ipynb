{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "import dirUtil \n",
    "from highDimLearning import vgg2feat\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "import random \n",
    "    \n",
    "\n",
    "def feat2labels(feat):\n",
    "    numClass = len(feat)\n",
    "    numDim = feat[0].shape[1]\n",
    "    numPts = 0\n",
    "    for i in range(numClass):\n",
    "        numPts = numPts + feat[i].shape[0]\n",
    "\n",
    "    allFeat = np.zeros([numPts, numDim])\n",
    "    allLabels = np.zeros(numPts, dtype = int)\n",
    "    cur = 0\n",
    "    for i in range(numClass):\n",
    "        allFeat[cur:cur+feat[i].shape[0],:] = feat[i]\n",
    "        allLabels[cur:cur+feat[i].shape[0]] = i\n",
    "        cur = cur + feat[i].shape[0]\n",
    "    return allFeat, allLabels\n",
    "        \n",
    "    \n",
    "def readNetVlad(folder, numDim =4096):\n",
    "    folderName = os.path.basename(os.path.normpath(folder))\n",
    "    print(folderName)\n",
    "    file = folder +'/vd16_pitts30k_conv5_3_vlad_preL2_intra_white_' +folderName + '_db.bin'    \n",
    "    data = np.fromfile(file, '<f4')\n",
    "    numPts = int(len(data)/numDim)\n",
    "    return np.reshape(data, [numPts, numDim])\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def cluster_acc(Y_pred, Y):\n",
    "    assert Y_pred.size == Y.size\n",
    "    D = max(Y_pred.max(), Y.max())+1\n",
    "    w = np.zeros((D,D), dtype=np.int64)\n",
    "    for i in range(Y_pred.size):\n",
    "        w[Y_pred[i], Y[i]] += 1\n",
    "    \n",
    "    row_ind, col_ind = linear_sum_assignment(w.max() - w)\n",
    "    \n",
    "    print(w[row_ind,col_ind])\n",
    "    return w[row_ind,col_ind].sum()/Y_pred.size, w\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1020 12:02:24.469805 140303834289984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:95: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n",
      "W1020 12:02:24.470493 140303834289984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:98: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W1020 12:02:24.482492 140303834289984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:102: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W1020 12:02:24.483368 140303834289984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W1020 12:02:24.485665 140303834289984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W1020 12:02:24.502786 140303834289984 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# feat1 = readNetVlad('/media/daniel/D/Data/basicMITData/abbey')\n",
    "    \n",
    "# feat2 = readNetVlad('/media/daniel/D/Data/basicMITData/airport_terminal')\n",
    "\n",
    "# feat3 = readNetVlad('/media/sliu/New Volume/basicMITData/alley')\n",
    "\n",
    "# feat4 = readNetVlad('/media/sliu/New Volume/basicMITData/amphitheater')\n",
    "\n",
    "\n",
    "# trainingNum = 1000\n",
    "\n",
    "tf.reset_default_graph()\n",
    "K.clear_session()\n",
    "folder = '/media/daniel/D/Data/basicMITData/abbey_small/'\n",
    "feats = dirUtil.dir2vgg16(folder)\n",
    "feat1 = vgg2feat(feats)\n",
    "\n",
    "\n",
    "folder2 = '/media/daniel/D/Data/basicMITData/airport_small/'\n",
    "tf.reset_default_graph()\n",
    "K.clear_session()\n",
    "feats = dirUtil.dir2vgg16(folder2)\n",
    "feat2 = vgg2feat(feats)\n",
    "\n",
    "# folder3 = '/home/sliu/code/keras-tutorial/animals/panda/'\n",
    "# tf.reset_default_graph()\n",
    "# K.clear_session()\n",
    "# feats = dirUtil.dir2vgg16(folder3)\n",
    "# feat3 = vgg2feat(feats)\n",
    "\n",
    "feat, gt = feat2labels([feat1, feat2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feat = np.load('/media/daniel/D/Data/STL-10/feats_2048.npy')\n",
    "gt = np.load('/media/daniel/D/Data/STL-10/labels_2048.npy')-1\n",
    "\n",
    "mask = gt>-1#np.logical_or(gt==3, gt==4)\n",
    "feat = feat[mask,:]\n",
    "gt = gt[mask]\n",
    "\n",
    "#feat = feat-np.mean(feat)\n",
    "\n",
    "feat = feat#/np.linalg.norm(feat, axis =1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "feat = np.reshape(x_train, [x_train.shape[0], x_train.shape[1]*x_train.shape[2]])\n",
    "feat = feat#/np.linalg.norm(feat, axis =1, keepdims=True)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=0.9)\n",
    "# pca.fit(feat)\n",
    "# feat = pca.transform(feat)\n",
    "\n",
    "\n",
    "gt = y_train\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "feat = np.reshape(x_test, [x_test.shape[0], x_test.shape[1]*x_test.shape[2]])\n",
    "feat = feat/np.linalg.norm(feat, axis =1, keepdims=True)\n",
    "\n",
    "\n",
    "\n",
    "gt = y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def get_train_test_feat(feat, target_class, num_train, gt):\n",
    "    mask_ = gt == target_class[0]\n",
    "    for i in target_class:\n",
    "        mask_ = mask_ + (gt ==i)\n",
    "    ind = np.where(mask_)[0]\n",
    "    ind = np.random.choice(ind, num_train, replace=False)\n",
    "    train_feat = copy.copy(feat[ind,:])\n",
    "    mask = np.ones(gt.size, dtype=bool)\n",
    "    mask[ind] = 0\n",
    "    test_feat = copy.copy(feat[mask, :])\n",
    "    test_gt = gt[mask]\n",
    "    test_gt_bool = np.zeros(test_gt.size, dtype=bool)\n",
    "    for i in target_class:\n",
    "        test_gt_bool[test_gt == i] = True\n",
    "\n",
    "    \n",
    "    return train_feat, test_feat, test_gt_bool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999754\n",
      "0.998394\n",
      "0.998074\n",
      "0.999134\n"
     ]
    }
   ],
   "source": [
    "num_train =500\n",
    "gp1_feat, _, _ = get_train_test_feat(feat, [3,5], num_train, gt)\n",
    "m1 = np.mean(gp1_feat, axis =0, keepdims=True)\n",
    "gp2_feat, _, _ = get_train_test_feat(feat, [1,3,4,5,6,7], num_train, gt)\n",
    "m2 = np.mean(gp2_feat, axis =0, keepdims=True)\n",
    "gp3_feat, _, _ = get_train_test_feat(feat,range(10), num_train, gt)\n",
    "m3 = np.mean(gp3_feat, axis =0, keepdims=True)\n",
    "\n",
    "#train_feat, test_feat, test_gt = get_train_test_feat(feat, [5], num_train, gt)\n",
    "mask = np.logical_or(gt==3, gt==5)\n",
    "train_feat, test_feat, test_gt = get_train_test_feat(feat[mask,:], [3], num_train, gt[mask])\n",
    "\n",
    "\n",
    "tf = train_feat-m1\n",
    "tf = tf/np.linalg.norm(tf, axis =1, keepdims=True)\n",
    "clf1 = OneClassSVM(gamma='auto').fit(tf)\n",
    "tsf = test_feat-m1\n",
    "tsf = tsf/np.linalg.norm(tsf, axis =1, keepdims=True)\n",
    "s1 =  clf1.score_samples(tsf)  \n",
    "fpr, tpr, _ = roc_curve(test_gt, s1)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n",
    "\n",
    "\n",
    "tf = train_feat-m2\n",
    "tf = tf/np.linalg.norm(tf, axis =1, keepdims=True)\n",
    "clf2 = OneClassSVM(gamma='auto').fit(tf)\n",
    "tsf = test_feat-m2\n",
    "tsf = tsf/np.linalg.norm(tsf, axis =1, keepdims=True)\n",
    "s2 =  clf2.score_samples(tsf)  \n",
    "fpr, tpr, _ = roc_curve(test_gt, s2)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n",
    "\n",
    "\n",
    "tf = train_feat-m3\n",
    "tf = tf/np.linalg.norm(tf, axis =1, keepdims=True)\n",
    "clf2 = OneClassSVM(gamma='auto').fit(tf)\n",
    "tsf = test_feat-m3\n",
    "tsf = tsf/np.linalg.norm(tsf, axis =1, keepdims=True)\n",
    "s3 =  clf2.score_samples(tsf)  \n",
    "fpr, tpr, _ = roc_curve(test_gt, s3)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n",
    "\n",
    "\n",
    "\n",
    "fpr, tpr, _ = roc_curve(test_gt, s1+s2+s3)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PCA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-c78f76558a01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_feat\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mtf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumIter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PCA' is not defined"
     ]
    }
   ],
   "source": [
    "# num_iter = 1\n",
    "\n",
    "# gp1_feat, _, _ = get_train_test_feat(feat, [3,5], 500, gt)\n",
    "# m1 = np.mean(gp1_feat, axis =0, keepdims=True)\n",
    "# gp2_feat, _, _ = get_train_test_feat(feat, [1,3,4,5,6,7], 500, gt)\n",
    "# m2 = np.mean(gp2_feat, axis =0, keepdims=True)\n",
    "# gp3_feat, _, _ = get_train_test_feat(feat,range(10), 500, gt)\n",
    "# m3 = np.mean(gp3_feat, axis =0, keepdims=True)\n",
    "\n",
    "# train_feat, test_feat, test_gt = get_train_test_feat(feat, [3], 500, gt)\n",
    "# #mask = np.logical_or(gt==3, gt==5)\n",
    "# #train_feat, test_feat, test_gt = get_train_test_feat(feat[mask,:], [3], 1000, gt[mask])\n",
    "\n",
    "\n",
    "# tf = train_feat-m1\n",
    "# tf = tf/np.linalg.norm(tf, axis =1, keepdims=True)\n",
    "# pca = PCA(n_components=numIter)\n",
    "# pca.fit(tf)\n",
    "# m = pca.components_\n",
    "# sig = np.mean(np.matmul(tf, np.transpose(m)), axis=0)\n",
    "# w, sig = estModel22(tf, np.transpose(m), sig, numShells=numIter, weight=0.1)\n",
    "# tsf = test_feat-m1\n",
    "# tsf = tsf/np.linalg.norm(tsf, axis =1, keepdims=True)\n",
    "# tf = np.matmul(tf,w)-sig\n",
    "# tsf = np.matmul(tsf,w)-sig\n",
    "# kde1 = KernelDensity(kernel='gaussian', bandwidth=0.05).fit(tf)\n",
    "# s1 = kde1.score_samples(tsf)\n",
    "# fpr, tpr, _ = roc_curve(test_gt, s1)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print(roc_auc)\n",
    "\n",
    "\n",
    "# tf = train_feat-m2\n",
    "# tf = tf/np.linalg.norm(tf, axis =1, keepdims=True)\n",
    "# pca = PCA(n_components=numIter)\n",
    "# pca.fit(tf)\n",
    "# m = pca.components_\n",
    "# sig = np.mean(np.matmul(tf, np.transpose(m)), axis=0)\n",
    "# w, sig = estModel22(tf, np.transpose(m), sig, numShells=numIter, weight=0.1)\n",
    "# tsf = test_feat-m2\n",
    "# tsf = tsf/np.linalg.norm(tsf, axis =1, keepdims=True)\n",
    "# tf = np.matmul(tf,w)-sig\n",
    "# tsf = np.matmul(tsf,w)-sig\n",
    "# kde2 = KernelDensity(kernel='gaussian', bandwidth=0.05).fit(tf)\n",
    "# s2 = kde2.score_samples(tsf)\n",
    "# fpr, tpr, _ = roc_curve(test_gt, s2)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print(roc_auc)\n",
    "\n",
    "\n",
    "# tf = train_feat-m3\n",
    "# tf = tf/np.linalg.norm(tf, axis =1, keepdims=True)\n",
    "# pca = PCA(n_components=numIter)\n",
    "# pca.fit(tf)\n",
    "# m = pca.components_\n",
    "# sig = np.mean(np.matmul(tf, np.transpose(m)), axis=0)\n",
    "# w, sig = estModel22(tf, np.transpose(m), sig, numShells=numIter, weight=0.1)\n",
    "# tsf = test_feat-m3\n",
    "# tsf = tsf/np.linalg.norm(tsf, axis =1, keepdims=True)\n",
    "# tf = np.matmul(tf,w)-sig\n",
    "# tsf = np.matmul(tsf,w)-sig\n",
    "# kde3 = KernelDensity(kernel='gaussian', bandwidth=0.05).fit(tf)\n",
    "# s3 = kde3.score_samples(tsf)\n",
    "# fpr, tpr, _ = roc_curve(test_gt, s3)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print(roc_auc)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# fpr, tpr, _ = roc_curve(test_gt, s1+s2+s3)\n",
    "# roc_auc = auc(fpr, tpr)\n",
    "# print(roc_auc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
