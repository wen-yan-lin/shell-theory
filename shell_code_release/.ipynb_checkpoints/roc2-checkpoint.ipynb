{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "import dirUtil \n",
    "from highDimLearning import vgg2feat\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "import random \n",
    "    \n",
    "\n",
    "def feat2labels(feat):\n",
    "    numClass = len(feat)\n",
    "    numDim = feat[0].shape[1]\n",
    "    numPts = 0\n",
    "    for i in range(numClass):\n",
    "        numPts = numPts + feat[i].shape[0]\n",
    "\n",
    "    allFeat = np.zeros([numPts, numDim])\n",
    "    allLabels = np.zeros(numPts, dtype = int)\n",
    "    cur = 0\n",
    "    for i in range(numClass):\n",
    "        allFeat[cur:cur+feat[i].shape[0],:] = feat[i]\n",
    "        allLabels[cur:cur+feat[i].shape[0]] = i\n",
    "        cur = cur + feat[i].shape[0]\n",
    "    return allFeat, allLabels\n",
    "        \n",
    "    \n",
    "def readNetVlad(folder, numDim =4096):\n",
    "    folderName = os.path.basename(os.path.normpath(folder))\n",
    "    print(folderName)\n",
    "    file = folder +'/vd16_pitts30k_conv5_3_vlad_preL2_intra_white_' +folderName + '_db.bin'    \n",
    "    data = np.fromfile(file, '<f4')\n",
    "    numPts = int(len(data)/numDim)\n",
    "    return np.reshape(data, [numPts, numDim])\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def cluster_acc(Y_pred, Y):\n",
    "    assert Y_pred.size == Y.size\n",
    "    D = max(Y_pred.max(), Y.max())+1\n",
    "    w = np.zeros((D,D), dtype=np.int64)\n",
    "    for i in range(Y_pred.size):\n",
    "        w[Y_pred[i], Y[i]] += 1\n",
    "    \n",
    "    row_ind, col_ind = linear_sum_assignment(w.max() - w)\n",
    "    \n",
    "    print(w[row_ind,col_ind])\n",
    "    return w[row_ind,col_ind].sum()/Y_pred.size, w\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feat = np.load('/media/daniel/D/Data/STL-10/feats_2048.npy')\n",
    "gt = np.load('/media/daniel/D/Data/STL-10/labels_2048.npy')-1\n",
    "\n",
    "mask = gt>-1#np.logical_or(gt==3, gt==4)\n",
    "feat = feat[mask,:]\n",
    "gt = gt[mask]\n",
    "\n",
    "feat = feat/np.linalg.norm(feat, axis =1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "feat = np.reshape(x_test, [x_test.shape[0], x_test.shape[1]*x_test.shape[2]])\n",
    "feat = feat/np.linalg.norm(feat, axis =1, keepdims=True)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=0.9)\n",
    "# pca.fit(feat)\n",
    "# feat = pca.transform(feat)\n",
    "\n",
    "\n",
    "gt = y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "feat = np.reshape(x_test, [x_test.shape[0], x_test.shape[1]*x_test.shape[2]])\n",
    "feat = feat/np.linalg.norm(feat, axis =1, keepdims=True)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=0.9)\n",
    "# pca.fit(feat)\n",
    "# feat = pca.transform(feat)\n",
    "\n",
    "\n",
    "gt = y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "target_class = 0\n",
    "num_train = 500\n",
    "def get_train_test_feat(feat, target_class, num_train, gt):\n",
    "    ind = np.where(gt== target_class)[0]\n",
    "    ind = np.random.choice(ind, num_train, replace=False)\n",
    "    train_feat = copy.copy(feat[ind,:])\n",
    "    mask = np.ones(gt.size, dtype=bool)\n",
    "    mask[ind] = 0\n",
    "    test_feat = copy.copy(feat[mask, :])\n",
    "    test_gt = gt[mask]\n",
    "    \n",
    "    return train_feat, test_feat, test_gt\n",
    "\n",
    "train_feat, test_feat,test_gt = get_train_test_feat(feat, target_class, num_train, gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "(200, 2048)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "\n",
    "from highDimLearningX import estModel23\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "numIter =200\n",
    "pca = PCA(n_components=numIter)\n",
    "pca.fit(train_feat)\n",
    "m = pca.components_\n",
    "sig = np.mean(np.matmul(train_feat, np.transpose(m)), axis=0)\n",
    "w, sig = estModel23(train_feat, m, sig, numShells=numIter, weight=1, numIter=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible dimension for X and Y matrices: X.shape[1] == 2048 while Y.shape[1] == 100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-cd181e35fb3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0meuclidean_distances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meuclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meuclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mkde\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKernelDensity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gaussian'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[0mpaired_distances\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mdistances\u001b[0m \u001b[0mbetweens\u001b[0m \u001b[0mpairs\u001b[0m \u001b[0mof\u001b[0m \u001b[0melements\u001b[0m \u001b[0mof\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m     \"\"\"\n\u001b[0;32m--> 232\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;31m# If norms are passed as float32, they are unused. If arrays are passed as\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype)\u001b[0m\n\u001b[1;32m    123\u001b[0m         raise ValueError(\"Incompatible dimension for X and Y matrices: \"\n\u001b[1;32m    124\u001b[0m                          \"X.shape[1] == %d while Y.shape[1] == %d\" % (\n\u001b[0;32m--> 125\u001b[0;31m                              X.shape[1], Y.shape[1]))\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 2048 while Y.shape[1] == 100"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "train = np.square(np.square(euclidean_distances(train_feat, w))-sig)\n",
    "test = np.square(np.square(euclidean_distances(test_feat, w))-sig)\n",
    "\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.05).fit(train)\n",
    "s = kde.score_samples(test)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(test_gt==target_class, s)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "0.9783436965811967\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "\n",
    "from highDimLearningX import estModel22\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "numIter =100\n",
    "pca = PCA(n_components=numIter)\n",
    "pca.fit(train_feat)\n",
    "m = pca.components_\n",
    "sig = np.mean(np.matmul(train_feat, np.transpose(m)), axis=0)\n",
    "w, sig = estModel22(train_feat, np.transpose(m), sig, numShells=numIter, weight=0.1)\n",
    "\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "\n",
    "train = np.matmul(train_feat,w)-sig\n",
    "test = np.matmul(test_feat,w)-sig\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.05).fit(train)\n",
    "s = kde.score_samples(test)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(test_gt==target_class, s)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training process completed.\n",
      "0.9591071581196582\n"
     ]
    }
   ],
   "source": [
    "from hyperFitProjection import HyperFitProjector\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "proj = HyperFitProjector(\"merged\")\n",
    "proj.fit_kmeans(train_feat, n_cluster=3, n_dim=100)\n",
    "train  = proj.transform(train_feat)\n",
    "test  = proj.transform(test_feat)\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.05).fit(train)\n",
    "s = kde.score_samples(test)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(test_gt==target_class, s)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
