{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# allFeat = np.load('/tf/notebooks/clusteringTree/stl_feat/feats_2048.npy')\n",
    "# gtAll = np.load('/tf/notebooks/clusteringTree/stl_feat/labels_2048.npy')-1\n",
    "\n",
    "allFeat = np.load('/tf/notebooks/STL-10/danielFeat.npy')\n",
    "gtAll = np.load('/tf/notebooks/STL-10/danielGt.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from clusteringX2 import normIt\n",
    "from clusteringX2 import clusterModel\n",
    "from clusteringX2 import train_step3\n",
    "\n",
    "\n",
    "def clustering(feat, numClass=60, thres=0.1):\n",
    "    feat, m = normIt(feat)\n",
    "    \n",
    "    # initilization\n",
    "    kmeans = KMeans(n_clusters=numClass, random_state=0).fit(feat)\n",
    "    labelK = kmeans.predict(feat)\n",
    "    means =np.zeros([numClass, feat.shape[1]])\n",
    "\n",
    "    for i in range(numClass):\n",
    "        mask = labelK == i\n",
    "        means[i,:] = np.mean(feat[mask,:], axis =0)\n",
    "\n",
    "    sigInit = np.zeros([numClass])\n",
    "    for i in range(numClass):\n",
    "        mask = np.logical_not(labelK == i)\n",
    "        sigInit[i] = np.mean(np.matmul(feat[mask,:], np.transpose(means[i,:])))\n",
    "    model = clusterModel(means.transpose(), sigInit)\n",
    "    train_step3(model, feat.astype(\"float32\"), iter =100)\n",
    "    \n",
    "    \n",
    "    \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    s = np.max(c, axis=1)\n",
    "    t = np.mean(s)\n",
    "    mask = s > t*0.5\n",
    "    train_step3(model, feat[mask,:].astype(\"float32\"), iter =100)\n",
    "    \n",
    "    \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    s = np.max(c, axis=1)\n",
    "    t = np.mean(s)\n",
    "    mask = s > t*0.5\n",
    "    train_step3(model, feat[mask,:].astype(\"float32\"), iter =100)\n",
    "\n",
    " \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    labels = np.argmax(c, axis =1)\n",
    "    mask_ = np.zeros(numClass, dtype=bool)\n",
    "        \n",
    "    for i in range(numClass):\n",
    "        if np.sum(labels==i)>0:\n",
    "            mask_[i] = 1\n",
    "    w = model.w.numpy()\n",
    "    sig = model.sig.numpy()\n",
    "    w = w[:,mask_]\n",
    "    sig = sig[mask_]\n",
    "            \n",
    "\n",
    "    return w, sig, m, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, mask=None, w=None, sig=None, m=None):\n",
    "        self.mask = mask\n",
    "        self.w = w\n",
    "        self.sig = sig\n",
    "        self.m = m\n",
    "            \n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.nodeList = []\n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self):\n",
    "        self.numLayers = 0\n",
    "        self.listOfLayers = []\n",
    "        self.numNodes = 0\n",
    "        self.listOfNodes = []\n",
    "        \n",
    "    def addNode(self, c):\n",
    "        self.listOfNodes.append(c)\n",
    "        self.numNodes = self.numNodes + 1\n",
    "        \n",
    "    def addLayer(self, c):\n",
    "        self.listOfLayers.append(c)\n",
    "        self.numLayers = self.numLayers + 1\n",
    "\n",
    "    \n",
    "def startTree(allFeat, numClass=2):\n",
    "    tree = Tree()    \n",
    "    w, sig, m, inMask = clustering(allFeat, numClass)\n",
    "    mask = np.ones(allFeat.shape[0], dtype=bool)\n",
    "    #mask[np.logical_not(inMask)] = 0\n",
    "    n = Node(mask, w, sig, m)\n",
    "\n",
    "    tree.addNode(n)\n",
    "    newLayer = Layer()\n",
    "    newLayer.nodeList.append(tree.numNodes-1)\n",
    "    tree.addLayer(newLayer)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "    \n",
    "#mask = np.logical_or(gtAll==3,  gtAll==4)\n",
    "mask = gtAll<10\n",
    "\n",
    "feat = allFeat[mask,:]\n",
    "gt = gtAll[mask]    \n",
    "gtCoarseAll = np.logical_or.reduce( [gtAll == 0, gtAll == 2, gtAll == 8, gtAll == 9]).astype(int)   \n",
    "gtCoarse = gtCoarseAll[mask]\n",
    "\n",
    "tree = startTree(feat[::2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataProjection(feat, node):\n",
    "    x, _ = normIt(feat, node.m) \n",
    "    return np.matmul(x, node.w) - node.sig\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def extendTree(tree, allFeat, numClass=2, clusteringThreshold=100):\n",
    "    newLayer = Layer()\n",
    "    lastLayer = tree.listOfLayers[-1]\n",
    "    for nodeIndex in lastLayer.nodeList:\n",
    "        node = tree.listOfNodes[nodeIndex]\n",
    "        curFeat = allFeat[node.mask,:]\n",
    "        score = dataProjection(curFeat, node)\n",
    "        #plt.scatter(score[:,0], score[:,1], alpha=0.1)\n",
    "        \n",
    "        clusterInd = np.argmax(score, axis =1)\n",
    "        curInd = np.where(node.mask)[0]\n",
    "\n",
    "        for i in range(score.shape[1]):\n",
    "            subMask = clusterInd == i\n",
    "            if sum(subMask) > clusteringThreshold:\n",
    "                \n",
    "                newMask =  np.zeros(allFeat.shape[0], dtype=bool)\n",
    "                newMask[curInd[subMask]] = 1\n",
    "                \n",
    "\n",
    "                w, sig, m, inMask = clustering(allFeat[newMask,:], numClass)\n",
    "                #subInd = np.where(newMask)[0]\n",
    "                #newMask[subInd[np.logical_not(inMask)]] = 0\n",
    "\n",
    "                if w.shape[1]>=2:\n",
    "                    n = Node(newMask, w, sig, m)\n",
    "                    tree.addNode(n)\n",
    "                    newLayer.nodeList.append(tree.numNodes-1)\n",
    "    tree.addLayer(newLayer)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "for k in range(100):\n",
    "    extendTree(tree, feat[::2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projectTree2(feat, tree, maxClus=2, unit_vector=True, scale2data=True, verboise=True):\n",
    "    \n",
    "    projectionSpace = np.zeros([feat.shape[0], tree.numNodes*maxClus])\n",
    "    \n",
    "    cur = 0\n",
    "    \n",
    "    for i, n in enumerate(tree.listOfNodes):\n",
    "        \n",
    "        f = dataProjection(feat, n)\n",
    "        numDim = f.shape[1]\n",
    "        if unit_vector:\n",
    "            f_ = np.concatenate([f, 10*np.ones([f.shape[0],1])], axis =1)\n",
    "            f_ = f_/np.linalg.norm(f_, axis =1, keepdims=True)\n",
    "            f = f_[:,:numDim]\n",
    "        if scale2data:\n",
    "            f = f*np.sum(n.mask)/n.mask.size \n",
    "        projectionSpace[:, cur:cur+numDim] = f\n",
    "        cur = cur+numDim\n",
    "        \n",
    "        if verboise == True:\n",
    "            print(i, n)\n",
    "    projectionSpace = projectionSpace[:,:cur]\n",
    "    return projectionSpace\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Feature\n",
      "0 <__main__.Node object at 0x7fa2ddac37b8>\n",
      "1 <__main__.Node object at 0x7fa233551518>\n",
      "2 <__main__.Node object at 0x7fa24071ba58>\n",
      "3 <__main__.Node object at 0x7fa2303ddb70>\n",
      "4 <__main__.Node object at 0x7fa2304c1cf8>\n",
      "5 <__main__.Node object at 0x7fa233551710>\n",
      "6 <__main__.Node object at 0x7fa239efcba8>\n",
      "7 <__main__.Node object at 0x7fa239e73400>\n",
      "8 <__main__.Node object at 0x7fa239cacf98>\n",
      "9 <__main__.Node object at 0x7fa239d986a0>\n",
      "10 <__main__.Node object at 0x7fa239d7fda0>\n",
      "11 <__main__.Node object at 0x7fa239afba90>\n",
      "12 <__main__.Node object at 0x7fa239ac95f8>\n",
      "13 <__main__.Node object at 0x7fa239a1b898>\n",
      "14 <__main__.Node object at 0x7fa239944e10>\n",
      "15 <__main__.Node object at 0x7fa239872940>\n",
      "16 <__main__.Node object at 0x7fa23996b470>\n",
      "17 <__main__.Node object at 0x7fa2397dfd30>\n",
      "18 <__main__.Node object at 0x7fa2397b6cf8>\n",
      "19 <__main__.Node object at 0x7fa23976f550>\n",
      "20 <__main__.Node object at 0x7fa239713240>\n",
      "21 <__main__.Node object at 0x7fa23960d898>\n",
      "22 <__main__.Node object at 0x7fa2395a6860>\n",
      "23 <__main__.Node object at 0x7fa239542c88>\n",
      "24 <__main__.Node object at 0x7fa23971bfd0>\n",
      "25 <__main__.Node object at 0x7fa2394ccda0>\n",
      "26 <__main__.Node object at 0x7fa2394a7710>\n",
      "27 <__main__.Node object at 0x7fa23943cf28>\n",
      "28 <__main__.Node object at 0x7fa23950dd68>\n",
      "29 <__main__.Node object at 0x7fa23943c978>\n",
      "30 <__main__.Node object at 0x7fa23933c208>\n",
      "31 <__main__.Node object at 0x7fa2392def60>\n",
      "32 <__main__.Node object at 0x7fa2392cfa90>\n",
      "33 <__main__.Node object at 0x7fa23925c630>\n",
      "34 <__main__.Node object at 0x7fa2391d78d0>\n",
      "35 <__main__.Node object at 0x7fa2391cd940>\n",
      "36 <__main__.Node object at 0x7fa23925d2b0>\n",
      "37 <__main__.Node object at 0x7fa2390ee390>\n",
      "38 <__main__.Node object at 0x7fa239378978>\n",
      "39 <__main__.Node object at 0x7fa239090710>\n",
      "40 <__main__.Node object at 0x7fa239147b38>\n",
      "41 <__main__.Node object at 0x7fa23906c630>\n",
      "42 <__main__.Node object at 0x7fa238f8e518>\n",
      "43 <__main__.Node object at 0x7fa239017f60>\n",
      "44 <__main__.Node object at 0x7fa238e5da90>\n",
      "45 <__main__.Node object at 0x7fa2390771d0>\n",
      "46 <__main__.Node object at 0x7fa238d79ef0>\n",
      "47 <__main__.Node object at 0x7fa238d9b908>\n",
      "48 <__main__.Node object at 0x7fa238d3bac8>\n",
      "49 <__main__.Node object at 0x7fa238d420b8>\n",
      "50 <__main__.Node object at 0x7fa238c64518>\n",
      "51 <__main__.Node object at 0x7fa238cb0128>\n",
      "52 <__main__.Node object at 0x7fa238da9c18>\n",
      "53 <__main__.Node object at 0x7fa238c27630>\n",
      "54 <__main__.Node object at 0x7fa238c32518>\n",
      "55 <__main__.Node object at 0x7fa238b47438>\n",
      "56 <__main__.Node object at 0x7fa238ac97b8>\n",
      "57 <__main__.Node object at 0x7fa238a76160>\n",
      "58 <__main__.Node object at 0x7fa238acfba8>\n",
      "59 <__main__.Node object at 0x7fa238a84160>\n",
      "60 <__main__.Node object at 0x7fa238970c50>\n",
      "61 <__main__.Node object at 0x7fa238927198>\n",
      "62 <__main__.Node object at 0x7fa238941630>\n",
      "63 <__main__.Node object at 0x7fa238946ef0>\n",
      "64 <__main__.Node object at 0x7fa2388863c8>\n",
      "65 <__main__.Node object at 0x7fa2387a1f28>\n",
      "66 <__main__.Node object at 0x7fa2388051d0>\n",
      "67 <__main__.Node object at 0x7fa238725fd0>\n",
      "68 <__main__.Node object at 0x7fa23871d208>\n",
      "69 <__main__.Node object at 0x7fa2393aac88>\n",
      "70 <__main__.Node object at 0x7fa2389b2d30>\n",
      "71 <__main__.Node object at 0x7fa238638ac8>\n",
      "72 <__main__.Node object at 0x7fa238845940>\n",
      "73 <__main__.Node object at 0x7fa2392eadd8>\n",
      "74 <__main__.Node object at 0x7fa23866aef0>\n",
      "75 <__main__.Node object at 0x7fa2386cfeb8>\n",
      "76 <__main__.Node object at 0x7fa2385aa128>\n",
      "77 <__main__.Node object at 0x7fa238595dd8>\n",
      "78 <__main__.Node object at 0x7fa23856d198>\n",
      "79 <__main__.Node object at 0x7fa238550e10>\n",
      "80 <__main__.Node object at 0x7fa238698908>\n",
      "81 <__main__.Node object at 0x7fa2384bcfd0>\n",
      "82 <__main__.Node object at 0x7fa23843d240>\n",
      "83 <__main__.Node object at 0x7fa238430dd8>\n",
      "84 <__main__.Node object at 0x7fa23837ae48>\n",
      "85 <__main__.Node object at 0x7fa2383cc8d0>\n",
      "86 <__main__.Node object at 0x7fa23840ea58>\n",
      "87 <__main__.Node object at 0x7fa23835c128>\n",
      "88 <__main__.Node object at 0x7fa2382cbdd8>\n",
      "89 <__main__.Node object at 0x7fa2382a3198>\n",
      "90 <__main__.Node object at 0x7fa2382b0908>\n",
      "num dimenions: 182\n"
     ]
    }
   ],
   "source": [
    "print('Create Feature')\n",
    "\n",
    "projectionSpace = projectTree2(feat, tree, unit_vector=True, scale2data=True)\n",
    "pp = projectionSpace.copy()\n",
    "pp_s, _ = normIt(pp)\n",
    "\n",
    "print('num dimenions:', pp_s.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <__main__.Node object at 0x7fa2ddac37b8>\n",
      "1 <__main__.Node object at 0x7fa233551518>\n",
      "2 <__main__.Node object at 0x7fa24071ba58>\n",
      "3 <__main__.Node object at 0x7fa2303ddb70>\n",
      "4 <__main__.Node object at 0x7fa2304c1cf8>\n",
      "5 <__main__.Node object at 0x7fa233551710>\n",
      "6 <__main__.Node object at 0x7fa239efcba8>\n",
      "7 <__main__.Node object at 0x7fa239e73400>\n",
      "8 <__main__.Node object at 0x7fa239cacf98>\n",
      "9 <__main__.Node object at 0x7fa239d986a0>\n",
      "10 <__main__.Node object at 0x7fa239d7fda0>\n",
      "11 <__main__.Node object at 0x7fa239afba90>\n",
      "12 <__main__.Node object at 0x7fa239ac95f8>\n",
      "13 <__main__.Node object at 0x7fa239a1b898>\n",
      "14 <__main__.Node object at 0x7fa239944e10>\n",
      "15 <__main__.Node object at 0x7fa239872940>\n",
      "16 <__main__.Node object at 0x7fa23996b470>\n",
      "17 <__main__.Node object at 0x7fa2397dfd30>\n",
      "18 <__main__.Node object at 0x7fa2397b6cf8>\n",
      "19 <__main__.Node object at 0x7fa23976f550>\n",
      "20 <__main__.Node object at 0x7fa239713240>\n",
      "21 <__main__.Node object at 0x7fa23960d898>\n",
      "22 <__main__.Node object at 0x7fa2395a6860>\n",
      "23 <__main__.Node object at 0x7fa239542c88>\n",
      "24 <__main__.Node object at 0x7fa23971bfd0>\n",
      "25 <__main__.Node object at 0x7fa2394ccda0>\n",
      "26 <__main__.Node object at 0x7fa2394a7710>\n",
      "27 <__main__.Node object at 0x7fa23943cf28>\n",
      "28 <__main__.Node object at 0x7fa23950dd68>\n",
      "29 <__main__.Node object at 0x7fa23943c978>\n",
      "30 <__main__.Node object at 0x7fa23933c208>\n",
      "31 <__main__.Node object at 0x7fa2392def60>\n",
      "32 <__main__.Node object at 0x7fa2392cfa90>\n",
      "33 <__main__.Node object at 0x7fa23925c630>\n",
      "34 <__main__.Node object at 0x7fa2391d78d0>\n",
      "35 <__main__.Node object at 0x7fa2391cd940>\n",
      "36 <__main__.Node object at 0x7fa23925d2b0>\n",
      "37 <__main__.Node object at 0x7fa2390ee390>\n",
      "38 <__main__.Node object at 0x7fa239378978>\n",
      "39 <__main__.Node object at 0x7fa239090710>\n",
      "40 <__main__.Node object at 0x7fa239147b38>\n",
      "41 <__main__.Node object at 0x7fa23906c630>\n",
      "42 <__main__.Node object at 0x7fa238f8e518>\n",
      "43 <__main__.Node object at 0x7fa239017f60>\n",
      "44 <__main__.Node object at 0x7fa238e5da90>\n",
      "45 <__main__.Node object at 0x7fa2390771d0>\n",
      "46 <__main__.Node object at 0x7fa238d79ef0>\n",
      "47 <__main__.Node object at 0x7fa238d9b908>\n",
      "48 <__main__.Node object at 0x7fa238d3bac8>\n",
      "49 <__main__.Node object at 0x7fa238d420b8>\n",
      "50 <__main__.Node object at 0x7fa238c64518>\n",
      "51 <__main__.Node object at 0x7fa238cb0128>\n",
      "52 <__main__.Node object at 0x7fa238da9c18>\n",
      "53 <__main__.Node object at 0x7fa238c27630>\n",
      "54 <__main__.Node object at 0x7fa238c32518>\n",
      "55 <__main__.Node object at 0x7fa238b47438>\n",
      "56 <__main__.Node object at 0x7fa238ac97b8>\n",
      "57 <__main__.Node object at 0x7fa238a76160>\n",
      "58 <__main__.Node object at 0x7fa238acfba8>\n",
      "59 <__main__.Node object at 0x7fa238a84160>\n",
      "60 <__main__.Node object at 0x7fa238970c50>\n",
      "61 <__main__.Node object at 0x7fa238927198>\n",
      "62 <__main__.Node object at 0x7fa238941630>\n",
      "63 <__main__.Node object at 0x7fa238946ef0>\n",
      "64 <__main__.Node object at 0x7fa2388863c8>\n",
      "65 <__main__.Node object at 0x7fa2387a1f28>\n",
      "66 <__main__.Node object at 0x7fa2388051d0>\n",
      "67 <__main__.Node object at 0x7fa238725fd0>\n",
      "68 <__main__.Node object at 0x7fa23871d208>\n",
      "69 <__main__.Node object at 0x7fa2393aac88>\n",
      "70 <__main__.Node object at 0x7fa2389b2d30>\n",
      "71 <__main__.Node object at 0x7fa238638ac8>\n",
      "72 <__main__.Node object at 0x7fa238845940>\n",
      "73 <__main__.Node object at 0x7fa2392eadd8>\n",
      "74 <__main__.Node object at 0x7fa23866aef0>\n",
      "75 <__main__.Node object at 0x7fa2386cfeb8>\n",
      "76 <__main__.Node object at 0x7fa2385aa128>\n",
      "77 <__main__.Node object at 0x7fa238595dd8>\n",
      "78 <__main__.Node object at 0x7fa23856d198>\n",
      "79 <__main__.Node object at 0x7fa238550e10>\n",
      "80 <__main__.Node object at 0x7fa238698908>\n",
      "81 <__main__.Node object at 0x7fa2384bcfd0>\n",
      "82 <__main__.Node object at 0x7fa23843d240>\n",
      "83 <__main__.Node object at 0x7fa238430dd8>\n",
      "84 <__main__.Node object at 0x7fa23837ae48>\n",
      "85 <__main__.Node object at 0x7fa2383cc8d0>\n",
      "86 <__main__.Node object at 0x7fa23840ea58>\n",
      "87 <__main__.Node object at 0x7fa23835c128>\n",
      "88 <__main__.Node object at 0x7fa2382cbdd8>\n",
      "89 <__main__.Node object at 0x7fa2382a3198>\n",
      "90 <__main__.Node object at 0x7fa2382b0908>\n",
      "num dimenions: 182\n"
     ]
    }
   ],
   "source": [
    "projectionSpace = projectTree2(feat, tree, unit_vector=True, scale2data=True)\n",
    "pp = projectionSpace.copy()\n",
    "pp_s, _ = normIt(pp)\n",
    "\n",
    "print('num dimenions:', pp_s.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree2 = startTree(pp_s[::2])\n",
    "\n",
    "\n",
    "for k in range(100):\n",
    "    extendTree(tree2, pp_s[::2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <__main__.Node object at 0x7fa252bf14a8>\n",
      "1 <__main__.Node object at 0x7fa23814aba8>\n",
      "2 <__main__.Node object at 0x7fa2380e37f0>\n",
      "3 <__main__.Node object at 0x7fa237f5f898>\n",
      "4 <__main__.Node object at 0x7fa237ef0128>\n",
      "5 <__main__.Node object at 0x7fa237f77e80>\n",
      "6 <__main__.Node object at 0x7fa237e98cc0>\n",
      "7 <__main__.Node object at 0x7fa237dc7860>\n",
      "8 <__main__.Node object at 0x7fa237cf0d68>\n",
      "9 <__main__.Node object at 0x7fa237c1e940>\n",
      "10 <__main__.Node object at 0x7fa237bccb38>\n",
      "11 <__main__.Node object at 0x7fa237ae7f60>\n",
      "12 <__main__.Node object at 0x7fa237a2ae10>\n",
      "13 <__main__.Node object at 0x7fa2379d2e10>\n",
      "14 <__main__.Node object at 0x7fa252bf1550>\n",
      "15 <__main__.Node object at 0x7fa237890e80>\n",
      "16 <__main__.Node object at 0x7fa23775f080>\n",
      "17 <__main__.Node object at 0x7fa237706c50>\n",
      "18 <__main__.Node object at 0x7fa2376247f0>\n",
      "19 <__main__.Node object at 0x7fa2375d3f28>\n",
      "20 <__main__.Node object at 0x7fa237509f28>\n",
      "21 <__main__.Node object at 0x7fa237436a90>\n",
      "22 <__main__.Node object at 0x7fa237362f98>\n",
      "23 <__main__.Node object at 0x7fa237316d68>\n",
      "24 <__main__.Node object at 0x7fa2372f5b70>\n",
      "25 <__main__.Node object at 0x7fa2371c6eb8>\n",
      "26 <__main__.Node object at 0x7fa237115e48>\n",
      "27 <__main__.Node object at 0x7fa236fd8ba8>\n",
      "28 <__main__.Node object at 0x7fa236f71e80>\n",
      "29 <__main__.Node object at 0x7fa236ea1fd0>\n",
      "30 <__main__.Node object at 0x7fa236e51e48>\n",
      "31 <__main__.Node object at 0x7fa236d76e48>\n",
      "32 <__main__.Node object at 0x7fa236e44da0>\n",
      "33 <__main__.Node object at 0x7fa236d50a58>\n",
      "34 <__main__.Node object at 0x7fa2302b6cc0>\n",
      "35 <__main__.Node object at 0x7fa2301ddc88>\n",
      "36 <__main__.Node object at 0x7fa23018d828>\n",
      "37 <__main__.Node object at 0x7fa2300b4da0>\n",
      "38 <__main__.Node object at 0x7fa22076cf60>\n",
      "39 <__main__.Node object at 0x7fa22071bac8>\n",
      "40 <__main__.Node object at 0x7fa220627f28>\n",
      "41 <__main__.Node object at 0x7fa220576da0>\n",
      "42 <__main__.Node object at 0x7fa22049dda0>\n",
      "43 <__main__.Node object at 0x7fa230294ac8>\n",
      "44 <__main__.Node object at 0x7fa220427ef0>\n",
      "45 <__main__.Node object at 0x7fa2202a49b0>\n",
      "46 <__main__.Node object at 0x7fa220251ba8>\n",
      "47 <__main__.Node object at 0x7fa22017c128>\n",
      "48 <__main__.Node object at 0x7fa2200abe80>\n",
      "49 <__main__.Node object at 0x7fa22003ee80>\n",
      "50 <__main__.Node object at 0x7fa22029dfd0>\n",
      "51 <__main__.Node object at 0x7fa1f43ecfd0>\n",
      "52 <__main__.Node object at 0x7fa1f4270cc0>\n",
      "53 <__main__.Node object at 0x7fa1f4198c88>\n",
      "54 <__main__.Node object at 0x7fa1f40c5828>\n",
      "55 <__main__.Node object at 0x7fa1f406eda0>\n",
      "56 <__main__.Node object at 0x7fa1e875cf60>\n",
      "57 <__main__.Node object at 0x7fa1e8689ac8>\n",
      "58 <__main__.Node object at 0x7fa1f42b9f28>\n",
      "59 <__main__.Node object at 0x7fa1e865b668>\n",
      "60 <__main__.Node object at 0x7fa1e8568da0>\n",
      "61 <__main__.Node object at 0x7fa1e8402fd0>\n",
      "62 <__main__.Node object at 0x7fa1e83b0e80>\n",
      "63 <__main__.Node object at 0x7fa1e83edd68>\n",
      "64 <__main__.Node object at 0x7fa1e820c208>\n",
      "65 <__main__.Node object at 0x7fa1e81d6e80>\n",
      "66 <__main__.Node object at 0x7fa1e80f27b8>\n",
      "67 <__main__.Node object at 0x7fa1e819b898>\n",
      "68 <__main__.Node object at 0x7fa1cc78eef0>\n",
      "69 <__main__.Node object at 0x7fa1cc7f2898>\n",
      "70 <__main__.Node object at 0x7fa1cc72ac50>\n",
      "71 <__main__.Node object at 0x7fa1cc6ba470>\n",
      "72 <__main__.Node object at 0x7fa1cc54fac8>\n",
      "73 <__main__.Node object at 0x7fa1cc4daf28>\n",
      "74 <__main__.Node object at 0x7fa1cc427da0>\n",
      "75 <__main__.Node object at 0x7fa1cc34fda0>\n",
      "76 <__main__.Node object at 0x7fa1cc605940>\n",
      "77 <__main__.Node object at 0x7fa1cc2d8ef0>\n",
      "78 <__main__.Node object at 0x7fa1cc662630>\n",
      "79 <__main__.Node object at 0x7fa1cc0cae48>\n",
      "80 <__main__.Node object at 0x7fa1cc229ef0>\n",
      "81 <__main__.Node object at 0x7fa1bc7a5a20>\n",
      "82 <__main__.Node object at 0x7fa1cc05a240>\n",
      "83 <__main__.Node object at 0x7fa1bc6027b8>\n",
      "84 <__main__.Node object at 0x7fa1bc54cc50>\n",
      "85 <__main__.Node object at 0x7fa1bc712e10>\n",
      "86 <__main__.Node object at 0x7fa1bc535978>\n",
      "87 <__main__.Node object at 0x7fa1bc409ac8>\n",
      "88 <__main__.Node object at 0x7fa1bc542630>\n",
      "89 <__main__.Node object at 0x7fa1bc3d6668>\n",
      "num dimenions: 180\n"
     ]
    }
   ],
   "source": [
    "projectionSpace2 = projectTree2(pp_s, tree2, unit_vector=True, scale2data=True)\n",
    "pp2 = projectionSpace2.copy()\n",
    "pp_s2, _ = normIt(pp2)\n",
    "\n",
    "print('num dimenions:', pp_s2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create UMAP Feature\n",
      "Processing /root/.cache/pip/wheels/d0/f8/d5/8e3af3ee957feb9b403a060ebe72f7561887fef9dea658326e/umap_learn-0.3.10-cp36-none-any.whl\n",
      "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from umap.learn) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from umap.learn) (0.22.1)\n",
      "Requirement already satisfied: numba>=0.37 in /usr/local/lib/python3.6/dist-packages (from umap.learn) (0.48.0)\n",
      "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.6/dist-packages (from umap.learn) (1.18.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->umap.learn) (0.14.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.37->umap.learn) (44.0.0)\n",
      "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.37->umap.learn) (0.31.0)\n",
      "Installing collected packages: umap.learn\n",
      "Successfully installed umap.learn\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numba/typed_passes.py:293: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../usr/local/lib/python3.6/dist-packages/umap/rp_tree.py\", line 135:\n",
      "@numba.njit(fastmath=True, nogil=True, parallel=True)\n",
      "def euclidean_random_projection_split(data, indices, rng_state):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/umap/nndescent.py:92: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../usr/local/lib/python3.6/dist-packages/umap/utils.py\", line 409:\n",
      "@numba.njit(parallel=True)\n",
      "def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):\n",
      "^\n",
      "\n",
      "  current_graph, n_vertices, n_neighbors, max_candidates, rng_state\n",
      "/usr/local/lib/python3.6/dist-packages/numba/typed_passes.py:293: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../usr/local/lib/python3.6/dist-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n"
     ]
    }
   ],
   "source": [
    "print('Create UMAP Feature')\n",
    "\n",
    "! pip3 install umap.learn\n",
    "import umap\n",
    "\n",
    "\n",
    "\n",
    "f_norm, _ = normIt(feat)\n",
    "embedding = umap.UMAP()\n",
    "fUmap = embedding.fit_transform(f_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Spreading evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "# setup\n",
    "lModel = LabelSpreading(gamma=100)\n",
    "gt_use = gt.copy()\n",
    "#gt_use = gtCoarse.copy()\n",
    "#########\n",
    "\n",
    "\n",
    "samplePerClass = 1\n",
    "numClass = int(max(gt_use)+1)\n",
    "ind = []\n",
    "for i in range(numClass):\n",
    "    index = list(np.where(gt_use==i)[0])\n",
    "    if len(index) == 0:\n",
    "        continue\n",
    "    index = random.sample(index, samplePerClass);\n",
    "    ind = ind + (index)\n",
    "#ind = random.sample(range(pp_s.shape[0]), numClass*samplePerClass);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours\n",
      "Precision: 0.825\n",
      "map: 0.9168310383725005\n"
     ]
    }
   ],
   "source": [
    "print('Ours')\n",
    "\n",
    "\n",
    "lModel.fit(pp_s[ind], gt_use[ind])\n",
    "label = lModel.predict(pp_s)\n",
    "score = np.max(lModel.predict_proba(pp_s), axis=1)\n",
    "\n",
    "\n",
    "print('Precision:', np.sum(label==gt_use)/label.size)\n",
    "print('map:', average_precision_score(label==gt_use, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "Precision: 0.4896153846153846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/_label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/_label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-a56868989fe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Precision:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mgt_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'map:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mgt_use\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    213\u001b[0m                                 pos_label=pos_label)\n\u001b[1;32m    214\u001b[0m     return _average_binary_score(average_precision, y_true, y_score,\n\u001b[0;32m--> 215\u001b[0;31m                                  average, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_uninterpolated_average_precision\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    194\u001b[0m             y_true, y_score, pos_label=1, sample_weight=None):\n\u001b[1;32m    195\u001b[0m         precision, recall, _ = precision_recall_curve(\n\u001b[0;32m--> 196\u001b[0;31m             y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Return the step function integral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# The following works because the last entry of precision is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    671\u001b[0m     fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n\u001b[1;32m    672\u001b[0m                                              \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                                              sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mallow_nan\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print('PCA')\n",
    "\n",
    "f_norm, _ = normIt(feat)\n",
    "\n",
    "pca = PCA(n_components=pp.shape[1])\n",
    "f_pca = pca.fit_transform(f_norm)\n",
    "\n",
    "\n",
    "\n",
    "lModel.fit(f_pca[ind], gt_use[ind])\n",
    "label = lModel.predict(f_pca)\n",
    "score = np.max(lModel.predict_proba(f_pca), axis=1)\n",
    "\n",
    "print('Precision:', np.sum(label==gt_use)/label.size)\n",
    "print('map:', average_precision_score(label==gt_use, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/_label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/_label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.13723076923076924\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-1bba2e9958f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Precision:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mgt_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'map:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mgt_use\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    213\u001b[0m                                 pos_label=pos_label)\n\u001b[1;32m    214\u001b[0m     return _average_binary_score(average_precision, y_true, y_score,\n\u001b[0;32m--> 215\u001b[0;31m                                  average, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_uninterpolated_average_precision\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    194\u001b[0m             y_true, y_score, pos_label=1, sample_weight=None):\n\u001b[1;32m    195\u001b[0m         precision, recall, _ = precision_recall_curve(\n\u001b[0;32m--> 196\u001b[0;31m             y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Return the step function integral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# The following works because the last entry of precision is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    671\u001b[0m     fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n\u001b[1;32m    672\u001b[0m                                              \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                                              sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mallow_nan\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "print('Naive')\n",
    "\n",
    "\n",
    "\n",
    "lModel.fit(f_norm[ind], gt_use[ind])\n",
    "label = lModel.predict(f_norm)\n",
    "score = np.max(lModel.predict_proba(f_norm), axis=1)\n",
    "\n",
    "\n",
    "print('Precision:', np.sum(label==gt_use)/label.size)\n",
    "print('map:', average_precision_score(label==gt_use, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('UMAP')\n",
    "\n",
    "lModel.fit(fUmap[ind], gt_use[ind])\n",
    "label = lModel.predict(fUmap)\n",
    "score = np.max(lModel.predict_proba(fUmap), axis=1)\n",
    "\n",
    "print('Precision:', np.sum(label==gt_use)/label.size)\n",
    "print('map:', average_precision_score(label==gt_use, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Feature Goodness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error of  0.675846 from 10 nearest neighbors\n",
      "num dimenions: 180\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def test_feat(feat, labels, nBest= 1000):\n",
    "    num_feat = feat.shape[0]\n",
    "    d = pairwise_distances(feat)\n",
    "    ind = np.argsort(d, axis =1)\n",
    "    \n",
    "    err = np.zeros(num_feat)\n",
    "    \n",
    "    for i in range(num_feat):\n",
    "        l = labels[ind[i,:nBest+1]]      \n",
    "        err[i] = nBest - (sum((l-l[0]) == 0))+1\n",
    "                          \n",
    "    return err\n",
    "\n",
    "\n",
    "\n",
    "nBest = 10\n",
    "\n",
    "err = test_feat(pp_s2[1::2], gt[1::2], nBest=nBest)\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', pp_s2.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error of  0.663846 from 10 nearest neighbors\n",
      "num dimenions: 182\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "err = test_feat(pp_s[1::2], gtAll[1::2], nBest=nBest)\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', pp.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error of  0.713538 from 10 nearest neighbors\n",
      "num dimenions: 182\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f_norm, m_ = normIt(feat[::2])\n",
    "\n",
    "pca = PCA(n_components=pp.shape[1])\n",
    "f_pca = pca.fit_transform(f_norm)\n",
    "\n",
    "err = test_feat(f_pca[1::2], gt[1::2], nBest=nBest)\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', pp.shape[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBest = 1\n",
    "\n",
    "af, _ = normIt(allFeat, m_)\n",
    "f_pca = pca.transform(af)\n",
    "\n",
    "err = test_feat(f_pca[1::2], gtAll[1::2], nBest=nBest)\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', pp.shape[1])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
