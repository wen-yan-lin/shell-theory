{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# allFeat = np.load('/tf/notebooks/clusteringTree/stl_feat/feats_2048.npy')\n",
    "# gtAll = np.load('/tf/notebooks/clusteringTree/stl_feat/labels_2048.npy')-1\n",
    "\n",
    "# allFeat = np.load('/tf/notebooks/STL-10/danielFeat.npy')\n",
    "# gtAll = np.load('/tf/notebooks/STL-10/danielGt.npy')\n",
    "\n",
    "\n",
    "\n",
    "allFeat = np.load('/tf/notebooks/Food59/train/resNet50.npy')\n",
    "gtAll = np.load('/tf/notebooks/Food59/train/gt.npy')\n",
    "\n",
    "mask = gtAll<5\n",
    "allFeat = allFeat[mask]\n",
    "gtAll = gtAll[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from clusteringX2 import normIt\n",
    "from clusteringX2 import clusterModel\n",
    "from clusteringX2 import train_step3\n",
    "\n",
    "\n",
    "def clustering(feat, numClass=60, thres=0.1):\n",
    "    feat, m = normIt(feat)\n",
    "    \n",
    "    # initilization\n",
    "    kmeans = KMeans(n_clusters=numClass, random_state=0).fit(feat)\n",
    "    labelK = kmeans.predict(feat)\n",
    "    means =np.zeros([numClass, feat.shape[1]])\n",
    "\n",
    "    for i in range(numClass):\n",
    "        mask = labelK == i\n",
    "        means[i,:] = np.mean(feat[mask,:], axis =0)\n",
    "\n",
    "    sigInit = np.zeros([numClass])\n",
    "    for i in range(numClass):\n",
    "        mask = np.logical_not(labelK == i)\n",
    "        sigInit[i] = np.mean(np.matmul(feat[mask,:], np.transpose(means[i,:])))\n",
    "    model = clusterModel(means.transpose(), sigInit)\n",
    "    train_step3(model, feat.astype(\"float32\"), iter =100)\n",
    "    \n",
    "    \n",
    "    \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    s = np.max(c, axis=1)\n",
    "    t = np.mean(s)\n",
    "    mask = s > t*0.5\n",
    "    train_step3(model, feat[mask,:].astype(\"float32\"), iter =100)\n",
    "    \n",
    "    \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    s = np.max(c, axis=1)\n",
    "    t = np.mean(s)\n",
    "    mask = s > t*0.5\n",
    "    train_step3(model, feat[mask,:].astype(\"float32\"), iter =100)\n",
    "\n",
    " \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    labels = np.argmax(c, axis =1)\n",
    "    mask_ = np.zeros(numClass, dtype=bool)\n",
    "        \n",
    "    for i in range(numClass):\n",
    "        if np.sum(labels==i)>0:\n",
    "            mask_[i] = 1\n",
    "    w = model.w.numpy()\n",
    "    sig = model.sig.numpy()\n",
    "    w = w[:,mask_]\n",
    "    sig = sig[mask_]\n",
    "            \n",
    "\n",
    "    return w, sig, m, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, mask=None, w=None, sig=None, m=None):\n",
    "        self.mask = mask\n",
    "        self.w = w\n",
    "        self.sig = sig\n",
    "        self.m = m\n",
    "            \n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.nodeList = []\n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self):\n",
    "        self.numLayers = 0\n",
    "        self.listOfLayers = []\n",
    "        self.numNodes = 0\n",
    "        self.listOfNodes = []\n",
    "        \n",
    "    def addNode(self, c):\n",
    "        self.listOfNodes.append(c)\n",
    "        self.numNodes = self.numNodes + 1\n",
    "        \n",
    "    def addLayer(self, c):\n",
    "        self.listOfLayers.append(c)\n",
    "        self.numLayers = self.numLayers + 1\n",
    "\n",
    "    \n",
    "def startTree(allFeat, numClass=2):\n",
    "    tree = Tree()    \n",
    "    w, sig, m, inMask = clustering(allFeat, numClass)\n",
    "    mask = np.ones(allFeat.shape[0], dtype=bool)\n",
    "    #mask[np.logical_not(inMask)] = 0\n",
    "    n = Node(mask, w, sig, m)\n",
    "\n",
    "    tree.addNode(n)\n",
    "    newLayer = Layer()\n",
    "    newLayer.nodeList.append(tree.numNodes-1)\n",
    "    tree.addLayer(newLayer)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "    \n",
    "#mask = np.logical_or(gtAll==3,  gtAll==4)\n",
    "mask = gtAll<10\n",
    "\n",
    "feat = allFeat[mask,:]\n",
    "gt = gtAll[mask]    \n",
    "gtCoarseAll = np.logical_or.reduce( [gtAll == 0, gtAll == 2, gtAll == 8, gtAll == 9]).astype(int)   \n",
    "gtCoarse = gtCoarseAll[mask]\n",
    "\n",
    "tree = startTree(feat[::2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataProjection(feat, node):\n",
    "    x, _ = normIt(feat, node.m) \n",
    "    return np.matmul(x, node.w) - node.sig\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def extendTree(tree, allFeat, numClass=2, clusteringThreshold=100):\n",
    "    newLayer = Layer()\n",
    "    lastLayer = tree.listOfLayers[-1]\n",
    "    for nodeIndex in lastLayer.nodeList:\n",
    "        node = tree.listOfNodes[nodeIndex]\n",
    "        curFeat = allFeat[node.mask,:]\n",
    "        score = dataProjection(curFeat, node)\n",
    "        #plt.scatter(score[:,0], score[:,1], alpha=0.1)\n",
    "        \n",
    "        clusterInd = np.argmax(score, axis =1)\n",
    "        curInd = np.where(node.mask)[0]\n",
    "\n",
    "        for i in range(score.shape[1]):\n",
    "            subMask = clusterInd == i\n",
    "            if sum(subMask) > clusteringThreshold:\n",
    "                \n",
    "                newMask =  np.zeros(allFeat.shape[0], dtype=bool)\n",
    "                newMask[curInd[subMask]] = 1\n",
    "                \n",
    "\n",
    "                w, sig, m, inMask = clustering(allFeat[newMask,:], numClass)\n",
    "                #subInd = np.where(newMask)[0]\n",
    "                #newMask[subInd[np.logical_not(inMask)]] = 0\n",
    "\n",
    "                if w.shape[1]>=2:\n",
    "                    n = Node(newMask, w, sig, m)\n",
    "                    tree.addNode(n)\n",
    "                    newLayer.nodeList.append(tree.numNodes-1)\n",
    "    tree.addLayer(newLayer)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "for k in range(100):\n",
    "    extendTree(tree, feat[::2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projectTree2(feat, tree, maxClus=2, unit_vector=True, scale2data=True, verboise=True):\n",
    "    \n",
    "    projectionSpace = np.zeros([feat.shape[0], tree.numNodes*maxClus])\n",
    "    \n",
    "    cur = 0\n",
    "    \n",
    "    for i, n in enumerate(tree.listOfNodes):\n",
    "        \n",
    "        f = dataProjection(feat, n)\n",
    "        numDim = f.shape[1]\n",
    "        if unit_vector:\n",
    "            f_ = np.concatenate([f, 10*np.ones([f.shape[0],1])], axis =1)\n",
    "            f_ = f_/np.linalg.norm(f_, axis =1, keepdims=True)\n",
    "            f = f_[:,:numDim]\n",
    "        if scale2data:\n",
    "            f = f*np.sum(n.mask)/n.mask.size \n",
    "        projectionSpace[:, cur:cur+numDim] = f\n",
    "        cur = cur+numDim\n",
    "        \n",
    "        if verboise == True:\n",
    "            print(i, n)\n",
    "    projectionSpace = projectionSpace[:,:cur]\n",
    "    return projectionSpace\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Feature\n",
      "0 <__main__.Node object at 0x7f66bc140b38>\n",
      "1 <__main__.Node object at 0x7f660811a978>\n",
      "2 <__main__.Node object at 0x7f66bf708160>\n",
      "3 <__main__.Node object at 0x7f65e8488a90>\n",
      "4 <__main__.Node object at 0x7f66080e94a8>\n",
      "5 <__main__.Node object at 0x7f65e8396e10>\n",
      "6 <__main__.Node object at 0x7f65e841fa20>\n",
      "7 <__main__.Node object at 0x7f65e8264ba8>\n",
      "8 <__main__.Node object at 0x7f65e8290898>\n",
      "9 <__main__.Node object at 0x7f65e8348c18>\n",
      "10 <__main__.Node object at 0x7f65e8188e48>\n",
      "11 <__main__.Node object at 0x7f65e8108b38>\n",
      "12 <__main__.Node object at 0x7f65e81d9be0>\n",
      "13 <__main__.Node object at 0x7f65e8073668>\n",
      "14 <__main__.Node object at 0x7f65e07c9fd0>\n",
      "15 <__main__.Node object at 0x7f65e0763ba8>\n",
      "16 <__main__.Node object at 0x7f65e07e5f28>\n",
      "17 <__main__.Node object at 0x7f65e06c16a0>\n",
      "18 <__main__.Node object at 0x7f65e825e518>\n",
      "19 <__main__.Node object at 0x7f65e067d1d0>\n",
      "20 <__main__.Node object at 0x7f65e07d5b70>\n",
      "21 <__main__.Node object at 0x7f65e05f8c88>\n",
      "22 <__main__.Node object at 0x7f65e0634be0>\n",
      "23 <__main__.Node object at 0x7f65e0509b38>\n",
      "24 <__main__.Node object at 0x7f65e053beb8>\n",
      "25 <__main__.Node object at 0x7f65e047ada0>\n",
      "26 <__main__.Node object at 0x7f65e040b1d0>\n",
      "27 <__main__.Node object at 0x7f65e0499ba8>\n",
      "28 <__main__.Node object at 0x7f65e042cf98>\n",
      "29 <__main__.Node object at 0x7f65e03aafd0>\n",
      "30 <__main__.Node object at 0x7f65e05adf28>\n",
      "31 <__main__.Node object at 0x7f65e0302e10>\n",
      "32 <__main__.Node object at 0x7f65e032ac50>\n",
      "33 <__main__.Node object at 0x7f65e0239f28>\n",
      "num dimenions: 68\n"
     ]
    }
   ],
   "source": [
    "print('Create Feature')\n",
    "\n",
    "projectionSpace = projectTree2(feat, tree, unit_vector=True, scale2data=True)\n",
    "pp = projectionSpace.copy()\n",
    "pp_s, _ = normIt(pp)\n",
    "\n",
    "print('num dimenions:', pp_s.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <__main__.Node object at 0x7f66bc140b38>\n",
      "1 <__main__.Node object at 0x7f660811a978>\n",
      "2 <__main__.Node object at 0x7f66bf708160>\n",
      "3 <__main__.Node object at 0x7f65e8488a90>\n",
      "4 <__main__.Node object at 0x7f66080e94a8>\n",
      "5 <__main__.Node object at 0x7f65e8396e10>\n",
      "6 <__main__.Node object at 0x7f65e841fa20>\n",
      "7 <__main__.Node object at 0x7f65e8264ba8>\n",
      "8 <__main__.Node object at 0x7f65e8290898>\n",
      "9 <__main__.Node object at 0x7f65e8348c18>\n",
      "10 <__main__.Node object at 0x7f65e8188e48>\n",
      "11 <__main__.Node object at 0x7f65e8108b38>\n",
      "12 <__main__.Node object at 0x7f65e81d9be0>\n",
      "13 <__main__.Node object at 0x7f65e8073668>\n",
      "14 <__main__.Node object at 0x7f65e07c9fd0>\n",
      "15 <__main__.Node object at 0x7f65e0763ba8>\n",
      "16 <__main__.Node object at 0x7f65e07e5f28>\n",
      "17 <__main__.Node object at 0x7f65e06c16a0>\n",
      "18 <__main__.Node object at 0x7f65e825e518>\n",
      "19 <__main__.Node object at 0x7f65e067d1d0>\n",
      "20 <__main__.Node object at 0x7f65e07d5b70>\n",
      "21 <__main__.Node object at 0x7f65e05f8c88>\n",
      "22 <__main__.Node object at 0x7f65e0634be0>\n",
      "23 <__main__.Node object at 0x7f65e0509b38>\n",
      "24 <__main__.Node object at 0x7f65e053beb8>\n",
      "25 <__main__.Node object at 0x7f65e047ada0>\n",
      "26 <__main__.Node object at 0x7f65e040b1d0>\n",
      "27 <__main__.Node object at 0x7f65e0499ba8>\n",
      "28 <__main__.Node object at 0x7f65e042cf98>\n",
      "29 <__main__.Node object at 0x7f65e03aafd0>\n",
      "30 <__main__.Node object at 0x7f65e05adf28>\n",
      "31 <__main__.Node object at 0x7f65e0302e10>\n",
      "32 <__main__.Node object at 0x7f65e032ac50>\n",
      "33 <__main__.Node object at 0x7f65e0239f28>\n",
      "num dimenions: 68\n"
     ]
    }
   ],
   "source": [
    "projectionSpace = projectTree2(feat, tree, unit_vector=True, scale2data=True)\n",
    "pp = projectionSpace.copy()\n",
    "pp_s, _ = normIt(pp)\n",
    "\n",
    "print('num dimenions:', pp_s.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree2 = startTree(pp_s[::2])\n",
    "\n",
    "\n",
    "for k in range(100):\n",
    "    extendTree(tree2, pp_s[::2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 <__main__.Node object at 0x7f66bf6f5c88>\n",
      "1 <__main__.Node object at 0x7f65e01a2c50>\n",
      "2 <__main__.Node object at 0x7f66a686bb70>\n",
      "3 <__main__.Node object at 0x7f65b03aa1d0>\n",
      "4 <__main__.Node object at 0x7f65b03c2d68>\n",
      "5 <__main__.Node object at 0x7f65e0187cc0>\n",
      "6 <__main__.Node object at 0x7f65b0322a20>\n",
      "7 <__main__.Node object at 0x7f65b02d1f60>\n",
      "8 <__main__.Node object at 0x7f65b0222eb8>\n",
      "9 <__main__.Node object at 0x7f65b0071ef0>\n",
      "10 <__main__.Node object at 0x7f65907d1128>\n",
      "11 <__main__.Node object at 0x7f65906fdcc0>\n",
      "12 <__main__.Node object at 0x7f65906a6860>\n",
      "13 <__main__.Node object at 0x7f65905cfdd8>\n",
      "14 <__main__.Node object at 0x7f65904fef98>\n",
      "15 <__main__.Node object at 0x7f65904adb00>\n",
      "16 <__main__.Node object at 0x7f659043b198>\n",
      "17 <__main__.Node object at 0x7f6590309e10>\n",
      "18 <__main__.Node object at 0x7f6590565940>\n",
      "19 <__main__.Node object at 0x7f65902249e8>\n",
      "20 <__main__.Node object at 0x7f6590298208>\n",
      "21 <__main__.Node object at 0x7f659018fdd8>\n",
      "22 <__main__.Node object at 0x7f65901207b8>\n",
      "23 <__main__.Node object at 0x7f6590099a90>\n",
      "24 <__main__.Node object at 0x7f65706f4cc0>\n",
      "25 <__main__.Node object at 0x7f65706d7ac8>\n",
      "26 <__main__.Node object at 0x7f65707aaf28>\n",
      "27 <__main__.Node object at 0x7f657051c9e8>\n",
      "28 <__main__.Node object at 0x7f657058c8d0>\n",
      "29 <__main__.Node object at 0x7f6570390ba8>\n",
      "30 <__main__.Node object at 0x7f6570280f60>\n",
      "31 <__main__.Node object at 0x7f657034cb38>\n",
      "32 <__main__.Node object at 0x7f65702d9cf8>\n",
      "33 <__main__.Node object at 0x7f6570168e10>\n",
      "num dimenions: 68\n"
     ]
    }
   ],
   "source": [
    "projectionSpace2 = projectTree2(pp_s, tree2, unit_vector=True, scale2data=True)\n",
    "pp2 = projectionSpace2.copy()\n",
    "pp_s2, _ = normIt(pp2)\n",
    "\n",
    "print('num dimenions:', pp_s2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create UMAP Feature\n",
      "Collecting umap.learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/92/36bac74962b424870026cb0b42cec3d5b6f4afa37d81818475d8762f9255/umap-learn-0.3.10.tar.gz (40kB)\n",
      "\u001b[K     |████████████████████████████████| 40kB 4.5MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.6/dist-packages (from umap.learn) (1.18.1)\n",
      "Requirement already satisfied: scikit-learn>=0.16 in /usr/local/lib/python3.6/dist-packages (from umap.learn) (0.22.1)\n",
      "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from umap.learn) (1.4.1)\n",
      "Collecting numba>=0.37\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ba/49/61522f34b1333aa4e9aa02005dc0774d25bd234400dff718b16615d6a744/numba-0.48.0-cp36-cp36m-manylinux1_x86_64.whl (2.5MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5MB 9.5MB/s eta 0:00:01     |██████████████████▍             | 1.4MB 9.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.16->umap.learn) (0.14.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.37->umap.learn) (44.0.0)\n",
      "Collecting llvmlite<0.32.0,>=0.31.0dev0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ad/bb/60d4033d56c9da36490af19caa6c794b72b8aef6f792fdfa8cb95d11e419/llvmlite-0.31.0-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n",
      "\u001b[K     |████████████████████████████████| 20.2MB 17.8MB/s eta 0:00:01    |███████████████▋                | 9.8MB 17.8MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: umap.learn\n",
      "  Building wheel for umap.learn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for umap.learn: filename=umap_learn-0.3.10-cp36-none-any.whl size=44352 sha256=b1a0c354e6fb279c0dc343a22718a1b4ea542c609b376d0172ba84cb74939772\n",
      "  Stored in directory: /root/.cache/pip/wheels/d0/f8/d5/8e3af3ee957feb9b403a060ebe72f7561887fef9dea658326e\n",
      "Successfully built umap.learn\n",
      "Installing collected packages: llvmlite, numba, umap.learn\n",
      "Successfully installed llvmlite-0.31.0 numba-0.48.0 umap.learn\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numba/typed_passes.py:293: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../usr/local/lib/python3.6/dist-packages/umap/rp_tree.py\", line 135:\n",
      "@numba.njit(fastmath=True, nogil=True, parallel=True)\n",
      "def euclidean_random_projection_split(data, indices, rng_state):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/usr/local/lib/python3.6/dist-packages/umap/nndescent.py:92: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../usr/local/lib/python3.6/dist-packages/umap/utils.py\", line 409:\n",
      "@numba.njit(parallel=True)\n",
      "def build_candidates(current_graph, n_vertices, n_neighbors, max_candidates, rng_state):\n",
      "^\n",
      "\n",
      "  current_graph, n_vertices, n_neighbors, max_candidates, rng_state\n",
      "/usr/local/lib/python3.6/dist-packages/numba/typed_passes.py:293: NumbaPerformanceWarning: \n",
      "The keyword argument 'parallel=True' was specified but no transformation for parallel execution was possible.\n",
      "\n",
      "To find out why, try turning on parallel diagnostics, see http://numba.pydata.org/numba-doc/latest/user/parallel.html#diagnostics for help.\n",
      "\n",
      "File \"../../../usr/local/lib/python3.6/dist-packages/umap/nndescent.py\", line 47:\n",
      "    @numba.njit(parallel=True)\n",
      "    def nn_descent(\n",
      "    ^\n",
      "\n",
      "  state.func_ir.loc))\n"
     ]
    }
   ],
   "source": [
    "print('Create UMAP Feature')\n",
    "\n",
    "! pip3 install umap.learn\n",
    "import umap\n",
    "\n",
    "\n",
    "\n",
    "f_norm, _ = normIt(feat)\n",
    "embedding = umap.UMAP()\n",
    "fUmap = embedding.fit_transform(f_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Spreading evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "# setup\n",
    "lModel = LabelSpreading(gamma=100)\n",
    "gt_use = gt.copy()\n",
    "#gt_use = gtCoarse.copy()\n",
    "#########\n",
    "\n",
    "\n",
    "samplePerClass = 1\n",
    "numClass = int(max(gt_use)+1)\n",
    "ind = []\n",
    "for i in range(numClass):\n",
    "    index = list(np.where(gt_use==i)[0])\n",
    "    if len(index) == 0:\n",
    "        continue\n",
    "    index = random.sample(index, samplePerClass);\n",
    "    ind = ind + (index)\n",
    "#ind = random.sample(range(pp_s.shape[0]), numClass*samplePerClass);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours\n",
      "Precision: 0.5265795206971677\n",
      "map: 0.7738439553435263\n"
     ]
    }
   ],
   "source": [
    "print('Ours')\n",
    "\n",
    "\n",
    "lModel.fit(pp_s[ind], gt_use[ind])\n",
    "label = lModel.predict(pp_s)\n",
    "score = np.max(lModel.predict_proba(pp_s), axis=1)\n",
    "\n",
    "\n",
    "print('Precision:', np.sum(label==gt_use)/label.size)\n",
    "print('map:', average_precision_score(label==gt_use, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ours\n",
      "Precision: 0.4871459694989107\n",
      "map: 0.7645141883126317\n"
     ]
    }
   ],
   "source": [
    "print('Ours')\n",
    "\n",
    "\n",
    "lModel.fit(pp_s2[ind], gt_use[ind])\n",
    "label = lModel.predict(pp_s2)\n",
    "score = np.max(lModel.predict_proba(pp_s2), axis=1)\n",
    "\n",
    "\n",
    "print('Precision:', np.sum(label==gt_use)/label.size)\n",
    "print('map:', average_precision_score(label==gt_use, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA\n",
      "Precision: 0.5738562091503268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/_label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/_label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-a56868989fe3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Precision:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mgt_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'map:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mgt_use\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    213\u001b[0m                                 pos_label=pos_label)\n\u001b[1;32m    214\u001b[0m     return _average_binary_score(average_precision, y_true, y_score,\n\u001b[0;32m--> 215\u001b[0;31m                                  average, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_uninterpolated_average_precision\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    194\u001b[0m             y_true, y_score, pos_label=1, sample_weight=None):\n\u001b[1;32m    195\u001b[0m         precision, recall, _ = precision_recall_curve(\n\u001b[0;32m--> 196\u001b[0;31m             y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Return the step function integral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# The following works because the last entry of precision is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    671\u001b[0m     fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n\u001b[1;32m    672\u001b[0m                                              \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                                              sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mallow_nan\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print('PCA')\n",
    "\n",
    "f_norm, _ = normIt(feat)\n",
    "\n",
    "pca = PCA(n_components=pp.shape[1])\n",
    "f_pca = pca.fit_transform(f_norm)\n",
    "\n",
    "\n",
    "\n",
    "lModel.fit(f_pca[ind], gt_use[ind])\n",
    "label = lModel.predict(f_pca)\n",
    "score = np.max(lModel.predict_proba(f_pca), axis=1)\n",
    "\n",
    "print('Precision:', np.sum(label==gt_use)/label.size)\n",
    "print('map:', average_precision_score(label==gt_use, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive\n",
      "Precision: 0.0869281045751634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/_label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/_label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-1bba2e9958f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Precision:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mgt_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'map:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mgt_use\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    213\u001b[0m                                 pos_label=pos_label)\n\u001b[1;32m    214\u001b[0m     return _average_binary_score(average_precision, y_true, y_score,\n\u001b[0;32m--> 215\u001b[0;31m                                  average, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_uninterpolated_average_precision\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    194\u001b[0m             y_true, y_score, pos_label=1, sample_weight=None):\n\u001b[1;32m    195\u001b[0m         precision, recall, _ = precision_recall_curve(\n\u001b[0;32m--> 196\u001b[0;31m             y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Return the step function integral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# The following works because the last entry of precision is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    671\u001b[0m     fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n\u001b[1;32m    672\u001b[0m                                              \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                                              sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mallow_nan\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "print('Naive')\n",
    "\n",
    "\n",
    "\n",
    "lModel.fit(f_norm[ind], gt_use[ind])\n",
    "label = lModel.predict(f_norm)\n",
    "score = np.max(lModel.predict_proba(f_norm), axis=1)\n",
    "\n",
    "\n",
    "print('Precision:', np.sum(label==gt_use)/label.size)\n",
    "print('map:', average_precision_score(label==gt_use, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UMAP\n",
      "Precision: 0.3989106753812636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/_label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/semi_supervised/_label_propagation.py:201: RuntimeWarning: invalid value encountered in true_divide\n",
      "  probabilities /= normalizer\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-7bd209366086>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Precision:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mgt_use\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'map:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mgt_use\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[0;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    213\u001b[0m                                 pos_label=pos_label)\n\u001b[1;32m    214\u001b[0m     return _average_binary_score(average_precision, y_true, y_score,\n\u001b[0;32m--> 215\u001b[0;31m                                  average, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_uninterpolated_average_precision\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    194\u001b[0m             y_true, y_score, pos_label=1, sample_weight=None):\n\u001b[1;32m    195\u001b[0m         precision, recall, _ = precision_recall_curve(\n\u001b[0;32m--> 196\u001b[0;31m             y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Return the step function integral\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# The following works because the last entry of precision is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    671\u001b[0m     fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n\u001b[1;32m    672\u001b[0m                                              \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m                                              sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtps\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtps\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    540\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mallow_nan\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                     (type_err,\n\u001b[0;32m---> 60\u001b[0;31m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m     \u001b[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "print('UMAP')\n",
    "\n",
    "lModel.fit(fUmap[ind], gt_use[ind])\n",
    "label = lModel.predict(fUmap)\n",
    "score = np.max(lModel.predict_proba(fUmap), axis=1)\n",
    "\n",
    "print('Precision:', np.sum(label==gt_use)/label.size)\n",
    "print('map:', average_precision_score(label==gt_use, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Feature Goodness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error of  112.210893 from 250 nearest neighbors\n",
      "num dimenions: 68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def test_feat(feat, labels, nBest= 1000):\n",
    "    num_feat = feat.shape[0]\n",
    "    d = pairwise_distances(feat)\n",
    "    ind = np.argsort(d, axis =1)\n",
    "    \n",
    "    err = np.zeros(num_feat)\n",
    "    \n",
    "    for i in range(num_feat):\n",
    "        l = labels[ind[i,:nBest+1]]      \n",
    "        err[i] = nBest - (sum((l-l[0]) == 0))+1\n",
    "                          \n",
    "    return err\n",
    "\n",
    "\n",
    "\n",
    "nBest = 250\n",
    "\n",
    "err = test_feat(pp_s2[1::2], gt[1::2], nBest=nBest)\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', pp_s2.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error of  108.026144 from 250 nearest neighbors\n",
      "num dimenions: 68\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "err = test_feat(pp_s[1::2], gtAll[1::2], nBest=nBest)\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', pp.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error of  106.695425 from 250 nearest neighbors\n",
      "num dimenions: 68\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f_norm, m_ = normIt(feat)\n",
    "\n",
    "pca = PCA(pp_s.shape[1])\n",
    "pca.fit(f_norm[::2])\n",
    "f_pca = pca.transform(f_norm)\n",
    "\n",
    "err = test_feat(f_pca[1::2], gt[1::2], nBest=nBest)\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', f_pca.shape[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average error of  105.885839 from 250 nearest neighbors\n",
      "num dimenions: 2048\n"
     ]
    }
   ],
   "source": [
    "f_norm, m_ = normIt(feat)\n",
    "\n",
    "\n",
    "err = test_feat(f_norm[1::2], gtAll[1::2], nBest=nBest)\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', f_norm.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "#distances, indices = nbrs.kneighbors(f_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "nbrs = NearestNeighbors(n_neighbors=1000, algorithm='ball_tree').fit(pp_s2)\n",
    "distances, indices = nbrs.kneighbors(pp_s2[i:i+1,:])\n",
    "print(np.sum(indices<1300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=1000, algorithm='ball_tree').fit(f_norm)\n",
    "distances, indices = nbrs.kneighbors(f_norm[i:i+1,:])\n",
    "print(np.sum(indices<1300))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
