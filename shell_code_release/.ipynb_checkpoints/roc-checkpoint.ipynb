{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "import dirUtil \n",
    "from highDimLearning import vgg2feat\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "import random \n",
    "    \n",
    "\n",
    "def feat2labels(feat):\n",
    "    numClass = len(feat)\n",
    "    numDim = feat[0].shape[1]\n",
    "    numPts = 0\n",
    "    for i in range(numClass):\n",
    "        numPts = numPts + feat[i].shape[0]\n",
    "\n",
    "    allFeat = np.zeros([numPts, numDim])\n",
    "    allLabels = np.zeros(numPts, dtype = int)\n",
    "    cur = 0\n",
    "    for i in range(numClass):\n",
    "        allFeat[cur:cur+feat[i].shape[0],:] = feat[i]\n",
    "        allLabels[cur:cur+feat[i].shape[0]] = i\n",
    "        cur = cur + feat[i].shape[0]\n",
    "    return allFeat, allLabels\n",
    "        \n",
    "    \n",
    "def readNetVlad(folder, numDim =4096):\n",
    "    folderName = os.path.basename(os.path.normpath(folder))\n",
    "    print(folderName)\n",
    "    file = folder +'/vd16_pitts30k_conv5_3_vlad_preL2_intra_white_' +folderName + '_db.bin'    \n",
    "    data = np.fromfile(file, '<f4')\n",
    "    numPts = int(len(data)/numDim)\n",
    "    return np.reshape(data, [numPts, numDim])\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def cluster_acc(Y_pred, Y):\n",
    "    assert Y_pred.size == Y.size\n",
    "    D = max(Y_pred.max(), Y.max())+1\n",
    "    w = np.zeros((D,D), dtype=np.int64)\n",
    "    for i in range(Y_pred.size):\n",
    "        w[Y_pred[i], Y[i]] += 1\n",
    "    \n",
    "    row_ind, col_ind = linear_sum_assignment(w.max() - w)\n",
    "    \n",
    "    print(w[row_ind,col_ind])\n",
    "    return w[row_ind,col_ind].sum()/Y_pred.size, w\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feat = np.load('/media/sliu/New Volume/STL-10/feats_2048.npy')\n",
    "gt = np.load('/media/sliu/New Volume/STL-10/labels_2048.npy')-1\n",
    "\n",
    "mask = gt>-1#np.logical_or(gt==3, gt==4)\n",
    "feat = feat[mask,:]\n",
    "gt = gt[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "K.clear_session()\n",
    "folder = '/media/daniel/D/code/keras-tutorial/animals/dogs/'\n",
    "feats = dirUtil.dir2vgg16(folder)\n",
    "feat1 = vgg2feat(feats)\n",
    "\n",
    "\n",
    "folder2 = '/media/daniel/D/code/keras-tutorial/animals/cats/'\n",
    "tf.reset_default_graph()\n",
    "K.clear_session()\n",
    "feats = dirUtil.dir2vgg16(folder2)\n",
    "feat2 = vgg2feat(feats)\n",
    "\n",
    "folder3 = '/media/daniel/D/code/keras-tutorial/animals/panda/'\n",
    "tf.reset_default_graph()\n",
    "K.clear_session()\n",
    "feats = dirUtil.dir2vgg16(folder3)\n",
    "feat3 = vgg2feat(feats)\n",
    "\n",
    "feat, gt = feat2labels([feat1, feat2, feat3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alley\n",
      "Flickr11K\n"
     ]
    }
   ],
   "source": [
    "#feat1 = readNetVlad('/media/daniel/D/Data/basicMITData/abbey')\n",
    "    \n",
    "#feat2 = readNetVlad('/media/daniel/D/Data/basicMITData/airport_terminal')\n",
    "\n",
    "feat3 = readNetVlad('/media/daniel/D/Data/basicMITData/alley')\n",
    "\n",
    "# feat4 = readNetVlad('/media/daniel/D/Data/basicMITData/amphitheater')\n",
    "\n",
    "feat_test = readNetVlad('/media/daniel/D/Data/Flickr11K')\n",
    "feat, gt = feat2labels([feat3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Training process completed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<hyperFitProjection.HyperFitProjector at 0x7f64d403e668>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "\n",
    "\n",
    "from hyperFitProjection import HyperFitProjector\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "\n",
    "proj = HyperFitProjector(\"merged\")\n",
    "proj.fit_kmeans(feat, n_cluster=3, n_dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors.kde import KernelDensity\n",
    "\n",
    "train = np.matmul(feat[mask],w)-sig\n",
    "test = np.matmul(feat,w)-sig\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.05).fit(train)\n",
    "\n",
    "\n",
    "\n",
    "new_mask = gt>0\n",
    "new_mask[1000:]=1\n",
    "\n",
    "s = kde.score_samples(test)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(gt[new_mask]==0, (s[new_mask]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train  = proj.transform(feat)\n",
    "test  = proj.transform(feat_test)\n",
    "\n",
    "weight = np.matmul(feat,w)-sig\n",
    "weight = np.sum(weight, axis =1)\n",
    "weight = weight-np.min(weight)\n",
    "weight = weight/np.sum(weight)\n",
    "\n",
    "kde = Gaussian_kde_mod(np.transpose(train), bw_method='scott', weights=weight*weight*weight*weight)\n",
    "s = np.zeros(test.shape[0])\n",
    "i = 0\n",
    "ends = 0\n",
    "while(ends<test.shape[0]):\n",
    "    start = i*1000\n",
    "    ends = min(start+1000, s.size)\n",
    "    s[start:ends] =  kde.evaluate(np.transpose(test[start:ends,:]))\n",
    "    i = i+1\n",
    "#s = kde.evaluate(np.transpose(test[:1000,:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from highDimLearningX import estModel22\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "numIter =100\n",
    "mask = gt==0\n",
    "mask[1000:] =0\n",
    "pca = PCA(n_components=numIter)\n",
    "pca.fit(feat[mask,:])\n",
    "m = pca.components_\n",
    "sig = np.mean(np.matmul(feat[mask,:], np.transpose(m)), axis=0)\n",
    "w, sig = estModel22(feat[mask,:], np.transpose(m), sig, numShells=numIter, weight=0.1)\n",
    "score = np.matmul(feat[mask],w)-sig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  45.,  206.,  803., 1957., 3260., 3899., 2224.,  511.,   83.,\n",
       "          12.]),\n",
       " array([-5.89877887e+02, -4.91549100e+02, -3.93220313e+02, -2.94891527e+02,\n",
       "        -1.96562740e+02, -9.82339531e+01,  9.48336306e-02,  9.84236204e+01,\n",
       "         1.96752407e+02,  2.95081194e+02,  3.93409981e+02]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "score = np.matmul(feat,w)-sig\n",
    "\n",
    "s = np.sum(score, axis =1)\n",
    "plt.hist(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7793589743589743\n"
     ]
    }
   ],
   "source": [
    "# ind = np.argsort(np.absolute(s))\n",
    "# print(ind)\n",
    "\n",
    "new_mask = gt>0\n",
    "new_mask[1000:]=1\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(gt[new_mask]==0, (s[new_mask]))\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.matmul(feat,w)-sig\n",
    "s = np.sum(score, axis =1)\n",
    "s = s-np.min(s)\n",
    "\n",
    "dirUtil.sortDirImages_topX('/media/daniel/D/Data/basicMITData/alley', -s, '/media/daniel/D/Data/tmp', 100,\n",
    "                           types=['*.jpg', '*.JPG', '*.png'], size=224, interp='bilinear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.matmul(feat_test,w)-sig\n",
    "s = np.sum(score, axis =1)\n",
    "s = s-np.min(s)\n",
    "\n",
    "\n",
    "dirUtil.sortDirImages_topX('/media/daniel/D/Data/Flickr11K', -s, '/media/daniel/D/Data/tmp', 100,\n",
    "                           types=['*.jpg', '*.JPG', '*.png'], size=224, interp='bilinear')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_train = np.matmul(feat[mask],w)-sig\n",
    "s_test = np.matmul(feat_test,w)-sig\n",
    "\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.01).fit(s_train)\n",
    "s = kde.score_samples(s_test)\n",
    "s = s-np.min(s)\n",
    "\n",
    "dirUtil.sortDirImages('/media/daniel/D/Data/Flickr11K', s, '/media/daniel/D/Data/tmp', types=['*.jpg', '*.JPG', '*.png'], size=224, interp='bilinear')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "s = np.sum(score, axis =1)\n",
    "s = s-np.min(s)\n",
    "\n",
    "dirUtil.sortDirImages('/media/daniel/D/Data/basicMITData/abbey', s, '/media/daniel/D/Data/tmp', types=['*.jpg', '*.JPG', '*.png'], size=224, interp='bilinear')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
