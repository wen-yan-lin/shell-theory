{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# allFeat = np.load('/tf/notebooks/clusteringTree/stl_feat/feats_2048.npy')\n",
    "# gtAll = np.load('/tf/notebooks/clusteringTree/stl_feat/labels_2048.npy')-1\n",
    "\n",
    "# allFeat = np.load('/tf/notebooks/STL-10/danielFeat.npy')\n",
    "# gtAll = np.load('/tf/notebooks/STL-10/danielGt.npy')\n",
    "\n",
    "allFeat = np.load('../MIT-Places/quickTest/resNet50.npy')\n",
    "gtAll = np.load('../MIT-Places/quickTest/gt.npy')\n",
    "\n",
    "\n",
    "\n",
    "# allFeat = np.load('/tf/notebooks/Food59/train/resNet50.npy')\n",
    "# gtAll = np.load('/tf/notebooks/Food59/train/gt.npy')\n",
    "\n",
    "# mask = gtAll<5\n",
    "# allFeat = allFeat[mask]\n",
    "# gtAll = gtAll[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from clusteringX2 import normIt\n",
    "from clusteringX2 import clusterModel\n",
    "from clusteringX2 import train_step3\n",
    "\n",
    "\n",
    "def clustering(feat, numClass=60, thres=0.1):\n",
    "    feat, m = normIt(feat)\n",
    "    \n",
    "    # initilization\n",
    "    kmeans = KMeans(n_clusters=numClass, random_state=0).fit(feat)\n",
    "    labelK = kmeans.predict(feat)\n",
    "    means =np.zeros([numClass, feat.shape[1]])\n",
    "\n",
    "    for i in range(numClass):\n",
    "        mask = labelK == i\n",
    "        means[i,:] = np.mean(feat[mask,:], axis =0)\n",
    "\n",
    "    sigInit = np.zeros([numClass])\n",
    "    for i in range(numClass):\n",
    "        mask = np.logical_not(labelK == i)\n",
    "        sigInit[i] = np.mean(np.matmul(feat[mask,:], np.transpose(means[i,:])))\n",
    "    model = clusterModel(means.transpose(), sigInit)\n",
    "    train_step3(model, feat.astype(\"float32\"), iter =100)\n",
    "    \n",
    "    \n",
    "    \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    s = np.max(c, axis=1)\n",
    "    t = np.mean(s)\n",
    "    mask = s > t*0.5\n",
    "    train_step3(model, feat[mask,:].astype(\"float32\"), iter =100)\n",
    "    \n",
    "    \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    s = np.max(c, axis=1)\n",
    "    t = np.mean(s)\n",
    "    mask = s > t*0.5\n",
    "    train_step3(model, feat[mask,:].astype(\"float32\"), iter =100)\n",
    "\n",
    " \n",
    "    c = model(feat.astype(\"float32\"))\n",
    "    labels = np.argmax(c, axis =1)\n",
    "    mask_ = np.zeros(numClass, dtype=bool)\n",
    "        \n",
    "    for i in range(numClass):\n",
    "        if np.sum(labels==i)>0:\n",
    "            mask_[i] = 1\n",
    "    w = model.w.numpy()\n",
    "    sig = model.sig.numpy()\n",
    "    w = w[:,mask_]\n",
    "    sig = sig[mask_]\n",
    "            \n",
    "\n",
    "    return w, sig, m, mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, mask=None, w=None, sig=None, m=None):\n",
    "        self.mask = mask\n",
    "        self.w = w\n",
    "        self.sig = sig\n",
    "        self.m = m\n",
    "            \n",
    "class Layer:\n",
    "    def __init__(self):\n",
    "        self.nodeList = []\n",
    "        \n",
    "class Tree:\n",
    "    def __init__(self):\n",
    "        self.numLayers = 0\n",
    "        self.listOfLayers = []\n",
    "        self.numNodes = 0\n",
    "        self.listOfNodes = []\n",
    "        \n",
    "    def addNode(self, c):\n",
    "        self.listOfNodes.append(c)\n",
    "        self.numNodes = self.numNodes + 1\n",
    "        \n",
    "    def addLayer(self, c):\n",
    "        self.listOfLayers.append(c)\n",
    "        self.numLayers = self.numLayers + 1\n",
    "\n",
    "    \n",
    "def startTree(allFeat, numClass=2):\n",
    "    tree = Tree()    \n",
    "    w, sig, m, inMask = clustering(allFeat, numClass)\n",
    "    mask = np.ones(allFeat.shape[0], dtype=bool)\n",
    "    #mask[np.logical_not(inMask)] = 0\n",
    "    n = Node(mask, w, sig, m)\n",
    "\n",
    "    tree.addNode(n)\n",
    "    newLayer = Layer()\n",
    "    newLayer.nodeList.append(tree.numNodes-1)\n",
    "    tree.addLayer(newLayer)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "    \n",
    "#mask = np.logical_or(gtAll==3,  gtAll==4)\n",
    "mask = gtAll<10\n",
    "\n",
    "feat = allFeat[mask,:]\n",
    "gt = gtAll[mask]    \n",
    "gtCoarseAll = np.logical_or.reduce( [gtAll == 0, gtAll == 2, gtAll == 8, gtAll == 9]).astype(int)   \n",
    "gtCoarse = gtCoarseAll[mask]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataProjection(feat, node):\n",
    "    x, _ = normIt(feat, node.m) \n",
    "    return np.matmul(x, node.w) - node.sig\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def extendTree(tree, allFeat, numClass=2, clusteringThreshold=100):\n",
    "    newLayer = Layer()\n",
    "    lastLayer = tree.listOfLayers[-1]\n",
    "    for nodeIndex in lastLayer.nodeList:\n",
    "        node = tree.listOfNodes[nodeIndex]\n",
    "        curFeat = allFeat[node.mask,:]\n",
    "        score = dataProjection(curFeat, node)\n",
    "        #plt.scatter(score[:,0], score[:,1], alpha=0.1)\n",
    "        \n",
    "        clusterInd = np.argmax(score, axis =1)\n",
    "        curInd = np.where(node.mask)[0]\n",
    "\n",
    "        for i in range(score.shape[1]):\n",
    "            subMask = clusterInd == i\n",
    "            if sum(subMask) > clusteringThreshold:\n",
    "                \n",
    "                newMask =  np.zeros(allFeat.shape[0], dtype=bool)\n",
    "                newMask[curInd[subMask]] = 1\n",
    "                \n",
    "\n",
    "                w, sig, m, inMask = clustering(allFeat[newMask,:], numClass)\n",
    "                #subInd = np.where(newMask)[0]\n",
    "                #newMask[subInd[np.logical_not(inMask)]] = 0\n",
    "\n",
    "                if w.shape[1]>=2:\n",
    "                    n = Node(newMask, w, sig, m)\n",
    "                    tree.addNode(n)\n",
    "                    newLayer.nodeList.append(tree.numNodes-1)\n",
    "    tree.addLayer(newLayer)\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def buildTree(feat):\n",
    "    \n",
    "    tree = startTree(feat)\n",
    "    for k in range(100):\n",
    "        extendTree(tree, feat)\n",
    "    return tree\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projectTree2(feat, tree, maxClus=2, unit_vector=True, scale2data=True, verboise=True):\n",
    "    \n",
    "    projectionSpace = np.zeros([feat.shape[0], tree.numNodes*maxClus])\n",
    "    \n",
    "    cur = 0\n",
    "    \n",
    "    for i, n in enumerate(tree.listOfNodes):\n",
    "        \n",
    "        f = dataProjection(feat, n)\n",
    "        numDim = f.shape[1]\n",
    "        if unit_vector:\n",
    "            f_ = np.concatenate([f, 10*np.ones([f.shape[0],1])], axis =1)\n",
    "            f_ = f_/np.linalg.norm(f_, axis =1, keepdims=True)\n",
    "            f = f_[:,:numDim]\n",
    "        if scale2data:\n",
    "            f = f*np.sum(n.mask)/n.mask.size \n",
    "        projectionSpace[:, cur:cur+numDim] = f\n",
    "        cur = cur+numDim\n",
    "        \n",
    "        if verboise == True:\n",
    "            print(i, n)\n",
    "    projectionSpace = projectionSpace[:,:cur]\n",
    "    return projectionSpace\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = []\n",
    "hierFeat = []\n",
    "for i in range(1):\n",
    "    if i == 0:\n",
    "        tree = buildTree(feat)\n",
    "        trees.append(tree)\n",
    "        projectionSpace = projectTree2(feat, tree, unit_vector=True, scale2data=True)\n",
    "        pp = projectionSpace.copy()\n",
    "        pp_s, _ = normIt(pp)\n",
    "        hierFeat.append(pp_s)\n",
    "\n",
    "    else:\n",
    "       \n",
    "        tree = buildTree(hierFeat[-1])\n",
    "        trees.append(tree)\n",
    "        projectionSpace = projectTree2(hierFeat[-1], tree, unit_vector=True, scale2data=True)\n",
    "        pp = projectionSpace.copy()\n",
    "        pp_s, _ = normIt(pp)\n",
    "        hierFeat.append(pp_s)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = donk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2path(mask, tree):\n",
    "    pathNode = -1*np.ones([mask.shape[0], len(tree.listOfLayers)+1], dtype=int)\n",
    "    pathNode[:,0] = 0\n",
    "    \n",
    "    pathDim = -1*np.ones([mask.shape[0], len(tree.listOfLayers)+1], dtype=int)\n",
    "\n",
    "    \n",
    "    cur = 0\n",
    "    for i, l in enumerate(tree.listOfLayers):\n",
    "        print('layer:',i)\n",
    "        \n",
    "        for nIndex in l.nodeList:           \n",
    "            \n",
    "            n = tree.listOfNodes[nIndex]\n",
    "            dim = n.w.shape[1]\n",
    "            \n",
    "            \n",
    "            allCur = pathNode[:,i] == nIndex # in node nIndex\n",
    "            sub_mask = mask[:,cur:cur+dim] # with dimenions\n",
    "            ind = np.argmax(sub_mask)\n",
    "\n",
    "            for k in range(dim):\n",
    "                m = np.logical_and(allCur, sub_mask[:,k])\n",
    "                pathDim[m, i] = cur + k \n",
    "\n",
    "            \n",
    "            \n",
    "            if not n.listOfChildren:\n",
    "                cur = cur + dim\n",
    "                continue\n",
    "\n",
    "                        \n",
    "            \n",
    "            for k in range(dim):\n",
    "                m = np.logical_and(allCur, sub_mask[:,k])\n",
    "                pathNode[m, i+1] = n.listOfChildren[k]\n",
    "                \n",
    "                \n",
    "            cur = cur + dim\n",
    "            \n",
    "            \n",
    "    return pathNode, pathDim\n",
    "\n",
    "def label2oneHot(labels):\n",
    "    b = np.zeros((labels.size, labels.max()+1), dtype=bool)\n",
    "    b[np.arange(labels.size),labels] = 1\n",
    "    return b\n",
    "\n",
    "\n",
    "\n",
    "def projectXX(feat, tree, maxClus=60, unit_vector=False, scale2data=False, verboise=True):\n",
    "    projectionSpace = np.zeros([feat.shape[0], tree.numNodes*maxClus])\n",
    "    maskAll = np.zeros([feat.shape[0], tree.numNodes*maxClus])\n",
    "\n",
    "    cur = 0    \n",
    "    for i, l in enumerate(tree.listOfLayers):\n",
    "        for nIndex in l.nodeList:\n",
    "            n = tree.listOfNodes[nIndex]\n",
    "            f, s = dataProjection(feat, n)\n",
    "            numDim = f.shape[1]\n",
    "            lab = np.argmax(f, axis =1)\n",
    "            maskAll[:,cur:cur+numDim] = label2oneHot(lab)\n",
    "            projectionSpace[:,cur:cur+numDim] = f\n",
    "            cur = cur + numDim\n",
    "    projectionSpace = projectionSpace[:,:cur]\n",
    "    maskAll = maskAll[:,:cur]\n",
    "    \n",
    "    return projectionSpace, maskAll\n",
    "\n",
    "\n",
    "ff2, mask2 = projectXX(feat, trees[0])\n",
    "#ff2N = ff2/np.linalg.norm(ff2, axis=1, keepdims=True)\n",
    "pathNode2, pathDim2 = mask2path(mask2, trees[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Create UMAP Feature')\n",
    "\n",
    "! pip3 install umap.learn\n",
    "import umap\n",
    "\n",
    "\n",
    "\n",
    "f_norm, _ = normIt(feat)\n",
    "embedding = umap.UMAP()\n",
    "fUmap = embedding.fit_transform(f_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Spreading evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from sklearn.semi_supervised import LabelSpreading\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "# setup\n",
    "lModel = LabelSpreading(gamma=100)\n",
    "gt_use = gt.copy()\n",
    "#gt_use = gtCoarse.copy()\n",
    "#########\n",
    "\n",
    "\n",
    "samplePerClass = 1000\n",
    "numClass = int(max(gt_use)+1)\n",
    "ind = []\n",
    "for i in range(numClass):\n",
    "    index = list(np.where(gt_use==i)[0])\n",
    "    if len(index) == 0:\n",
    "        continue\n",
    "    index = random.sample(index, samplePerClass);\n",
    "    ind = ind + (index)\n",
    "#ind = random.sample(range(pp_s.shape[0]), numClass*samplePerClass);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ours')\n",
    "\n",
    "\n",
    "lModel.fit(hierFeat[0][ind], gt_use[ind])\n",
    "label = lModel.predict(hierFeat[0])\n",
    "score = np.max(lModel.predict_proba(hierFeat[0]), axis=1)\n",
    "\n",
    "\n",
    "print('Precision:', np.sum(label==gt_use)/label.size)\n",
    "print('map:', average_precision_score(label==gt_use, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Ours')\n",
    "\n",
    "\n",
    "lModel.fit(hierFeat[1][ind], gt_use[ind])\n",
    "label = lModel.predict(hierFeat[1])\n",
    "score = np.max(lModel.predict_proba(hierFeat[1]), axis=1)\n",
    "\n",
    "\n",
    "print('Precision:', np.sum(label==gt_use)/label.size)\n",
    "print('map:', average_precision_score(label==gt_use, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "print('PCA')\n",
    "\n",
    "f_norm, _ = normIt(feat)\n",
    "\n",
    "pca = PCA(n_components=pp.shape[1])\n",
    "f_pca = pca.fit_transform(f_norm)\n",
    "\n",
    "\n",
    "\n",
    "lModel.fit(f_pca[ind], gt_use[ind])\n",
    "label = lModel.predict(f_pca)\n",
    "score = np.max(lModel.predict_proba(f_pca), axis=1)\n",
    "\n",
    "print('Precision:', np.sum(label==gt_use)/label.size)\n",
    "print('map:', average_precision_score(label==gt_use, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Naive')\n",
    "\n",
    "\n",
    "\n",
    "lModel.fit(f_norm[ind], gt_use[ind])\n",
    "label = lModel.predict(f_norm)\n",
    "score = np.max(lModel.predict_proba(f_norm), axis=1)\n",
    "\n",
    "\n",
    "print('Precision:', np.sum(label==gt_use)/label.size)\n",
    "print('map:', average_precision_score(label==gt_use, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('UMAP')\n",
    "\n",
    "lModel.fit(fUmap[ind], gt_use[ind])\n",
    "label = lModel.predict(fUmap)\n",
    "score = np.max(lModel.predict_proba(fUmap), axis=1)\n",
    "\n",
    "print('Precision:', np.sum(label==gt_use)/label.size)\n",
    "print('map:', average_precision_score(label==gt_use, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Feature Goodness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def test_feat(feat, labels, nBest= 1000):\n",
    "    num_feat = feat.shape[0]\n",
    "    d = pairwise_distances(feat)\n",
    "    ind = np.argsort(d, axis =1)\n",
    "    \n",
    "    err = np.zeros(num_feat)\n",
    "    \n",
    "    for i in range(num_feat):\n",
    "        l = labels[ind[i,:nBest+1]]      \n",
    "        err[i] = nBest - (sum((l-l[0]) == 0))+1\n",
    "                          \n",
    "    return err\n",
    "\n",
    "\n",
    "\n",
    "nBest = 100\n",
    "\n",
    "ff = hierFeat[0]\n",
    "\n",
    "err = test_feat(ff, gt, nBest=nBest)\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', ff.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = hierFeat[1]\n",
    "\n",
    "err = test_feat(ff, gt, nBest=nBest)\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', ff.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = hierFeat[2]\n",
    "\n",
    "err = test_feat(ff, gt, nBest=nBest)\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', ff.shape[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f_norm, m_ = normIt(feat)\n",
    "\n",
    "pca = PCA(pp_s.shape[1])\n",
    "pca.fit(f_norm)\n",
    "f_pca = pca.transform(f_norm)\n",
    "\n",
    "err = test_feat(f_pca, gt, nBest=nBest)\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', f_pca.shape[1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "nbrs = NearestNeighbors(n_neighbors=2, algorithm='ball_tree').fit(f_norm)\n",
    "distances, indices = nbrs.kneighbors(f_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = np.zeros(gtAll.size, dtype=int)\n",
    "for i in indices[:,1]:\n",
    "    est[i] = gtAll[i]\n",
    "1-np.sum((est==gtAll))/est.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_norm, m_ = normIt(feat)\n",
    "\n",
    "\n",
    "err = test_feat(f_norm, gtAll, nBest=nBest)\n",
    "print('average error of  %f from %d nearest neighbors'  %(np.mean(err), nBest))\n",
    "\n",
    "print('num dimenions:', f_norm.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "#distances, indices = nbrs.kneighbors(f_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "nbrs = NearestNeighbors(n_neighbors=1000, algorithm='ball_tree').fit(pp_s2)\n",
    "distances, indices = nbrs.kneighbors(pp_s2[i:i+1,:])\n",
    "print(np.sum(indices<1300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbrs = NearestNeighbors(n_neighbors=1000, algorithm='ball_tree').fit(f_norm)\n",
    "distances, indices = nbrs.kneighbors(f_norm[i:i+1,:])\n",
    "print(np.sum(indices<1300))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
