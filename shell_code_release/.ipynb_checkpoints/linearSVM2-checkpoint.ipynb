{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "allFeat = np.load('/tf/notebooks/STL-10/danielFeat.npy')\n",
    "gtAll = np.load('/tf/notebooks/STL-10/danielGt.npy')\n",
    "\n",
    "# allFeat = np.load('/tf/notebooks/clusteringTree/stl_feat/feats_2048.npy')\n",
    "# gtAll = np.load('/tf/notebooks/clusteringTree/stl_feat/labels_2048.npy')-1\n",
    "\n",
    "\n",
    "\n",
    "#m = np.load('/tf/notebooks/Flickr11K/resNet50Mean.npy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "from clusteringX2 import normIt\n",
    "\n",
    "#allFeat = allFeat/np.linalg.norm(allFeat, axis =1, keepdims=True)\n",
    "allFeat, _ = normIt(allFeat)\n",
    "\n",
    "\n",
    "numClass = max(gtAll)+1\n",
    "allMeans = np.zeros([numClass, allFeat.shape[1]])\n",
    "for i in range(numClass):\n",
    "    allMeans[i,:] = np.mean(allFeat[gtAll==i], axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestSplit_oneClass(allFeat, allGt, target, numSamples=300):\n",
    "    mask = np.where(allGt ==target)[0]\n",
    "    trainInd = random.sample(list(mask), numSamples)    \n",
    "    trainFeat = np.copy(allFeat[trainInd])\n",
    "    testFeat = allFeat.copy()\n",
    "    testFeat = np.delete(testFeat, trainInd, axis =0)\n",
    "    testGt = allGt.copy()\n",
    "    testGt = np.delete(testGt, trainInd, axis =0)\n",
    "    return trainFeat, testFeat, testGt\n",
    "\n",
    "def trainTestSplit_multiClass(allFeat, allGt, numSamples=300):\n",
    "    numClass = int(np.max(allGt)+1)\n",
    "    trainFeat = []\n",
    "    testFeat = allFeat.copy()\n",
    "    testGt = allGt.copy()\n",
    "    for i in range(numClass):\n",
    "        trainF, testFeat, testGt = trainTestSplit_oneClass(testFeat, testGt, i, numSamples=numSamples)\n",
    "        trainFeat.append(trainF)\n",
    "        \n",
    "    \n",
    "    return trainFeat, testFeat, testGt\n",
    "        \n",
    "\n",
    "trainFeat, testFeat, testGt = trainTestSplit_multiClass(allFeat, gtAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorted_neighbors_of_i(m_all, i):\n",
    "    neighbors = np.zeros(m_all.shape[0])\n",
    "    for j in range(m_all.shape[0]):\n",
    "        neighbors[j] = np.linalg.norm(m_all[i,:]-m_all[j,:])\n",
    "    return neighbors, np.argsort(neighbors)\n",
    "   \n",
    "    \n",
    "\n",
    "def stacked_classifer(train_feat, target, m_all):\n",
    "    _, neighs = sorted_neighbors_of_i(m_all, target)\n",
    "    classifers = []\n",
    "    current_shell = []\n",
    "    for i in neighs:\n",
    "        current_shell.append(i)\n",
    "        if len(current_shell)> 1:\n",
    "            m1 = np.mean(m_all[current_shell,:], axis =0, keepdims=True)\n",
    "            tf = train_feat-m1\n",
    "            tf = tf/np.linalg.norm(tf, axis =1, keepdims=True)\n",
    "            clf1 = OneClassSVM(gamma='auto').fit(tf)\n",
    "            classifers.append({'mean': m1, 'classifer': clf1})\n",
    "    return classifers\n",
    "\n",
    "def basic_classifer(train_feat):\n",
    "    classifers = []\n",
    "    m1 = 0\n",
    "    clf1 = OneClassSVM(gamma='auto').fit(train_feat)\n",
    "    classifers.append({'mean': m1, 'classifer': clf1})\n",
    "    return classifers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "allClassifiers = []\n",
    "for i in range(numClass):\n",
    "    target = i\n",
    "    m_ex = np.concatenate([np.zeros([1, allMeans.shape[1]]), allMeans])\n",
    "    classifers = stacked_classifer(trainFeat[target], target+1, m_ex)\n",
    "    allClassifiers.append(classifers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_samples(classifers, test_feat):\n",
    "    score = np.zeros([test_feat.shape[0], len(classifers)])\n",
    "    for i in range(len(classifers)):\n",
    "        m = classifers[i]['mean']\n",
    "        tsf = test_feat-m\n",
    "        tsf = tsf/np.linalg.norm(tsf, keepdims=True, axis =1)\n",
    "        s = classifers[i]['classifer'].score_samples(tsf)   \n",
    "        score[:,i] = s\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.zeros([testFeat.shape[0], numClass])\n",
    "\n",
    "for i in range(numClass):\n",
    "    s = score_samples(allClassifiers[i], testFeat)\n",
    "    s = np.mean(s, axis =1)\n",
    "    scores[:,i] = s\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9456\n"
     ]
    }
   ],
   "source": [
    "labelEst = np.argmax(scores, axis=1)\n",
    "print(1-np.mean(labelEst-testGt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "allClassifiersTrad = []\n",
    "for i in range(numClass):\n",
    "    target = i\n",
    "    classifers = basic_classifer(trainFeat[target])\n",
    "    allClassifiersTrad.append(classifers)\n",
    "    \n",
    "scoresTrad = np.zeros([testFeat.shape[0], numClass])\n",
    "\n",
    "for i in range(numClass):\n",
    "    s = score_samples(allClassifiersTrad[i], testFeat)\n",
    "    s = np.mean(s, axis =1)\n",
    "    scoresTrad[:,i] = s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9251\n"
     ]
    }
   ],
   "source": [
    "labelEst = np.argmax(scoresTrad, axis=1)\n",
    "print(1-np.mean(labelEst-testGt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 9, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelEst[2000:2100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trad with mean\n"
     ]
    }
   ],
   "source": [
    "from clusteringX2 import normIt\n",
    "\n",
    "print('trad with mean')\n",
    "\n",
    "test_ , m = normIt(testFeat)\n",
    "\n",
    "\n",
    "allClassifiers_M = []\n",
    "for i in range(numClass):\n",
    "    target = i\n",
    "    train_, _ = normIt(trainFeat[target], m)\n",
    "    classifers = basic_classifer(train_)\n",
    "    allClassifiers_M.append(classifers)\n",
    "    \n",
    "scores_M = np.zeros([testFeat.shape[0], numClass])\n",
    "\n",
    "for i in range(numClass):\n",
    "    s = score_samples(allClassifiers_M[i], test_)\n",
    "    s = np.mean(s, axis =1)\n",
    "    scores_M[:,i] = s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.925\n"
     ]
    }
   ],
   "source": [
    "labelEst = np.argmax(scores_M, axis=1)\n",
    "print(1-np.mean(labelEst-testGt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'donk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-cfd52543731e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdonk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'donk' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "k = donk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "          multi_class='ovr', penalty='l2', random_state=0, tol=1e-05,\n",
       "          verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def listToFeat(feat):\n",
    "    newFeat = np.concatenate(feat, axis =0)\n",
    "    newGt = np.zeros(newFeat.shape[0], dtype = int)\n",
    "    cur = 0\n",
    "    for i in range(len(feat)):\n",
    "        newGt[cur:cur+feat[i].shape[0]] = i\n",
    "        cur = cur + feat[i].shape[0]\n",
    "    return newFeat, newGt\n",
    "\n",
    "trainFeat_, trainGt_ = listToFeat(trainFeat)\n",
    "clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "clf.fit(trainFeat_, trainGt_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.40113885, -1.65779137, -1.02632664, ..., -1.91208265,\n",
       "        -1.2461334 , -0.99414662],\n",
       "       [ 0.73010326, -1.26533078, -1.98539672, ..., -1.23950324,\n",
       "        -0.9643629 , -1.86633478],\n",
       "       [ 1.21727132, -1.63520482, -1.4586674 , ..., -2.08924527,\n",
       "        -1.96796202, -1.16820633],\n",
       "       ...,\n",
       "       [-2.02859228, -2.19715401, -1.67154451, ..., -1.60751096,\n",
       "        -1.5143772 ,  1.69600229],\n",
       "       [-2.03481703, -1.47678657, -0.21152362, ..., -1.86718623,\n",
       "        -2.19325447,  0.21440502],\n",
       "       [-1.6168262 , -1.25752836, -1.73946019, ..., -1.65618936,\n",
       "        -1.58380093,  1.53809126]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.decision_function(testFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9804\n"
     ]
    }
   ],
   "source": [
    "labelEst = clf.predict(testFeat)\n",
    "print(1-np.mean(labelEst-testGt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(allMeans.shape)\n",
    "numClass = allMeans.shape[0]\n",
    "\n",
    "def sorted_neighbors_of_i(m_all, i):\n",
    "    neighbors = np.zeros(m_all.shape[0])\n",
    "    for j in range(m_all.shape[0]):\n",
    "        neighbors[j] = np.linalg.norm(m_all[i,:]-m_all[j,:])\n",
    "    return neighbors, np.argsort(neighbors)\n",
    "   \n",
    "    \n",
    "\n",
    "def stacked_classifer_LinSVM(train_feat, target, m_all, gt):\n",
    "    mask = gt == target\n",
    "    _, neighs = sorted_neighbors_of_i(m_all, target)\n",
    "    classifers = []\n",
    "    current_shell = []\n",
    "    for i in neighs:\n",
    "        current_shell.append(i)\n",
    "        if len(current_shell)> 1:\n",
    "            m1 = np.mean(m_all[current_shell,:], axis =0, keepdims=True)\n",
    "            tf = train_feat-m1\n",
    "            tf = tf/np.linalg.norm(tf, axis =1, keepdims=True)\n",
    "            clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "            clf.fit(trainFeat_, mask)\n",
    "            classifers.append({'mean': m1, 'classifer': clf})\n",
    "    return classifers\n",
    "\n",
    "\n",
    "allClassifiers = []\n",
    "target = 0\n",
    "m_ex = np.concatenate([np.zeros([1, allMeans.shape[1]]), allMeans])\n",
    "classifers = stacked_classifer_LinSVM(trainFeat_, target+1, m_ex, trainGt_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean': array([[-0.00027645,  0.00014985,  0.00465344, ...,  0.00164049,\n",
       "         -0.00355006,  0.00110171]]),\n",
       " 'classifer': LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "           intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "           multi_class='ovr', penalty='l2', random_state=0, tol=1e-05,\n",
       "           verbose=0)}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classifyTest(classifers, feat):\n",
    "    for i in range(len(classifers)):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allClassifiers = []\n",
    "for i in range(numClass):\n",
    "    target = i\n",
    "    m_ex = np.concatenate([np.zeros([1, allMeans.shape[1]]), allMeans])\n",
    "    classifers = stacked_classifer(trainFeat[target], target+1, m_ex)\n",
    "    allClassifiers.append(classifers)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
