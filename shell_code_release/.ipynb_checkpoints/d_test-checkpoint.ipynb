{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/daniel/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "import dirUtil \n",
    "from highDimLearning import vgg2feat\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "import random \n",
    "    \n",
    "\n",
    "def feat2labels(feat):\n",
    "    numClass = len(feat)\n",
    "    numDim = feat[0].shape[1]\n",
    "    numPts = 0\n",
    "    for i in range(numClass):\n",
    "        numPts = numPts + feat[i].shape[0]\n",
    "\n",
    "    allFeat = np.zeros([numPts, numDim])\n",
    "    allLabels = np.zeros(numPts, dtype = int)\n",
    "    cur = 0\n",
    "    for i in range(numClass):\n",
    "        allFeat[cur:cur+feat[i].shape[0],:] = feat[i]\n",
    "        allLabels[cur:cur+feat[i].shape[0]] = i\n",
    "        cur = cur + feat[i].shape[0]\n",
    "    return allFeat, allLabels\n",
    "        \n",
    "    \n",
    "def readNetVlad(folder, numDim =4096):\n",
    "    folderName = os.path.basename(os.path.normpath(folder))\n",
    "    print(folderName)\n",
    "    file = folder +'/vd16_pitts30k_conv5_3_vlad_preL2_intra_white_' +folderName + '_db.bin'    \n",
    "    data = np.fromfile(file, '<f4')\n",
    "    numPts = int(len(data)/numDim)\n",
    "    return np.reshape(data, [numPts, numDim])\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def cluster_acc(Y_pred, Y):\n",
    "    assert Y_pred.size == Y.size\n",
    "    D = max(Y_pred.max(), Y.max())+1\n",
    "    w = np.zeros((D,D), dtype=np.int64)\n",
    "    for i in range(Y_pred.size):\n",
    "        w[Y_pred[i], Y[i]] += 1\n",
    "    \n",
    "    row_ind, col_ind = linear_sum_assignment(w.max() - w)\n",
    "    \n",
    "    print(w[row_ind,col_ind])\n",
    "    return w[row_ind,col_ind].sum()/Y_pred.size, w\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "feat = np.load('/media/daniel/D/Data/STL-10/feats_2048.npy')\n",
    "gt = np.load('/media/daniel/D/Data/STL-10/labels_2048.npy')-1\n",
    "\n",
    "mask = gt>-1#np.logical_or(gt==3, gt==4)\n",
    "feat = feat[mask,:]\n",
    "gt = gt[mask]\n",
    "\n",
    "#feat = feat-np.mean(feat)\n",
    "\n",
    "feat = feat#/np.linalg.norm(feat, axis =1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "feat = np.reshape(x_test, [x_test.shape[0], x_test.shape[1]*x_test.shape[2]])\n",
    "feat = feat/np.linalg.norm(feat, axis =1, keepdims=True)\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "# pca = PCA(n_components=0.9)\n",
    "# pca.fit(feat)\n",
    "# feat = pca.transform(feat)\n",
    "\n",
    "\n",
    "gt = y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "feat = np.reshape(x_test, [x_test.shape[0], x_test.shape[1]*x_test.shape[2]])\n",
    "feat = feat/np.linalg.norm(feat, axis =1, keepdims=True)\n",
    "\n",
    "\n",
    "\n",
    "gt = y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(feat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-69f90f27dbc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mtrain_feat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_feat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_train_test_feat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mtrain_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_feat\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mtest_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_feat\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "target_class = 0\n",
    "num_train = 500\n",
    "def get_train_test_feat(feat, target_class, num_train, gt):\n",
    "    ind = np.where(gt== target_class)[0]\n",
    "    ind = np.random.choice(ind, num_train, replace=False)\n",
    "    train_feat = copy.copy(feat[ind,:])\n",
    "    mask = np.ones(gt.size, dtype=bool)\n",
    "    mask[ind] = 0\n",
    "    test_feat = copy.copy(feat[mask, :])\n",
    "    test_gt = gt[mask]\n",
    "    \n",
    "    return train_feat, test_feat, test_gt\n",
    "\n",
    "train_feat, test_feat,test_gt = get_train_test_feat(feat, target_class, num_train, gt)\n",
    "a= \n",
    "m = np.mean(feat[np.logical_and(gt==0, gt==1),:], axis =0, keepdims=True)\n",
    "train_feat = train_feat-m\n",
    "test_feat = test_feat -m\n",
    "train_feat = train_feat/np.linalg.norm(train_feat, keepdims=True, axis =1)\n",
    "test_feat = test_feat/np.linalg.norm(test_feat, keepdims=True, axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "0.8982385683760683\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "\n",
    "\n",
    "from highDimLearningX import estModel22\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "numIter =100\n",
    "pca = PCA(n_components=numIter)\n",
    "pca.fit(train_feat)\n",
    "m = pca.components_\n",
    "sig = np.mean(np.matmul(train_feat, np.transpose(m)), axis=0)\n",
    "w, sig = estModel22(train_feat, np.transpose(m), sig, numShells=numIter, weight=0.1)\n",
    "\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "\n",
    "train = np.matmul(train_feat,w)-sig\n",
    "test = np.matmul(test_feat,w)-sig\n",
    "kde = KernelDensity(kernel='gaussian', bandwidth=0.05).fit(train)\n",
    "s = kde.score_samples(test)\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(test_gt==target_class, s)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39207713675213673\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import OneClassSVM\n",
    "\n",
    "clf = OneClassSVM(gamma='auto').fit(train_feat)\n",
    "s =  clf.score_samples(test_feat)  \n",
    "fpr, tpr, _ = roc_curve(test_gt==target_class, s)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
