{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abbey\n",
      "airport_terminal\n",
      "alley\n",
      "amphitheater\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "import dirUtil \n",
    "from highDimLearning import vgg2feat\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "import random \n",
    "    \n",
    "\n",
    "def feat2labels(feat):\n",
    "    numClass = len(feat)\n",
    "    numDim = feat[0].shape[1]\n",
    "    numPts = 0\n",
    "    for i in range(numClass):\n",
    "        numPts = numPts + feat[i].shape[0]\n",
    "\n",
    "    allFeat = np.zeros([numPts, numDim])\n",
    "    allLabels = np.zeros(numPts, dtype = int)\n",
    "    cur = 0\n",
    "    for i in range(numClass):\n",
    "        allFeat[cur:cur+feat[i].shape[0],:] = feat[i]\n",
    "        allLabels[cur:cur+feat[i].shape[0]] = i\n",
    "        cur = cur + feat[i].shape[0]\n",
    "    return allFeat, allLabels\n",
    "        \n",
    "    \n",
    "def readNetVlad(folder, numDim =4096):\n",
    "    folderName = os.path.basename(os.path.normpath(folder))\n",
    "    print(folderName)\n",
    "    file = folder +'/vd16_pitts30k_conv5_3_vlad_preL2_intra_white_' +folderName + '_db.bin'    \n",
    "    data = np.fromfile(file, '<f4')\n",
    "    numPts = int(len(data)/numDim)\n",
    "    return np.reshape(data, [numPts, numDim])\n",
    "\n",
    "\n",
    "feat1 = readNetVlad('/media/sliu/New Volume/basicMITData/abbey')\n",
    "    \n",
    "feat2 = readNetVlad('/media/sliu/New Volume/basicMITData/airport_terminal')\n",
    "\n",
    "feat3 = readNetVlad('/media/sliu/New Volume/basicMITData/alley')\n",
    "\n",
    "feat4 = readNetVlad('/media/sliu/New Volume/basicMITData/amphitheater')\n",
    "\n",
    "\n",
    "# trainingNum = 1000\n",
    "\n",
    "# tf.reset_default_graph()\n",
    "# K.clear_session()\n",
    "# folder = '/home/sliu/code/keras-tutorial/animals/dogs/'\n",
    "# feats = dirUtil.dir2vgg16(folder)\n",
    "# feat1 = vgg2feat(feats)\n",
    "\n",
    "\n",
    "# folder2 = '/home/sliu/code/keras-tutorial/animals/cats/'\n",
    "# tf.reset_default_graph()\n",
    "# K.clear_session()\n",
    "# feats = dirUtil.dir2vgg16(folder2)\n",
    "# feat2 = vgg2feat(feats)\n",
    "\n",
    "# folder3 = '/home/sliu/code/keras-tutorial/animals/panda/'\n",
    "# tf.reset_default_graph()\n",
    "# K.clear_session()\n",
    "# feats = dirUtil.dir2vgg16(folder3)\n",
    "# feat3 = vgg2feat(feats)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from clusteringTree import ClusteringTree\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#import ClusteringTree\n",
    "\n",
    "tree = ClusteringTree(1, n_branch=2)\n",
    "\n",
    "#trainFeat, gt = feat2labels([feat1[:6000,:], feat2[:6000,:]])\n",
    "trainFeat, gt = feat2labels([feat1[:6000,:]])\n",
    "\n",
    "labels_final, scores_final = tree.construct_tree(trainFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41736197 0.62925318]\n",
      "[0.46210655 0.63291139]\n",
      "[0.41825831 0.60072466]\n"
     ]
    }
   ],
   "source": [
    "a = tree.transform(feat1[6000:,:])\n",
    "sameFeat = a/np.linalg.norm(a, axis =1, keepdims=True)\n",
    "\n",
    "f = tree.transform(feat4)\n",
    "diffFeat = f/np.linalg.norm(f, axis =1, keepdims=True)\n",
    "\n",
    "c = tree.transform(trainFeat)\n",
    "trainingFeat = c/np.linalg.norm(c, axis =1, keepdims=True)\n",
    "\n",
    "\n",
    "print(np.mean(sameFeat, axis =0))\n",
    "print(np.mean(diffFeat, axis =0))\n",
    "print(np.mean(trainingFeat, axis =0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6077274323849666"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors.kde import KernelDensity\n",
    "\n",
    "\n",
    "def densityScoring(trainingFeat, sameFeat, diffFeat, bandwidth=0.001):\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth).fit(trainingFeat)\n",
    "    sameScore = kde.score_samples(sameFeat)\n",
    "    diffScore = kde.score_samples(diffFeat)\n",
    "\n",
    "    comb = np.concatenate([sameScore, diffScore])\n",
    "    \n",
    "    ind = np.argsort(-comb)\n",
    "    est = np.zeros(ind.size)\n",
    "    gt  = np.zeros(ind.size)\n",
    "    thres = sameFeat.shape[0]\n",
    "    runner = 0\n",
    "    for i in ind:\n",
    "        if runner<thres:\n",
    "            gt[runner] = 1\n",
    "            est[i] = 1\n",
    "            runner = runner +1\n",
    "            \n",
    "    score = 1- np.sum(np.absolute(est-gt))/gt.size\n",
    "    return score\n",
    "\n",
    "densityScoring(trainingFeat, sameFeat, diffFeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.52019669827889"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "numDim = 3\n",
    "\n",
    "scaler = StandardScaler(with_std=False).fit(trainFeat)\n",
    "trainingFeat = scaler.transform(trainFeat)\n",
    "pca = PCA(n_components=numDim)\n",
    "pca.fit(trainingFeat)\n",
    "trainingFeat = pca.transform(trainingFeat)\n",
    "#trainingFeat = trainingFeat/np.linalg.norm(trainingFeat, axis =1, keepdims=True)\n",
    "\n",
    "\n",
    "a = scaler.transform(feat1[6000:,:])\n",
    "a = pca.transform(a)\n",
    "sameFeat = a#a/np.linalg.norm(a, axis =1, keepdims=True)\n",
    "\n",
    "\n",
    "b = scaler.transform(feat4)\n",
    "b = pca.transform(b)\n",
    "diffFeat = b#/np.linalg.norm(b, axis =1, keepdims=True)\n",
    "\n",
    "\n",
    "densityScoring(trainingFeat, sameFeat, diffFeat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
