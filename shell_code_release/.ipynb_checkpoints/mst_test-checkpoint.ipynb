{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "import dirUtil \n",
    "from highDimLearning import vgg2feat\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import os\n",
    "import random \n",
    "    \n",
    "\n",
    "def feat2labels(feat):\n",
    "    numClass = len(feat)\n",
    "    numDim = feat[0].shape[1]\n",
    "    numPts = 0\n",
    "    for i in range(numClass):\n",
    "        numPts = numPts + feat[i].shape[0]\n",
    "\n",
    "    allFeat = np.zeros([numPts, numDim])\n",
    "    allLabels = np.zeros(numPts, dtype = int)\n",
    "    cur = 0\n",
    "    for i in range(numClass):\n",
    "        allFeat[cur:cur+feat[i].shape[0],:] = feat[i]\n",
    "        allLabels[cur:cur+feat[i].shape[0]] = i\n",
    "        cur = cur + feat[i].shape[0]\n",
    "    return allFeat, allLabels\n",
    "        \n",
    "    \n",
    "def readNetVlad(folder, numDim =4096):\n",
    "    folderName = os.path.basename(os.path.normpath(folder))\n",
    "    print(folderName)\n",
    "    file = folder +'/vd16_pitts30k_conv5_3_vlad_preL2_intra_white_' +folderName + '_db.bin'    \n",
    "    data = np.fromfile(file, '<f4')\n",
    "    numPts = int(len(data)/numDim)\n",
    "    return np.reshape(data, [numPts, numDim])\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def cluster_acc(Y_pred, Y):\n",
    "    assert Y_pred.size == Y.size\n",
    "    D = max(Y_pred.max(), Y.max())+1\n",
    "    w = np.zeros((D,D), dtype=np.int64)\n",
    "    for i in range(Y_pred.size):\n",
    "        w[Y_pred[i], Y[i]] += 1\n",
    "    \n",
    "    row_ind, col_ind = linear_sum_assignment(w.max() - w)\n",
    "    \n",
    "    print(w[row_ind,col_ind])\n",
    "    return w[row_ind,col_ind].sum()/Y_pred.size, w\n",
    "\n",
    "\n",
    "\n",
    "feat = np.load('/media/sliu/New Volume/STL-10/feats_2048.npy')\n",
    "gt = np.load('/media/sliu/New Volume/STL-10/labels_2048.npy')-1\n",
    "\n",
    "mask = gt<3#np.logical_or(gt==0, gt==1)\n",
    "feat = feat[mask,:]\n",
    "gt = gt[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3920054125396601"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "new_feat = feat/np.linalg.norm(feat, axis =1, keepdims=True)\n",
    "aff = pairwise_distances(new_feat)\n",
    "\n",
    "np.max(aff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "sig =0.1\n",
    "max_val = 1.2\n",
    "mat = copy.copy(aff)\n",
    "mat[mat>max_val] = max_val\n",
    "\n",
    "mat = 1-np.exp( (mat -max_val)/sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import spectral_clustering\n",
    "\n",
    "clustering = SpectralClustering(n_clusters=2,\n",
    "         assign_labels=\"discretize\",\n",
    "         random_state=0).fit(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.fromarray(255*mat/np.max(mat))\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSTClustering(approximate=False, cutoff=None, cutoff_scale=0.85,\n",
       "              metric='euclidean', metric_params=None, min_cluster_size=500,\n",
       "              n_neighbors=10)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mst_clustering import MSTClustering\n",
    "\n",
    "\n",
    "new_feat = feat/np.linalg.norm(feat, axis =1, keepdims=True)\n",
    "noisy_model = MSTClustering(cutoff_scale=0.85, n_neighbors=10, min_cluster_size=500,  approximate=False)\n",
    "noisy_model.fit(new_feat)\n",
    "#plot_mst(noisy_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = noisy_model.fit_predict(new_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3359\n",
      "0 3359\n"
     ]
    }
   ],
   "source": [
    "for i in range(max(labels)+1):\n",
    "    num = sum(labels==i)\n",
    "    print(num)\n",
    "    if num> 100:\n",
    "        print(i,num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 -1 -1  0 -1  0  0  0  0  0  0 -1 -1  0  0  0  0  0  0 -1  0  0  0  0\n",
      "  0  0 -1  0 -1  0  0  0 -1  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0\n",
      "  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1 -1\n",
      "  0  0 -1  0  0  0  0  0  0 -1  0  0 -1  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0 -1 -1  0  0  0  0 -1  0  0  0  0  0  0 -1  0  0  0  0\n",
      "  0 -1  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0 -1  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0 -1  0  0 -1\n",
      "  0  0  0 -1  0  0  0  0 -1  0  0  0  0  0 -1  0  0  0  0  0  0 -1 -1 -1\n",
      "  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0\n",
      "  0  0  0 -1  0  0 -1 -1  0  0  0  0  0  0  0  0  0  0 -1  0 -1  0 -1  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0 -1  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0\n",
      " -1 -1  0 -1 -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1\n",
      "  0  0  0  0  0  0  0 -1 -1  0  0  0  0 -1  0  0  0  0  0  0  0  0 -1  0\n",
      " -1  0 -1  0  0  0 -1  0 -1  0  0  0 -1  0  0  0  0  0 -1 -1  0  0  0 -1\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1 -1  0  0  0  0  0 -1  0\n",
      " -1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0\n",
      "  0  0  0  0  0 -1  0  0  0  0  0  0  0  0  0  0 -1  0  0  0  0  0  0 -1\n",
      " -1  0  0  0 -1  0  0  0  0  0  0  0  0  0  0  0  0  0 -1  0]\n"
     ]
    }
   ],
   "source": [
    "print(labels[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1  0 -1 ...  0 -1 -1]\n"
     ]
    }
   ],
   "source": [
    "print(labels[1300:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "graph should be a square array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-5ff421902dbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 [0, 0, 0, 0]])\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mTcsr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimum_spanning_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mTcsr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_min_spanning_tree.pyx\u001b[0m in \u001b[0;36mscipy.sparse.csgraph._min_spanning_tree.minimum_spanning_tree\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/scipy/sparse/csgraph/_validation.py\u001b[0m in \u001b[0;36mvalidate_graph\u001b[0;34m(csgraph, directed, dtype, csr_output, dense_output, copy_if_dense, copy_if_sparse, null_value_in, null_value_out, infinity_null, nan_null)\u001b[0m\n\u001b[1;32m     48\u001b[0m             csgraph = csgraph_from_dense(csgraph, null_value=null_value_in,\n\u001b[1;32m     49\u001b[0m                                          \u001b[0minfinity_null\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minfinity_null\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                                          nan_null=nan_null)\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcsgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m_tools.pyx\u001b[0m in \u001b[0;36mscipy.sparse.csgraph._tools.csgraph_from_dense\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_tools.pyx\u001b[0m in \u001b[0;36mscipy.sparse.csgraph._tools.csgraph_masked_from_dense\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: graph should be a square array"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "X = csr_matrix([[0, 8, 0, 3],\n",
    "                [0, 0, 2, 5],\n",
    "                [0, 0, 0, 6],\n",
    "                [0, 0, 0, 0]])\n",
    "Tcsr = minimum_spanning_tree(new_feat)\n",
    "Tcsr.toarray().astype(int)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
